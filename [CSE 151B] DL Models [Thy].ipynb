{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e438c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 02:26:59.004382: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 02:26:59.877888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statistics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08659c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ee28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('dftrain.csv'):\n",
    "    dftrain = pd.read_csv('dftrain.csv')\n",
    "if os.path.exists('dftest.csv'):\n",
    "    dftest = pd.read_csv('dftest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b992ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebc17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bf4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_ids=list(set(test_data['TAXI_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc69b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408039037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  CALL_TYPE_A  \\\n",
       "0      T1  20000542  2014      8    33   14    17   57        3            0   \n",
       "\n",
       "   CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  MISSING_DATA  \\\n",
       "0            1            0            1             1             0   \n",
       "\n",
       "    TIMESTAMP  \n",
       "0  1408039037  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04e1272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "new_train=dftrain[dftrain['TAXI_ID'] == 20000542]\n",
    "sns.heatmap(new_train.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm',square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd0c83",
   "metadata": {},
   "source": [
    "## Get train/test for 1st taxi_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289d5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_id = []\n",
    "travel_preds = []\n",
    "\n",
    "for taxi_id in [20000542]:\n",
    "    newtrain=dftrain[dftrain['TAXI_ID'] == taxi_id]\n",
    "    \n",
    "    train_corr=newtrain[['TRAVEL_TIME', 'YEAR', 'MONTH', 'WEEK', 'DAY', 'HOUR', 'MIN', 'WEEKDAY']].corr()\n",
    "    positive_corr_list=list(train_corr[train_corr > 0]['TRAVEL_TIME'].dropna().keys())\n",
    "    positive_corr_list.remove('TRAVEL_TIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80240a6",
   "metadata": {},
   "source": [
    "## Cut outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b99c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = newtrain\n",
    "Q1 = tmpdf['TRAVEL_TIME'].quantile(0.25)\n",
    "Q3 = tmpdf['TRAVEL_TIME'].quantile(0.5)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "new_train = newtrain[newtrain.TRAVEL_TIME >= lower_bound]\n",
    "new_train = newtrain[newtrain.TRAVEL_TIME <= upper_bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc775a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10717f9",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81695b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {\n",
    "    2013: [1, 0],\n",
    "    2014: [0, 1]\n",
    "}\n",
    "\n",
    "tmp_day = np.zeros(len(new_train.DAY.unique()))\n",
    "days = {}\n",
    "for d in list(new_train.DAY):\n",
    "    tmp = list(tmp_day)\n",
    "    tmp[d-1] = tmp[d-1] + 1\n",
    "    days[d] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f373f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_hr = np.zeros(len(new_train.HOUR.unique()))\n",
    "hrs = {}\n",
    "for h in list(new_train.HOUR):\n",
    "    tmp = list(tmp_hr)\n",
    "    tmp[h-1] = tmp[h-1] + 1\n",
    "    hrs[h] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a402065",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_min = np.zeros(len(new_train.MIN.unique()))\n",
    "mins = {}\n",
    "for m in list(new_train.MIN):\n",
    "    tmp = list(tmp_min)\n",
    "    tmp[m-1] = tmp[m-1] + 1\n",
    "    mins[m] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534a4df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR', 'DAY', 'HOUR', 'MIN']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff14cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_travel_time = np.zeros(len(new_train.TRAVEL_TIME.unique()))\n",
    "uniq_travels = new_train.TRAVEL_TIME.unique()\n",
    "times = {}\n",
    "for i in range(len(tmp_travel_time)):\n",
    "    tmp = list(tmp_travel_time)\n",
    "    tmp[i] = 1\n",
    "    times[uniq_travels[i]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c31004",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for row in new_train.iterrows():\n",
    "    lst = []\n",
    "    for elem in positive_corr_list:\n",
    "        if elem == 'YEAR':\n",
    "            lst = lst + years[row[1]['YEAR']]\n",
    "        if elem == 'DAY':\n",
    "            lst = lst + days[row[1]['DAY']]\n",
    "        if elem == 'HOUR':\n",
    "            lst = lst + hrs[row[1]['HOUR']]\n",
    "        if elem == 'MIN':\n",
    "            lst = lst + mins[row[1]['MIN']]\n",
    "    Xtrain.append(np.array(lst))\n",
    "    ytrain.append(np.array(times[row[1]['TRAVEL_TIME']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c3994c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 02:27:23.948983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10379 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:3e:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.array(Xtrain)\n",
    "ytrain = np.array(ytrain)\n",
    "\n",
    "X_train = tf.convert_to_tensor(np.array(Xtrain[:int(Xtrain.shape[0]*2/3)]))\n",
    "y_train = tf.convert_to_tensor(np.array(ytrain[:int(Xtrain.shape[0]*2/3)]))\n",
    "\n",
    "X_val = tf.convert_to_tensor(np.array(Xtrain[int(Xtrain.shape[0]*2/3):]))\n",
    "y_val = tf.convert_to_tensor(np.array(ytrain[int(Xtrain.shape[0]*2/3):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d6cab4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3160, 65])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5acc57",
   "metadata": {},
   "source": [
    "## True-value FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2980f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for row in new_train.iterrows():\n",
    "    lst = []\n",
    "    for elem in positive_corr_list:\n",
    "        lst.append(row[1][elem])\n",
    "    Xtrain.append(np.array(lst))\n",
    "    ytrain.append(np.array(times[row[1]['TRAVEL_TIME']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f9ee3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.array(Xtrain)\n",
    "ytrain = np.array(ytrain)\n",
    "\n",
    "X_train = tf.convert_to_tensor(np.array(Xtrain[:int(Xtrain.shape[0]*2/3)]))\n",
    "y_train = tf.convert_to_tensor(np.array(ytrain[:int(Xtrain.shape[0]*2/3)]))\n",
    "\n",
    "X_val = tf.convert_to_tensor(np.array(Xtrain[int(Xtrain.shape[0]*2/3):]))\n",
    "y_val = tf.convert_to_tensor(np.array(ytrain[int(Xtrain.shape[0]*2/3):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cdae5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = dftest[dftest.TAXI_ID == 20000542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a461b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408039037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>20000108</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408038611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>20000370</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408038568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>20000492</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408039090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>20000621</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408039177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>20000430</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1419171485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>20000020</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1419170802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>20000207</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1419172121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>20000667</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1419171980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>20000255</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1419171420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "0        T1  20000542  2014      8    33   14    17   57        3   \n",
       "1        T2  20000108  2014      8    33   14    17   50        3   \n",
       "2        T3  20000370  2014      8    33   14    17   49        3   \n",
       "3        T4  20000492  2014      8    33   14    17   58        3   \n",
       "4        T5  20000621  2014      8    33   14    17   59        3   \n",
       "..      ...       ...   ...    ...   ...  ...   ...  ...      ...   \n",
       "315    T323  20000430  2014     12    51   21    14   18        6   \n",
       "316    T324  20000020  2014     12    51   21    14    6        6   \n",
       "317    T325  20000207  2014     12    51   21    14   28        6   \n",
       "318    T326  20000667  2014     12    51   21    14   26        6   \n",
       "319    T327  20000255  2014     12    51   21    14   17        6   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0              0            1            0            1             1   \n",
       "1              0            1            0            1             1   \n",
       "2              0            1            0            1             1   \n",
       "3              0            1            0            1             1   \n",
       "4              0            1            0            1             1   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "315            1            0            0            1             1   \n",
       "316            0            1            0            1             1   \n",
       "317            0            0            1            1             1   \n",
       "318            1            0            0            1             1   \n",
       "319            1            0            0            1             1   \n",
       "\n",
       "     MISSING_DATA   TIMESTAMP  \n",
       "0               0  1408039037  \n",
       "1               0  1408038611  \n",
       "2               0  1408038568  \n",
       "3               0  1408039090  \n",
       "4               0  1408039177  \n",
       "..            ...         ...  \n",
       "315             0  1419171485  \n",
       "316             0  1419170802  \n",
       "317             0  1419172121  \n",
       "318             0  1419171980  \n",
       "319             0  1419171420  \n",
       "\n",
       "[320 rows x 16 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23577264",
   "metadata": {},
   "source": [
    "## Deep Belief Networks (DBNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9aeae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 02:27:45.218232: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f65e4007840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-02 02:27:45.218279: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-06-02 02:27:45.517906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.543537: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.543792: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.543829: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "\t [[{{node StatefulPartitionedCall_10}}]]\n",
      "2023-06-02 02:27:45.547924: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.572873: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.573073: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.577076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.602574: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.602796: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.606950: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.634421: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.634652: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.639029: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.666577: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.666808: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.671066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.698357: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.698604: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.705829: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.732899: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.733131: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.737496: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.762887: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.763071: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.767165: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.791964: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.792116: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.814323: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.852500: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.852680: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.859251: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.883966: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.884116: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-02 02:27:45.890765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-02 02:27:45.917025: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-02 02:27:45.917205: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_10' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_13846/4146499484.py\", line 20, in <module>\n      model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_10'\nRET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n\t [[{{node StatefulPartitionedCall_10}}]] [Op:__inference_train_function_1076]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13846/4146499484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train the DBN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_10' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_13846/4146499484.py\", line 20, in <module>\n      model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_10'\nRET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n\t [[{{node StatefulPartitionedCall_10}}]] [Op:__inference_train_function_1076]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Create the DBN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the hidden layers\n",
    "model.add(Dense(units=128, activation='sigmoid', input_shape=(Xtrain.shape[1],)))\n",
    "model.add(Dense(units=128, activation='sigmoid'))\n",
    "model.add(Dense(units=64, activation='sigmoid'))\n",
    "model.add(Dense(units=64, activation='sigmoid'))\n",
    "model.add(Dense(units=32, activation='sigmoid'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(units=len(times), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the DBN\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf8b1e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "#ytrain = []\n",
    "\n",
    "for row in new_test.iterrows():\n",
    "    lst = []\n",
    "    for elem in positive_corr_list:\n",
    "        if elem == 'YEAR':\n",
    "            lst = lst + years[row[1]['YEAR']]\n",
    "        if elem == 'DAY':\n",
    "            lst = lst + days[row[1]['DAY']]\n",
    "        if elem == 'HOUR':\n",
    "            lst = lst + hrs[row[1]['HOUR']]\n",
    "        if elem == 'MIN':\n",
    "            lst = lst + mins[row[1]['MIN']]\n",
    "    Xtest.append(np.array(lst))\n",
    "    #ytrain.append(np.array(times[row[1]['TRAVEL_TIME']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31cd88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = np.array(Xtest)\n",
    "X_test = tf.convert_to_tensor(np.array(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "92703cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predicted_labels = np.argmax(model.predict(Xtest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "58992083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 13])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "649fd661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_travels[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eed064",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66344534",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(np.array(Xtrain[:int(Xtrain.shape[0]*2/3)]))\n",
    "\n",
    "ytrain = list(new_train.TRAVEL_TIME)\n",
    "y_train = tf.convert_to_tensor(np.array(ytrain[:int(Xtrain.shape[0]*2/3)]))\n",
    "\n",
    "X_val = tf.convert_to_tensor(np.array(Xtrain[int(Xtrain.shape[0]*2/3):]))\n",
    "y_val = tf.convert_to_tensor(np.array(ytrain[int(Xtrain.shape[0]*2/3):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a08f1e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 23:58:54.387885: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.419634: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.420042: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.420072: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "\t [[{{node StatefulPartitionedCall_10}}]]\n",
      "2023-06-01 23:58:54.438557: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.464388: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.464762: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.485171: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.523816: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.524220: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.548686: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.591030: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.591529: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.612173: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.637702: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.637973: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.652526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.676725: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.676934: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.691766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.721861: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.722139: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.739552: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.781649: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.782050: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.807708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.838099: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.838584: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.867735: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.898653: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.899122: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.918096: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.942771: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.943011: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "2023-06-01 23:58:54.957502: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-06-01 23:58:54.981799: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n",
      "*** Begin stack trace ***\n",
      "\ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "\t\n",
      "\txla::status_macros::MakeErrorStream::Impl::GetStatus()\n",
      "\txla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*, xla::gpu::GpuTargetConfig const&, xla::AutotuneResults const*)\n",
      "\txla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)\n",
      "\txla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)\n",
      "\txla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\txla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)\n",
      "\ttensorflow::XlaDeviceCompilerClient::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileStrict(tensorflow::DeviceCompilationClusterSignature const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::DeviceCompilationCache<xla::LocalExecutable>::Value, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tsl::mutex*)\n",
      "\ttensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::DeviceCompiler<xla::LocalExecutable, xla::LocalClient>::CompileScope, tensorflow::DeviceCompileMode, tensorflow::OpKernelContext*, tensorflow::DeviceCompilationProfiler*, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)\n",
      "\t\n",
      "\ttensorflow::XlaLocalLaunchBase::ComputeAsync(tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\ttensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function<void ()>)\n",
      "\t\n",
      "\t\n",
      "\tEigen::ThreadPoolTempl<tsl::thread::EigenEnvironment>::WorkerLoop(int)\n",
      "\tstd::_Function_handler<void (), tsl::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&)\n",
      "\t\n",
      "\t\n",
      "\tclone\n",
      "*** End stack trace ***\n",
      "\n",
      "2023-06-01 23:58:54.982014: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_10' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_9012/289510580.py\", line 20, in <module>\n      model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_10'\nRET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n\t [[{{node StatefulPartitionedCall_10}}]] [Op:__inference_train_function_5016]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9012/289510580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_10' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_9012/289510580.py\", line 20, in <module>\n      model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_10'\nRET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:618) dnn != nullptr \n\t [[{{node StatefulPartitionedCall_10}}]] [Op:__inference_train_function_5016]"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='softmax', input_dim=Xtrain.shape[1]))\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss=root_mean_squared_error, metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d225899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.12.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.9/site-packages\n",
      "Requires: google-pasta, astunparse, six, h5py, typing-extensions, tensorflow-io-gcs-filesystem, libclang, numpy, setuptools, tensorflow-estimator, protobuf, flatbuffers, gast, termcolor, wrapt, grpcio, tensorboard, absl-py, keras, packaging, opt-einsum, jax\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec544b",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "85152b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567.5"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## in_data\n",
    "for taxi_id in [20000542]:\n",
    "    newtrain=dftrain[dftrain['TAXI_ID'] == taxi_id]\n",
    "    \n",
    "    train_corr=newtrain[['TRAVEL_TIME', 'YEAR', 'MONTH', 'WEEK', 'DAY', 'HOUR', 'MIN', 'WEEKDAY']].corr()\n",
    "    positive_corr_list=list(train_corr[train_corr > 0]['TRAVEL_TIME'].dropna().keys())\n",
    "    positive_corr_list.remove('TRAVEL_TIME')\n",
    "\n",
    "## outlier cut\n",
    "tmpdf = newtrain\n",
    "Q1 = tmpdf['TRAVEL_TIME'].quantile(0.25)\n",
    "Q3 = tmpdf['TRAVEL_TIME'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "new_train = newtrain[newtrain.TRAVEL_TIME >= lower_bound]\n",
    "new_train = newtrain[newtrain.TRAVEL_TIME <= upper_bound]\n",
    "\n",
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "47c8b7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-292.5"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "25daf3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR', 'DAY', 'HOUR', 'MIN']"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "7ade913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = newtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "cdf09765",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_times = new_train.TRAVEL_TIME.unique()\n",
    "n = len(avail_times)\n",
    "range_ = list(range(n))\n",
    "labels = dict(zip(avail_times,range_))\n",
    "labels_rev = dict(zip(range_, avail_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "63ac2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for row in new_train.iterrows():\n",
    "    \n",
    "    lst = []\n",
    "    for elem in ['YEAR', 'DAY', 'HOUR', 'MIN']:#, 'WEEKDAY']:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    Xtrain.append(np.array(lst))\n",
    "    ytrain.append(np.array(labels[row[1]['TRAVEL_TIME']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "0cd7f57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "5543b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5689655172413793\n"
     ]
    }
   ],
   "source": [
    "X = Xtrain\n",
    "y = ytrain\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99, random_state=42)\n",
    "\n",
    "# Create an LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the LDA model on the training data\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for the test data\n",
    "y_pred = lda.predict(X_train)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "9066cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = dftest[dftest.TAXI_ID == 20000542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "5763a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "#ytest = []\n",
    "\n",
    "for row in new_test.iterrows():\n",
    "    lst = []\n",
    "    for elem in ['YEAR', 'DAY', 'HOUR', 'MIN']:#, 'WEEKDAY']:\n",
    "        lst.append(row[1][elem])\n",
    "    Xtest.append(np.array(lst))\n",
    "    #ytest.append(np.array(labels[row[1]['TRAVEL_TIME']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "65fc1f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 33])"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "381451e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_rev[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "62f5f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "81225\n"
     ]
    }
   ],
   "source": [
    "print((585-labels_rev[17])**2)\n",
    "print((210-labels_rev[4])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "2bdd2175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408039037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>T308</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1419162114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "0        T1  20000542  2014      8    33   14    17   57        3   \n",
       "300    T308  20000542  2014     12    51   21    11   41        6   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0              0            1            0            1             1   \n",
       "300            0            0            1            1             1   \n",
       "\n",
       "     MISSING_DATA   TIMESTAMP  \n",
       "0               0  1408039037  \n",
       "300             0  1419162114  "
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "4ec009c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0),\n",
       " array(1),\n",
       " array(2),\n",
       " array(3),\n",
       " array(4),\n",
       " array(5),\n",
       " array(6),\n",
       " array(7),\n",
       " array(8),\n",
       " array(9),\n",
       " array(10),\n",
       " array(11),\n",
       " array(8),\n",
       " array(12),\n",
       " array(5),\n",
       " array(13),\n",
       " array(14),\n",
       " array(15),\n",
       " array(8),\n",
       " array(16),\n",
       " array(17),\n",
       " array(18),\n",
       " array(12),\n",
       " array(19),\n",
       " array(9),\n",
       " array(20),\n",
       " array(21),\n",
       " array(22),\n",
       " array(20),\n",
       " array(0),\n",
       " array(23),\n",
       " array(5),\n",
       " array(24),\n",
       " array(15),\n",
       " array(13),\n",
       " array(25),\n",
       " array(10),\n",
       " array(21),\n",
       " array(26),\n",
       " array(4),\n",
       " array(27),\n",
       " array(9),\n",
       " array(19),\n",
       " array(28),\n",
       " array(29),\n",
       " array(30),\n",
       " array(31),\n",
       " array(10),\n",
       " array(32),\n",
       " array(33),\n",
       " array(34),\n",
       " array(29),\n",
       " array(35),\n",
       " array(26),\n",
       " array(10),\n",
       " array(36),\n",
       " array(35),\n",
       " array(37),\n",
       " array(8),\n",
       " array(38),\n",
       " array(31),\n",
       " array(29),\n",
       " array(19),\n",
       " array(25),\n",
       " array(39),\n",
       " array(0),\n",
       " array(40),\n",
       " array(41),\n",
       " array(42),\n",
       " array(12),\n",
       " array(13),\n",
       " array(43),\n",
       " array(44),\n",
       " array(45),\n",
       " array(31),\n",
       " array(13),\n",
       " array(31),\n",
       " array(46),\n",
       " array(24),\n",
       " array(47),\n",
       " array(25),\n",
       " array(45),\n",
       " array(48),\n",
       " array(17),\n",
       " array(49),\n",
       " array(50),\n",
       " array(0),\n",
       " array(21),\n",
       " array(51),\n",
       " array(52),\n",
       " array(53),\n",
       " array(17),\n",
       " array(15),\n",
       " array(13),\n",
       " array(15),\n",
       " array(4),\n",
       " array(37),\n",
       " array(54),\n",
       " array(39),\n",
       " array(55),\n",
       " array(56),\n",
       " array(13),\n",
       " array(33),\n",
       " array(12),\n",
       " array(57),\n",
       " array(12),\n",
       " array(33),\n",
       " array(28),\n",
       " array(42),\n",
       " array(31),\n",
       " array(46),\n",
       " array(0),\n",
       " array(24),\n",
       " array(30),\n",
       " array(58),\n",
       " array(59),\n",
       " array(59),\n",
       " array(34),\n",
       " array(54),\n",
       " array(17),\n",
       " array(60),\n",
       " array(30),\n",
       " array(42),\n",
       " array(54),\n",
       " array(61),\n",
       " array(32),\n",
       " array(17),\n",
       " array(62),\n",
       " array(63),\n",
       " array(5),\n",
       " array(10),\n",
       " array(10),\n",
       " array(64),\n",
       " array(36),\n",
       " array(39),\n",
       " array(65),\n",
       " array(17),\n",
       " array(17),\n",
       " array(14),\n",
       " array(66),\n",
       " array(41),\n",
       " array(30),\n",
       " array(32),\n",
       " array(39),\n",
       " array(38),\n",
       " array(59),\n",
       " array(60),\n",
       " array(8),\n",
       " array(60),\n",
       " array(22),\n",
       " array(67),\n",
       " array(56),\n",
       " array(22),\n",
       " array(68),\n",
       " array(61),\n",
       " array(0),\n",
       " array(29),\n",
       " array(41),\n",
       " array(12),\n",
       " array(61),\n",
       " array(48),\n",
       " array(69),\n",
       " array(17),\n",
       " array(70),\n",
       " array(71),\n",
       " array(34),\n",
       " array(50),\n",
       " array(12),\n",
       " array(3),\n",
       " array(57),\n",
       " array(36),\n",
       " array(72),\n",
       " array(20),\n",
       " array(69),\n",
       " array(34),\n",
       " array(17),\n",
       " array(73),\n",
       " array(3),\n",
       " array(16),\n",
       " array(34),\n",
       " array(74),\n",
       " array(75),\n",
       " array(48),\n",
       " array(38),\n",
       " array(57),\n",
       " array(19),\n",
       " array(76),\n",
       " array(59),\n",
       " array(77),\n",
       " array(75),\n",
       " array(21),\n",
       " array(74),\n",
       " array(39),\n",
       " array(15),\n",
       " array(15),\n",
       " array(13),\n",
       " array(78),\n",
       " array(50),\n",
       " array(24),\n",
       " array(3),\n",
       " array(11),\n",
       " array(60),\n",
       " array(61),\n",
       " array(4),\n",
       " array(45),\n",
       " array(75),\n",
       " array(32),\n",
       " array(58),\n",
       " array(25),\n",
       " array(29),\n",
       " array(75),\n",
       " array(21),\n",
       " array(24),\n",
       " array(26),\n",
       " array(42),\n",
       " array(58),\n",
       " array(25),\n",
       " array(33),\n",
       " array(36),\n",
       " array(18),\n",
       " array(26),\n",
       " array(33),\n",
       " array(72),\n",
       " array(32),\n",
       " array(17),\n",
       " array(12),\n",
       " array(54),\n",
       " array(16),\n",
       " array(79),\n",
       " array(79),\n",
       " array(64),\n",
       " array(6),\n",
       " array(26),\n",
       " array(77),\n",
       " array(72),\n",
       " array(61),\n",
       " array(76),\n",
       " array(11),\n",
       " array(4),\n",
       " array(10),\n",
       " array(33),\n",
       " array(20),\n",
       " array(29),\n",
       " array(56),\n",
       " array(80),\n",
       " array(0),\n",
       " array(57),\n",
       " array(5),\n",
       " array(26),\n",
       " array(26),\n",
       " array(81),\n",
       " array(82),\n",
       " array(19),\n",
       " array(83),\n",
       " array(21),\n",
       " array(29),\n",
       " array(10),\n",
       " array(33),\n",
       " array(15),\n",
       " array(48),\n",
       " array(54),\n",
       " array(72),\n",
       " array(26),\n",
       " array(84),\n",
       " array(28),\n",
       " array(22),\n",
       " array(10),\n",
       " array(54),\n",
       " array(31),\n",
       " array(29),\n",
       " array(38),\n",
       " array(69),\n",
       " array(10),\n",
       " array(6),\n",
       " array(75),\n",
       " array(29),\n",
       " array(22),\n",
       " array(52),\n",
       " array(38),\n",
       " array(21),\n",
       " array(15),\n",
       " array(16),\n",
       " array(32),\n",
       " array(74),\n",
       " array(21),\n",
       " array(80),\n",
       " array(71),\n",
       " array(5),\n",
       " array(29),\n",
       " array(64),\n",
       " array(20),\n",
       " array(13),\n",
       " array(74),\n",
       " array(85),\n",
       " array(17),\n",
       " array(16),\n",
       " array(80),\n",
       " array(80),\n",
       " array(12),\n",
       " array(80),\n",
       " array(71),\n",
       " array(58),\n",
       " array(86),\n",
       " array(74),\n",
       " array(77),\n",
       " array(10),\n",
       " array(32),\n",
       " array(58),\n",
       " array(9),\n",
       " array(29),\n",
       " array(32),\n",
       " array(58),\n",
       " array(8),\n",
       " array(81),\n",
       " array(17),\n",
       " array(46),\n",
       " array(12),\n",
       " array(74),\n",
       " array(87),\n",
       " array(52),\n",
       " array(10),\n",
       " array(8),\n",
       " array(17),\n",
       " array(61),\n",
       " array(16),\n",
       " array(31),\n",
       " array(72),\n",
       " array(10),\n",
       " array(29),\n",
       " array(13),\n",
       " array(9),\n",
       " array(8),\n",
       " array(57),\n",
       " array(66),\n",
       " array(12),\n",
       " array(16),\n",
       " array(20),\n",
       " array(88),\n",
       " array(6),\n",
       " array(20),\n",
       " array(31),\n",
       " array(54),\n",
       " array(6),\n",
       " array(31),\n",
       " array(2),\n",
       " array(46),\n",
       " array(5),\n",
       " array(15),\n",
       " array(13),\n",
       " array(14),\n",
       " array(21),\n",
       " array(32),\n",
       " array(56),\n",
       " array(47),\n",
       " array(11),\n",
       " array(13),\n",
       " array(32),\n",
       " array(13),\n",
       " array(54),\n",
       " array(26),\n",
       " array(20),\n",
       " array(42),\n",
       " array(33),\n",
       " array(29),\n",
       " array(78),\n",
       " array(89),\n",
       " array(90),\n",
       " array(21),\n",
       " array(24),\n",
       " array(91),\n",
       " array(66),\n",
       " array(12),\n",
       " array(24),\n",
       " array(21),\n",
       " array(8),\n",
       " array(32),\n",
       " array(5),\n",
       " array(59),\n",
       " array(12),\n",
       " array(19),\n",
       " array(67),\n",
       " array(64),\n",
       " array(92),\n",
       " array(30),\n",
       " array(30),\n",
       " array(93),\n",
       " array(39),\n",
       " array(31),\n",
       " array(24),\n",
       " array(0),\n",
       " array(57),\n",
       " array(17),\n",
       " array(0),\n",
       " array(6),\n",
       " array(21),\n",
       " array(69),\n",
       " array(59),\n",
       " array(46),\n",
       " array(14),\n",
       " array(31),\n",
       " array(63),\n",
       " array(75),\n",
       " array(47),\n",
       " array(94),\n",
       " array(4),\n",
       " array(66),\n",
       " array(76),\n",
       " array(64),\n",
       " array(72),\n",
       " array(87),\n",
       " array(36),\n",
       " array(6),\n",
       " array(95),\n",
       " array(96),\n",
       " array(95),\n",
       " array(93),\n",
       " array(72),\n",
       " array(13),\n",
       " array(4),\n",
       " array(26),\n",
       " array(97),\n",
       " array(12),\n",
       " array(38),\n",
       " array(6),\n",
       " array(22),\n",
       " array(15),\n",
       " array(28),\n",
       " array(5),\n",
       " array(15),\n",
       " array(25),\n",
       " array(22),\n",
       " array(72),\n",
       " array(38),\n",
       " array(30),\n",
       " array(75),\n",
       " array(58),\n",
       " array(14),\n",
       " array(13),\n",
       " array(39),\n",
       " array(61),\n",
       " array(47),\n",
       " array(39),\n",
       " array(24),\n",
       " array(3),\n",
       " array(6),\n",
       " array(10),\n",
       " array(24),\n",
       " array(26),\n",
       " array(39),\n",
       " array(26),\n",
       " array(26),\n",
       " array(36),\n",
       " array(32),\n",
       " array(13),\n",
       " array(22),\n",
       " array(32),\n",
       " array(64),\n",
       " array(26),\n",
       " array(24),\n",
       " array(98),\n",
       " array(36),\n",
       " array(25),\n",
       " array(53),\n",
       " array(20),\n",
       " array(1),\n",
       " array(6),\n",
       " array(99),\n",
       " array(16),\n",
       " array(69),\n",
       " array(70),\n",
       " array(13),\n",
       " array(59),\n",
       " array(45),\n",
       " array(46),\n",
       " array(76),\n",
       " array(75),\n",
       " array(72),\n",
       " array(72),\n",
       " array(59),\n",
       " array(45),\n",
       " array(34),\n",
       " array(56),\n",
       " array(78),\n",
       " array(74),\n",
       " array(21),\n",
       " array(24),\n",
       " array(39),\n",
       " array(10),\n",
       " array(26),\n",
       " array(39),\n",
       " array(69),\n",
       " array(72),\n",
       " array(25),\n",
       " array(12),\n",
       " array(76),\n",
       " array(10),\n",
       " array(15),\n",
       " array(29),\n",
       " array(17),\n",
       " array(46),\n",
       " array(17),\n",
       " array(4),\n",
       " array(5),\n",
       " array(5),\n",
       " array(42),\n",
       " array(38),\n",
       " array(76),\n",
       " array(32),\n",
       " array(5),\n",
       " array(15),\n",
       " array(48),\n",
       " array(26),\n",
       " array(42),\n",
       " array(26),\n",
       " array(10),\n",
       " array(64),\n",
       " array(0),\n",
       " array(26),\n",
       " array(15),\n",
       " array(39),\n",
       " array(27),\n",
       " array(26),\n",
       " array(59),\n",
       " array(11),\n",
       " array(36),\n",
       " array(5),\n",
       " array(19),\n",
       " array(53),\n",
       " array(88),\n",
       " array(38),\n",
       " array(13),\n",
       " array(100),\n",
       " array(15),\n",
       " array(48),\n",
       " array(93),\n",
       " array(30),\n",
       " array(54),\n",
       " array(39),\n",
       " array(6),\n",
       " array(6),\n",
       " array(61),\n",
       " array(15),\n",
       " array(72),\n",
       " array(66),\n",
       " array(8),\n",
       " array(10),\n",
       " array(26),\n",
       " array(101),\n",
       " array(16),\n",
       " array(54),\n",
       " array(26),\n",
       " array(4),\n",
       " array(60),\n",
       " array(66),\n",
       " array(47),\n",
       " array(30),\n",
       " array(69),\n",
       " array(21),\n",
       " array(25),\n",
       " array(26),\n",
       " array(102),\n",
       " array(26),\n",
       " array(75),\n",
       " array(52),\n",
       " array(17),\n",
       " array(25),\n",
       " array(26),\n",
       " array(33),\n",
       " array(103),\n",
       " array(104),\n",
       " array(74),\n",
       " array(69),\n",
       " array(53),\n",
       " array(17),\n",
       " array(72),\n",
       " array(15),\n",
       " array(35),\n",
       " array(11),\n",
       " array(47),\n",
       " array(8),\n",
       " array(3),\n",
       " array(82),\n",
       " array(39),\n",
       " array(105),\n",
       " array(106),\n",
       " array(59),\n",
       " array(0),\n",
       " array(31),\n",
       " array(29),\n",
       " array(14),\n",
       " array(28),\n",
       " array(13),\n",
       " array(20),\n",
       " array(15),\n",
       " array(13),\n",
       " array(107),\n",
       " array(4),\n",
       " array(73),\n",
       " array(6),\n",
       " array(35),\n",
       " array(46),\n",
       " array(5),\n",
       " array(12),\n",
       " array(17),\n",
       " array(42),\n",
       " array(75),\n",
       " array(36),\n",
       " array(89),\n",
       " array(54),\n",
       " array(106),\n",
       " array(108),\n",
       " array(109),\n",
       " array(94),\n",
       " array(4),\n",
       " array(28),\n",
       " array(19),\n",
       " array(26),\n",
       " array(37),\n",
       " array(36),\n",
       " array(10),\n",
       " array(27),\n",
       " array(1),\n",
       " array(73),\n",
       " array(26),\n",
       " array(26),\n",
       " array(24),\n",
       " array(110),\n",
       " array(29),\n",
       " array(5),\n",
       " array(36),\n",
       " array(16),\n",
       " array(4),\n",
       " array(33),\n",
       " array(35),\n",
       " array(47),\n",
       " array(46),\n",
       " array(22),\n",
       " array(59),\n",
       " array(39),\n",
       " array(16),\n",
       " array(32),\n",
       " array(74),\n",
       " array(26),\n",
       " array(111),\n",
       " array(26),\n",
       " array(112),\n",
       " array(45),\n",
       " array(50),\n",
       " array(113),\n",
       " array(20),\n",
       " array(61),\n",
       " array(6),\n",
       " array(3),\n",
       " array(5),\n",
       " array(8),\n",
       " array(70),\n",
       " array(46),\n",
       " array(70),\n",
       " array(4),\n",
       " array(45),\n",
       " array(28),\n",
       " array(4),\n",
       " array(15),\n",
       " array(8),\n",
       " array(8),\n",
       " array(80),\n",
       " array(75),\n",
       " array(94),\n",
       " array(61),\n",
       " array(14),\n",
       " array(61),\n",
       " array(114),\n",
       " array(54),\n",
       " array(33),\n",
       " array(31),\n",
       " array(74),\n",
       " array(14),\n",
       " array(71),\n",
       " array(29),\n",
       " array(24),\n",
       " array(4),\n",
       " array(61),\n",
       " array(15),\n",
       " array(15),\n",
       " array(5),\n",
       " array(16),\n",
       " array(59),\n",
       " array(3),\n",
       " array(53),\n",
       " array(70),\n",
       " array(17),\n",
       " array(66),\n",
       " array(72),\n",
       " array(63),\n",
       " array(31),\n",
       " array(36),\n",
       " array(62),\n",
       " array(94),\n",
       " array(52),\n",
       " array(28),\n",
       " array(72),\n",
       " array(5),\n",
       " array(3),\n",
       " array(6),\n",
       " array(40),\n",
       " array(84),\n",
       " array(46),\n",
       " array(15),\n",
       " array(56),\n",
       " array(15),\n",
       " array(115),\n",
       " array(81),\n",
       " array(30),\n",
       " array(42),\n",
       " array(104),\n",
       " array(39),\n",
       " array(9),\n",
       " array(16),\n",
       " array(9),\n",
       " array(41),\n",
       " array(13),\n",
       " array(42),\n",
       " array(31),\n",
       " array(80),\n",
       " array(39),\n",
       " array(81),\n",
       " array(61),\n",
       " array(54),\n",
       " array(59),\n",
       " array(5),\n",
       " array(69),\n",
       " array(57),\n",
       " array(10),\n",
       " array(39),\n",
       " array(8),\n",
       " array(16),\n",
       " array(34),\n",
       " array(17),\n",
       " array(41),\n",
       " array(32),\n",
       " array(6),\n",
       " array(72),\n",
       " array(22),\n",
       " array(47),\n",
       " array(33),\n",
       " array(22),\n",
       " array(31),\n",
       " array(12),\n",
       " array(42),\n",
       " array(41),\n",
       " array(33),\n",
       " array(41),\n",
       " array(39),\n",
       " array(26),\n",
       " array(13),\n",
       " array(20),\n",
       " array(39),\n",
       " array(70),\n",
       " array(42),\n",
       " array(10),\n",
       " array(66),\n",
       " array(14),\n",
       " array(21),\n",
       " array(10),\n",
       " array(72),\n",
       " array(49),\n",
       " array(73),\n",
       " array(6),\n",
       " array(14),\n",
       " array(30),\n",
       " array(57),\n",
       " array(116),\n",
       " array(116),\n",
       " array(22),\n",
       " array(50),\n",
       " array(12),\n",
       " array(58),\n",
       " array(91),\n",
       " array(31),\n",
       " array(60),\n",
       " array(117),\n",
       " array(26),\n",
       " array(26),\n",
       " array(33),\n",
       " array(20),\n",
       " array(75),\n",
       " array(65),\n",
       " array(17),\n",
       " array(118),\n",
       " array(74),\n",
       " array(61),\n",
       " array(15),\n",
       " array(9),\n",
       " array(105),\n",
       " array(85),\n",
       " array(77),\n",
       " array(119),\n",
       " array(120),\n",
       " array(12),\n",
       " array(30),\n",
       " array(118),\n",
       " array(121),\n",
       " array(36),\n",
       " array(3),\n",
       " array(40),\n",
       " array(72),\n",
       " array(61),\n",
       " array(47),\n",
       " array(30),\n",
       " array(47),\n",
       " array(30),\n",
       " array(4),\n",
       " array(20),\n",
       " array(21),\n",
       " array(74),\n",
       " array(23),\n",
       " array(74),\n",
       " array(6),\n",
       " array(70),\n",
       " array(54),\n",
       " array(31),\n",
       " array(42),\n",
       " array(59),\n",
       " array(96),\n",
       " array(22),\n",
       " array(122),\n",
       " array(123),\n",
       " array(13),\n",
       " array(48),\n",
       " array(5),\n",
       " array(8),\n",
       " array(10),\n",
       " array(0),\n",
       " array(14),\n",
       " array(61),\n",
       " array(26),\n",
       " array(48),\n",
       " array(15),\n",
       " array(46),\n",
       " array(29),\n",
       " array(1),\n",
       " array(36),\n",
       " array(41),\n",
       " array(10),\n",
       " array(24),\n",
       " array(16),\n",
       " array(73),\n",
       " array(78),\n",
       " array(9),\n",
       " array(34),\n",
       " array(10),\n",
       " array(39),\n",
       " array(80),\n",
       " array(33),\n",
       " array(33),\n",
       " array(33),\n",
       " array(31),\n",
       " array(3),\n",
       " array(124),\n",
       " array(30),\n",
       " array(46),\n",
       " array(125),\n",
       " array(72),\n",
       " array(14),\n",
       " array(6),\n",
       " array(42),\n",
       " array(24),\n",
       " array(17),\n",
       " array(5),\n",
       " array(65),\n",
       " array(41),\n",
       " array(46),\n",
       " array(21),\n",
       " array(8),\n",
       " array(86),\n",
       " array(45),\n",
       " array(2),\n",
       " array(21),\n",
       " array(118),\n",
       " array(31),\n",
       " array(8),\n",
       " array(76),\n",
       " array(80),\n",
       " array(36),\n",
       " array(51),\n",
       " array(24),\n",
       " array(64),\n",
       " array(126),\n",
       " array(58),\n",
       " array(70),\n",
       " array(30),\n",
       " array(24),\n",
       " array(13),\n",
       " array(57),\n",
       " array(0),\n",
       " array(66),\n",
       " array(13),\n",
       " array(30),\n",
       " array(17),\n",
       " array(17),\n",
       " array(54),\n",
       " array(11),\n",
       " array(127),\n",
       " array(59),\n",
       " array(54),\n",
       " array(6),\n",
       " array(12),\n",
       " array(36),\n",
       " array(54),\n",
       " array(17),\n",
       " array(34),\n",
       " array(42),\n",
       " array(22),\n",
       " array(42),\n",
       " array(47),\n",
       " array(39),\n",
       " array(128),\n",
       " array(45),\n",
       " array(17),\n",
       " array(41),\n",
       " array(97),\n",
       " array(75),\n",
       " array(74),\n",
       " array(16),\n",
       " array(20),\n",
       " array(24),\n",
       " array(75),\n",
       " array(5),\n",
       " array(6),\n",
       " array(0),\n",
       " array(74),\n",
       " array(20),\n",
       " array(42),\n",
       " array(76),\n",
       " array(69),\n",
       " array(30),\n",
       " array(25),\n",
       " array(21),\n",
       " array(72),\n",
       " array(38),\n",
       " array(14),\n",
       " array(9),\n",
       " array(48),\n",
       " array(129),\n",
       " array(29),\n",
       " array(72),\n",
       " array(53),\n",
       " array(38),\n",
       " array(34),\n",
       " array(77),\n",
       " array(39),\n",
       " array(52),\n",
       " array(5),\n",
       " array(75),\n",
       " array(25),\n",
       " array(25),\n",
       " array(10),\n",
       " array(59),\n",
       " array(61),\n",
       " array(38),\n",
       " array(67),\n",
       " array(72),\n",
       " array(71),\n",
       " array(15),\n",
       " array(10),\n",
       " array(121),\n",
       " array(14),\n",
       " array(130),\n",
       " array(8),\n",
       " array(80),\n",
       " array(94),\n",
       " array(46),\n",
       " array(36),\n",
       " array(16),\n",
       " array(22),\n",
       " array(4),\n",
       " array(61),\n",
       " array(39),\n",
       " array(6),\n",
       " array(67),\n",
       " array(11),\n",
       " array(24),\n",
       " array(29),\n",
       " array(98),\n",
       " array(29),\n",
       " array(75),\n",
       " array(48),\n",
       " array(24),\n",
       " array(5),\n",
       " array(131),\n",
       " array(13),\n",
       " array(24),\n",
       " array(33),\n",
       " array(74),\n",
       " array(47),\n",
       " array(44),\n",
       " array(31),\n",
       " array(29),\n",
       " array(34),\n",
       " array(17),\n",
       " ...]"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448edd7b",
   "metadata": {},
   "source": [
    "## LDA (complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "809885dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000256\n",
      "20000260\n",
      "20000261\n",
      "20000263\n",
      "20000268\n",
      "20000272\n",
      "20000276\n",
      "20000280\n",
      "20000281\n",
      "20000285\n",
      "20000286\n",
      "20000288\n",
      "20000294\n",
      "20000295\n",
      "20000296\n",
      "20000303\n",
      "20000304\n",
      "20000307\n",
      "20000310\n",
      "20000311\n",
      "20000312\n",
      "20000314\n",
      "20000320\n",
      "20000325\n",
      "20000327\n",
      "20000328\n",
      "20000331\n",
      "20000333\n",
      "20000334\n",
      "20000338\n",
      "20000340\n",
      "20000342\n",
      "20000345\n",
      "20000347\n",
      "20000349\n",
      "20000351\n",
      "20000352\n",
      "20000353\n",
      "20000356\n",
      "20000361\n",
      "20000362\n",
      "20000363\n",
      "20000370\n",
      "20000372\n",
      "20000377\n",
      "20000381\n",
      "20000383\n",
      "20000384\n",
      "20000387\n",
      "20000900\n",
      "20000901\n",
      "20000903\n",
      "20000904\n",
      "20000391\n",
      "20000393\n",
      "20000395\n",
      "20000400\n",
      "20000403\n",
      "20000406\n",
      "20000407\n",
      "20000410\n",
      "20000421\n",
      "20000424\n",
      "20000426\n",
      "20000429\n",
      "20000430\n",
      "20000431\n",
      "20000434\n",
      "20000436\n",
      "20000440\n",
      "20000446\n",
      "20000450\n",
      "20000452\n",
      "20000453\n",
      "20000454\n",
      "20000455\n",
      "20000456\n",
      "20000460\n",
      "20000463\n",
      "20000464\n",
      "20000467\n",
      "20000473\n",
      "20000476\n",
      "20000477\n",
      "20000480\n",
      "20000483\n",
      "20000486\n",
      "20000488\n",
      "20000492\n",
      "20000494\n",
      "20000495\n",
      "20000496\n",
      "20000497\n",
      "20000499\n",
      "20000500\n",
      "20000502\n",
      "20000503\n",
      "20000510\n",
      "20000513\n",
      "20000004\n",
      "20000005\n",
      "20000518\n",
      "20000517\n",
      "20000008\n",
      "20000009\n",
      "20000010\n",
      "20000523\n",
      "20000012\n",
      "20000525\n",
      "20000015\n",
      "20000017\n",
      "20000529\n",
      "20000020\n",
      "20000021\n",
      "20000022\n",
      "20000026\n",
      "20000539\n",
      "20000540\n",
      "20000541\n",
      "20000542\n",
      "20000543\n",
      "20000546\n",
      "20000547\n",
      "20000036\n",
      "20000548\n",
      "20000549\n",
      "20000039\n",
      "20000040\n",
      "20000041\n",
      "20000554\n",
      "20000044\n",
      "20000047\n",
      "20000048\n",
      "20000561\n",
      "20000560\n",
      "20000049\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of samples must be more than the number of classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_148/759505616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Fit the LDA model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mnew_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdftest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdftest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAXI_ID\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtaxi_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             raise ValueError(\"The number of samples must be more \"\n\u001b[0m\u001b[1;32m    516\u001b[0m                              \"than the number of classes.\")\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of samples must be more than the number of classes."
     ]
    }
   ],
   "source": [
    "trips = []\n",
    "preds = []\n",
    "travel_preds = []\n",
    "## in_data\n",
    "for taxi_id in taxi_ids:\n",
    "    print(taxi_id)\n",
    "    if taxi_id in [20000312, 20000407, 20000510, 20000539,\n",
    "                       20000079,20000100,20000185,20000248,20000294,20000071,\n",
    "                      20000603,20000121,20000693,20000377, 20000494,20000547]:\n",
    "        continue\n",
    "    newtrain=dftrain[dftrain['TAXI_ID'] == taxi_id]\n",
    "    \n",
    "\n",
    "    ## outlier cut\n",
    "    tmpdf = newtrain\n",
    "    Q1 = tmpdf['TRAVEL_TIME'].quantile(0.25)\n",
    "    Q3 = tmpdf['TRAVEL_TIME'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = tmpdf['TRAVEL_TIME'].quantile(0.5)#Q3 + 1.5 * IQR\n",
    "\n",
    "    new_train = newtrain[newtrain.TRAVEL_TIME >= lower_bound]\n",
    "    new_train = newtrain[newtrain.TRAVEL_TIME <= upper_bound]\n",
    "\n",
    "    # upper_bound\n",
    "    #new_train = newtrain\n",
    "\n",
    "    avail_times = new_train.TRAVEL_TIME.unique()\n",
    "    n = len(avail_times)\n",
    "    range_ = list(range(n))\n",
    "    labels = dict(zip(avail_times,range_))\n",
    "    labels_rev = dict(zip(range_, avail_times))\n",
    "\n",
    "    Xtrain = []\n",
    "    ytrain = []\n",
    "\n",
    "    for row in new_train.iterrows():\n",
    "        lst = []\n",
    "        for elem in ['DAY']:#, 'WEEKDAY']:\n",
    "            lst.append(row[1][elem])\n",
    "\n",
    "        Xtrain.append(np.array(lst))\n",
    "        ytrain.append(np.array(labels[row[1]['TRAVEL_TIME']]))\n",
    "\n",
    "    X = Xtrain\n",
    "    y = ytrain\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "#     if taxi_id not in [20000312, 20000407, 20000510, 20000539,\n",
    "#                        20000079,20000100,20000185,20000248,20000294,20000071,\n",
    "#                       20000603,20000121,20000693,20000377]:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.99, random_state=42)\n",
    "    #else:\n",
    "        #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.90, random_state=42)\n",
    "    # Create an LDA classifier\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # Fit the LDA model on the training data\n",
    "    lda.fit(X_train, y_train)\n",
    "    \n",
    "    new_test = dftest[dftest.TAXI_ID == taxi_id]\n",
    "    \n",
    "    Xtest = []\n",
    "\n",
    "    for row in new_test.iterrows():\n",
    "        trips.append(row[1]['TRIP_ID'])\n",
    "        lst = []\n",
    "        for elem in ['DAY']:#, 'WEEKDAY']:\n",
    "            lst.append(row[1][elem])\n",
    "        Xtest.append(np.array(lst))\n",
    "        #ytest.append(np.array(labels[row[1]['TRAVEL_TIME']]))\n",
    "    \n",
    "    preds.append(lda.predict(Xtest))\n",
    "    for pred in preds:\n",
    "        for p in pred:\n",
    "            if p in labels_rev:\n",
    "                travel_preds.append(labels_rev[p])\n",
    "            else:\n",
    "                travel_preds.append(-1)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "6fb0cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "8deb01a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n",
      "420\n",
      "1245\n",
      "615\n",
      "285\n",
      "450\n",
      "930\n",
      "300\n",
      "570\n",
      "960\n",
      "510\n",
      "840\n",
      "420\n",
      "285\n",
      "210\n",
      "1110\n",
      "435\n",
      "735\n",
      "795\n",
      "1170\n",
      "300\n",
      "870\n",
      "1290\n",
      "675\n",
      "450\n",
      "1575\n",
      "255\n",
      "1260\n",
      "675\n",
      "1440\n",
      "900\n",
      "270\n",
      "1425\n",
      "870\n",
      "675\n",
      "1395\n",
      "1035\n",
      "1290\n",
      "900\n",
      "360\n",
      "285\n",
      "765\n",
      "375\n",
      "1425\n",
      "225\n",
      "135\n",
      "570\n",
      "1785\n",
      "1230\n",
      "375\n",
      "1110\n",
      "375\n",
      "795\n",
      "1110\n",
      "735\n",
      "360\n",
      "1110\n",
      "990\n",
      "1035\n",
      "825\n",
      "660\n",
      "405\n",
      "810\n",
      "1005\n",
      "1005\n",
      "420\n",
      "495\n",
      "870\n",
      "885\n",
      "285\n",
      "810\n",
      "555\n",
      "1155\n",
      "225\n",
      "1245\n",
      "885\n",
      "1005\n",
      "1785\n",
      "1230\n",
      "645\n",
      "1110\n",
      "1410\n",
      "1050\n",
      "1320\n",
      "825\n",
      "150\n",
      "540\n",
      "540\n",
      "225\n",
      "960\n",
      "630\n",
      "315\n",
      "825\n",
      "630\n",
      "525\n",
      "630\n",
      "420\n",
      "1350\n",
      "495\n",
      "450\n",
      "150\n",
      "735\n",
      "345\n",
      "210\n",
      "495\n",
      "720\n",
      "0\n",
      "240\n",
      "435\n",
      "1515\n",
      "945\n",
      "15\n",
      "675\n",
      "390\n",
      "465\n",
      "1350\n",
      "60\n",
      "300\n",
      "1215\n",
      "180\n",
      "615\n",
      "390\n",
      "405\n",
      "135\n",
      "885\n",
      "330\n",
      "1500\n",
      "630\n",
      "630\n",
      "660\n",
      "855\n",
      "525\n",
      "1620\n",
      "330\n",
      "240\n",
      "345\n",
      "810\n",
      "735\n",
      "900\n",
      "675\n",
      "300\n",
      "465\n",
      "375\n",
      "735\n",
      "420\n",
      "705\n",
      "1710\n",
      "525\n",
      "300\n",
      "930\n",
      "450\n",
      "795\n",
      "540\n",
      "780\n",
      "255\n",
      "1590\n",
      "1335\n",
      "1350\n",
      "855\n",
      "390\n",
      "585\n",
      "30\n",
      "870\n",
      "345\n",
      "1050\n",
      "1305\n",
      "465\n",
      "0\n",
      "960\n",
      "960\n",
      "525\n",
      "630\n",
      "780\n",
      "15\n",
      "1620\n",
      "510\n",
      "300\n",
      "675\n",
      "300\n",
      "1530\n",
      "1035\n",
      "1290\n",
      "795\n",
      "960\n",
      "465\n",
      "1365\n",
      "390\n",
      "990\n",
      "780\n",
      "1335\n",
      "255\n",
      "15\n",
      "1665\n",
      "705\n",
      "450\n",
      "1290\n",
      "1080\n",
      "585\n",
      "1635\n",
      "465\n",
      "615\n",
      "180\n",
      "420\n",
      "885\n",
      "330\n",
      "570\n",
      "225\n",
      "645\n",
      "195\n",
      "900\n",
      "870\n",
      "555\n",
      "810\n",
      "1275\n",
      "660\n",
      "540\n",
      "1110\n",
      "1485\n",
      "1080\n",
      "1455\n",
      "345\n",
      "960\n",
      "480\n",
      "960\n",
      "480\n",
      "105\n",
      "930\n",
      "1065\n",
      "360\n",
      "615\n",
      "420\n",
      "765\n",
      "405\n",
      "555\n",
      "795\n",
      "1155\n",
      "720\n",
      "510\n",
      "465\n",
      "1050\n",
      "480\n",
      "645\n",
      "1605\n",
      "420\n",
      "1620\n",
      "495\n",
      "615\n",
      "210\n",
      "1005\n",
      "1530\n",
      "810\n",
      "360\n",
      "1050\n",
      "1560\n",
      "165\n",
      "900\n",
      "150\n",
      "1065\n",
      "1050\n",
      "405\n",
      "1005\n",
      "630\n",
      "1425\n",
      "240\n",
      "1035\n",
      "915\n",
      "480\n",
      "1275\n",
      "510\n",
      "135\n",
      "465\n",
      "420\n",
      "555\n",
      "645\n",
      "1335\n",
      "495\n",
      "540\n",
      "615\n",
      "1410\n",
      "870\n",
      "615\n",
      "1050\n",
      "1095\n",
      "1665\n",
      "1185\n",
      "915\n",
      "900\n",
      "945\n",
      "0\n",
      "615\n",
      "495\n",
      "1080\n",
      "570\n",
      "420\n",
      "630\n",
      "1245\n",
      "1440\n",
      "30\n",
      "960\n",
      "255\n",
      "690\n",
      "945\n",
      "810\n",
      "1500\n",
      "660\n",
      "675\n",
      "1170\n",
      "240\n",
      "750\n",
      "570\n",
      "360\n",
      "1020\n",
      "285\n",
      "810\n",
      "435\n",
      "255\n",
      "15\n",
      "270\n",
      "1125\n",
      "975\n"
     ]
    }
   ],
   "source": [
    "dcts=dict(zip(trips, travel_preds))\n",
    "\n",
    "all_ids = list(test_data.TRIP_ID)\n",
    "\n",
    "file1 = open(\"pred.csv\", \"w\")\n",
    "n = len(all_ids)\n",
    "#line='\"TRIP_ID\",\"TRAVEL_TIME\"\\n'\n",
    "#file1.write(line)\n",
    "for i in range(n):\n",
    "    print(dcts[all_ids[i]])\n",
    "#     if i+1 != n:\n",
    "#         line = '\"' + all_ids[i] + '\",' + str(dcts[all_ids[i]]) + '\\n'\n",
    "#     else:\n",
    "#         line = '\"' + all_ids[i] + '\",'  + str(dcts[all_ids[i]])\n",
    "#     file1.write(line)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "de5cf579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1',\n",
       " 'T2',\n",
       " 'T3',\n",
       " 'T4',\n",
       " 'T5',\n",
       " 'T6',\n",
       " 'T7',\n",
       " 'T8',\n",
       " 'T9',\n",
       " 'T10',\n",
       " 'T11',\n",
       " 'T12',\n",
       " 'T13',\n",
       " 'T14',\n",
       " 'T15',\n",
       " 'T16',\n",
       " 'T17',\n",
       " 'T18',\n",
       " 'T19',\n",
       " 'T20',\n",
       " 'T21',\n",
       " 'T22',\n",
       " 'T23',\n",
       " 'T24',\n",
       " 'T25',\n",
       " 'T26',\n",
       " 'T27',\n",
       " 'T28',\n",
       " 'T29',\n",
       " 'T30',\n",
       " 'T31',\n",
       " 'T32',\n",
       " 'T33',\n",
       " 'T34',\n",
       " 'T35',\n",
       " 'T36',\n",
       " 'T37',\n",
       " 'T38',\n",
       " 'T39',\n",
       " 'T40',\n",
       " 'T41',\n",
       " 'T42',\n",
       " 'T43',\n",
       " 'T44',\n",
       " 'T45',\n",
       " 'T46',\n",
       " 'T47',\n",
       " 'T48',\n",
       " 'T49',\n",
       " 'T50',\n",
       " 'T51',\n",
       " 'T52',\n",
       " 'T53',\n",
       " 'T54',\n",
       " 'T55',\n",
       " 'T56',\n",
       " 'T57',\n",
       " 'T58',\n",
       " 'T59',\n",
       " 'T60',\n",
       " 'T61',\n",
       " 'T62',\n",
       " 'T63',\n",
       " 'T64',\n",
       " 'T65',\n",
       " 'T66',\n",
       " 'T67',\n",
       " 'T68',\n",
       " 'T69',\n",
       " 'T70',\n",
       " 'T71',\n",
       " 'T72',\n",
       " 'T73',\n",
       " 'T74',\n",
       " 'T75',\n",
       " 'T76',\n",
       " 'T77',\n",
       " 'T78',\n",
       " 'T79',\n",
       " 'T80',\n",
       " 'T81',\n",
       " 'T82',\n",
       " 'T83',\n",
       " 'T84',\n",
       " 'T85',\n",
       " 'T86',\n",
       " 'T87',\n",
       " 'T88',\n",
       " 'T90',\n",
       " 'T91',\n",
       " 'T92',\n",
       " 'T93',\n",
       " 'T94',\n",
       " 'T95',\n",
       " 'T96',\n",
       " 'T98',\n",
       " 'T99',\n",
       " 'T100',\n",
       " 'T101',\n",
       " 'T102',\n",
       " 'T103',\n",
       " 'T104',\n",
       " 'T107',\n",
       " 'T109',\n",
       " 'T110',\n",
       " 'T111',\n",
       " 'T112',\n",
       " 'T113',\n",
       " 'T114',\n",
       " 'T115',\n",
       " 'T116',\n",
       " 'T117',\n",
       " 'T118',\n",
       " 'T119',\n",
       " 'T120',\n",
       " 'T121',\n",
       " 'T122',\n",
       " 'T123',\n",
       " 'T124',\n",
       " 'T125',\n",
       " 'T126',\n",
       " 'T127',\n",
       " 'T128',\n",
       " 'T129',\n",
       " 'T130',\n",
       " 'T131',\n",
       " 'T132',\n",
       " 'T133',\n",
       " 'T134',\n",
       " 'T135',\n",
       " 'T136',\n",
       " 'T137',\n",
       " 'T138',\n",
       " 'T139',\n",
       " 'T140',\n",
       " 'T141',\n",
       " 'T142',\n",
       " 'T143',\n",
       " 'T144',\n",
       " 'T145',\n",
       " 'T146',\n",
       " 'T147',\n",
       " 'T148',\n",
       " 'T149',\n",
       " 'T151',\n",
       " 'T152',\n",
       " 'T153',\n",
       " 'T154',\n",
       " 'T155',\n",
       " 'T156',\n",
       " 'T157',\n",
       " 'T158',\n",
       " 'T159',\n",
       " 'T160',\n",
       " 'T161',\n",
       " 'T162',\n",
       " 'T163',\n",
       " 'T164',\n",
       " 'T166',\n",
       " 'T167',\n",
       " 'T168',\n",
       " 'T169',\n",
       " 'T170',\n",
       " 'T171',\n",
       " 'T172',\n",
       " 'T173',\n",
       " 'T174',\n",
       " 'T175',\n",
       " 'T176',\n",
       " 'T177',\n",
       " 'T178',\n",
       " 'T179',\n",
       " 'T180',\n",
       " 'T181',\n",
       " 'T182',\n",
       " 'T183',\n",
       " 'T184',\n",
       " 'T185',\n",
       " 'T186',\n",
       " 'T187',\n",
       " 'T188',\n",
       " 'T189',\n",
       " 'T190',\n",
       " 'T191',\n",
       " 'T192',\n",
       " 'T193',\n",
       " 'T194',\n",
       " 'T195',\n",
       " 'T196',\n",
       " 'T197',\n",
       " 'T198',\n",
       " 'T199',\n",
       " 'T200',\n",
       " 'T201',\n",
       " 'T202',\n",
       " 'T203',\n",
       " 'T204',\n",
       " 'T205',\n",
       " 'T206',\n",
       " 'T207',\n",
       " 'T208',\n",
       " 'T209',\n",
       " 'T210',\n",
       " 'T211',\n",
       " 'T212',\n",
       " 'T213',\n",
       " 'T214',\n",
       " 'T215',\n",
       " 'T216',\n",
       " 'T217',\n",
       " 'T218',\n",
       " 'T219',\n",
       " 'T220',\n",
       " 'T221',\n",
       " 'T222',\n",
       " 'T223',\n",
       " 'T224',\n",
       " 'T225',\n",
       " 'T226',\n",
       " 'T227',\n",
       " 'T228',\n",
       " 'T229',\n",
       " 'T230',\n",
       " 'T231',\n",
       " 'T232',\n",
       " 'T233',\n",
       " 'T234',\n",
       " 'T235',\n",
       " 'T236',\n",
       " 'T237',\n",
       " 'T238',\n",
       " 'T239',\n",
       " 'T240',\n",
       " 'T241',\n",
       " 'T242',\n",
       " 'T243',\n",
       " 'T244',\n",
       " 'T245',\n",
       " 'T246',\n",
       " 'T247',\n",
       " 'T248',\n",
       " 'T249',\n",
       " 'T250',\n",
       " 'T251',\n",
       " 'T252',\n",
       " 'T253',\n",
       " 'T254',\n",
       " 'T255',\n",
       " 'T256',\n",
       " 'T257',\n",
       " 'T258',\n",
       " 'T259',\n",
       " 'T260',\n",
       " 'T261',\n",
       " 'T262',\n",
       " 'T263',\n",
       " 'T264',\n",
       " 'T265',\n",
       " 'T266',\n",
       " 'T267',\n",
       " 'T268',\n",
       " 'T269',\n",
       " 'T270',\n",
       " 'T271',\n",
       " 'T272',\n",
       " 'T273',\n",
       " 'T274',\n",
       " 'T275',\n",
       " 'T276',\n",
       " 'T277',\n",
       " 'T278',\n",
       " 'T279',\n",
       " 'T280',\n",
       " 'T281',\n",
       " 'T282',\n",
       " 'T283',\n",
       " 'T284',\n",
       " 'T285',\n",
       " 'T286',\n",
       " 'T287',\n",
       " 'T288',\n",
       " 'T289',\n",
       " 'T290',\n",
       " 'T291',\n",
       " 'T292',\n",
       " 'T293',\n",
       " 'T294',\n",
       " 'T295',\n",
       " 'T296',\n",
       " 'T297',\n",
       " 'T298',\n",
       " 'T299',\n",
       " 'T300',\n",
       " 'T301',\n",
       " 'T302',\n",
       " 'T303',\n",
       " 'T304',\n",
       " 'T305',\n",
       " 'T306',\n",
       " 'T307',\n",
       " 'T308',\n",
       " 'T309',\n",
       " 'T310',\n",
       " 'T311',\n",
       " 'T312',\n",
       " 'T313',\n",
       " 'T314',\n",
       " 'T315',\n",
       " 'T316',\n",
       " 'T317',\n",
       " 'T318',\n",
       " 'T319',\n",
       " 'T320',\n",
       " 'T321',\n",
       " 'T322',\n",
       " 'T323',\n",
       " 'T324',\n",
       " 'T325',\n",
       " 'T326',\n",
       " 'T327']"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ab29d",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7fc5e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.01263537906137184\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import svm\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = svm.SVC(kernel='sigmoid')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "800e62cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  3])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "aab9d75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_rev[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e17e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c8409",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    X_train = np.array(Xtrain)\n",
    "    y_train = np.array(ytrain)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    y_train = np.reshape(y_train, (-1,1))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add input layer and first hidden layer\n",
    "    model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "    # Add additional hidden layers\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=True)\n",
    "    \n",
    "    tmp_test=dftest[dftest['TAXI_ID'] == taxi_id]\n",
    "    for row in tmp_test.iterrows():\n",
    "        trip_id = row[1]['TRIP_ID']\n",
    "        \n",
    "        lst = []\n",
    "        for elem in positive_corr_list:\n",
    "            lst.append(row[1][elem])\n",
    "            \n",
    "        #Reshape your data either using array.reshape(-1, 1) if your data has a single feature \n",
    "        #or array.reshape(1, -1) if it contains a single sample.\n",
    "        pred = model.predict(np.array(lst).reshape(1,-1))[0][0]\n",
    "        \n",
    "        travel_preds.append(pred)\n",
    "        trips_id.append(trip_id)\n",
    "        \n",
    "        print(trip_id, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "719c6cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR', 'DAY', 'HOUR', 'MIN']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c7b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 06:32:18.397916: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: the library was not initialized\n",
      "2023-05-26 06:32:18.398328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:222] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
      "2023-05-26 06:32:18.398394: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:621 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2023-05-26 06:32:18.398447: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "\t [[{{node sequential_3/dense_15/MatMul}}]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_3/dense_15/MatMul' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28476/3966855020.py\", line 26, in <module>\n      model.fit(X_train, y_train, batch_size=32, epochs=10)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential_3/dense_15/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node sequential_3/dense_15/MatMul}}]] [Op:__inference_train_function_5028]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28476/3966855020.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_3/dense_15/MatMul' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28476/3966855020.py\", line 26, in <module>\n      model.fit(X_train, y_train, batch_size=32, epochs=10)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential_3/dense_15/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node sequential_3/dense_15/MatMul}}]] [Op:__inference_train_function_5028]"
     ]
    }
   ],
   "source": [
    "X_train = np.array(Xtrain)\n",
    "y_train = np.array(ytrain)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "y_train = np.reshape(y_train, (-1,1))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer and first hidden layer\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "# Add additional hidden layers\n",
    "#model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_test=dftest[dftest['TAXI_ID'] == 20000542]\n",
    "preds = []   \n",
    "for row in tmp_test.iterrows():\n",
    "    trip_id = row[1]['TRIP_ID']\n",
    "\n",
    "    lst = []\n",
    "    for elem in positive_corr_list:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    #Reshape your data either using array.reshape(-1, 1) if your data has a single feature \n",
    "    #or array.reshape(1, -1) if it contains a single sample.\n",
    "    pred = model.predict(np.array(lst).reshape(1,-1))[0]\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e51bb22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>20000589</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>20000596</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>20000320</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>20000520</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>20000337</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674155</th>\n",
       "      <td>1388660427620000585</td>\n",
       "      <td>20000585</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674156</th>\n",
       "      <td>1404171463620000698</td>\n",
       "      <td>20000698</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674157</th>\n",
       "      <td>1404171367620000670</td>\n",
       "      <td>20000670</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674158</th>\n",
       "      <td>1404141826620000248</td>\n",
       "      <td>20000248</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674159</th>\n",
       "      <td>1404157147620000079</td>\n",
       "      <td>20000079</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1674160 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  \\\n",
       "0        1372636858620000589  20000589  2013      7    27    1     0    0   \n",
       "1        1372637303620000596  20000596  2013      7    27    1     0    8   \n",
       "2        1372636951620000320  20000320  2013      7    27    1     0    2   \n",
       "3        1372636854620000520  20000520  2013      7    27    1     0    0   \n",
       "4        1372637091620000337  20000337  2013      7    27    1     0    4   \n",
       "...                      ...       ...   ...    ...   ...  ...   ...  ...   \n",
       "1674155  1388660427620000585  20000585  2014      1     1    2    11    0   \n",
       "1674156  1404171463620000698  20000698  2014      6    27   30    23   37   \n",
       "1674157  1404171367620000670  20000670  2014      6    27   30    23   36   \n",
       "1674158  1404141826620000248  20000248  2014      6    27   30    15   23   \n",
       "1674159  1404157147620000079  20000079  2014      6    27   30    19   39   \n",
       "\n",
       "         WEEKDAY  CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  \\\n",
       "0              0            0            0            1            1   \n",
       "1              0            0            1            0            1   \n",
       "2              0            0            0            1            1   \n",
       "3              0            0            0            1            1   \n",
       "4              0            0            0            1            1   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1674155        3            0            0            1            1   \n",
       "1674156        0            0            0            1            1   \n",
       "1674157        0            0            0            1            1   \n",
       "1674158        0            0            1            0            1   \n",
       "1674159        0            0            1            0            1   \n",
       "\n",
       "         ORIGIN_STAND  MISSING_DATA  TRAVEL_TIME  \n",
       "0                   1             0        330.0  \n",
       "1                   1             0        270.0  \n",
       "2                   1             0        960.0  \n",
       "3                   1             0        630.0  \n",
       "4                   1             0        420.0  \n",
       "...               ...           ...          ...  \n",
       "1674155             1             0       2895.0  \n",
       "1674156             1             0        465.0  \n",
       "1674157             1             0        435.0  \n",
       "1674158             1             0        915.0  \n",
       "1674159             1             0        390.0  \n",
       "\n",
       "[1674160 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d47df10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>A</td>\n",
       "      <td>70885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000430</td>\n",
       "      <td>1419171485</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000020</td>\n",
       "      <td>1419170802</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000207</td>\n",
       "      <td>1419172121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>A</td>\n",
       "      <td>76232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000667</td>\n",
       "      <td>1419171980</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>A</td>\n",
       "      <td>31208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000255</td>\n",
       "      <td>1419171420</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0        T1         B          NaN          15.0  20000542  1408039037   \n",
       "1        T2         B          NaN          57.0  20000108  1408038611   \n",
       "2        T3         B          NaN          15.0  20000370  1408038568   \n",
       "3        T4         B          NaN          53.0  20000492  1408039090   \n",
       "4        T5         B          NaN          18.0  20000621  1408039177   \n",
       "..      ...       ...          ...           ...       ...         ...   \n",
       "315    T323         A      70885.0           NaN  20000430  1419171485   \n",
       "316    T324         B          NaN          53.0  20000020  1419170802   \n",
       "317    T325         C          NaN           NaN  20000207  1419172121   \n",
       "318    T326         A      76232.0           NaN  20000667  1419171980   \n",
       "319    T327         A      31208.0           NaN  20000255  1419171420   \n",
       "\n",
       "    DAY_TYPE  MISSING_DATA  \n",
       "0          A         False  \n",
       "1          A         False  \n",
       "2          A         False  \n",
       "3          A         False  \n",
       "4          A         False  \n",
       "..       ...           ...  \n",
       "315        A         False  \n",
       "316        A         False  \n",
       "317        A         False  \n",
       "318        A         False  \n",
       "319        A         False  \n",
       "\n",
       "[320 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5034c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = pd.read_csv('train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70ed6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c32fa1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3720       1372702836620000080\n",
       "21385      1373025987620000601\n",
       "33350      1373210896620000598\n",
       "51966      1373551710620000014\n",
       "76596      1374014097620000337\n",
       "                  ...         \n",
       "1647665    1403115272620000066\n",
       "1660290    1403323491620000600\n",
       "1665292    1403407180620000242\n",
       "1684729    1403716904620000337\n",
       "1705655    1404093316620000307\n",
       "Name: TRIP_ID, Length: 81, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TRIP_ID'][df.duplicated('TRIP_ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbc0bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan in df['TRIP_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7782bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan in [np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a638c6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>LEN</th>\n",
       "      <th>YR</th>\n",
       "      <th>MON</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HR</th>\n",
       "      <th>WK</th>\n",
       "      <th>DESCR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33228</th>\n",
       "      <td>33228</td>\n",
       "      <td>1373210896620000598</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000598</td>\n",
       "      <td>1373210896</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610885,41.145525]]</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>So Bento</td>\n",
       "      <td>41.145719</td>\n",
       "      <td>-8.610707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33350</th>\n",
       "      <td>33350</td>\n",
       "      <td>1373210896620000598</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000598</td>\n",
       "      <td>1373210896</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610813,41.14548],[-8.610732,41.145579],[-...</td>\n",
       "      <td>270</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "33228       33228  1373210896620000598         B          NaN          57.0   \n",
       "33350       33350  1373210896620000598         C          NaN           NaN   \n",
       "\n",
       "        TAXI_ID   TIMESTAMP  MISSING_DATA  \\\n",
       "33228  20000598  1373210896         False   \n",
       "33350  20000598  1373210896         False   \n",
       "\n",
       "                                                POLYLINE  LEN    YR  MON  DAY  \\\n",
       "33228                            [[-8.610885,41.145525]]    0  2013    7    7   \n",
       "33350  [[-8.610813,41.14548],[-8.610732,41.145579],[-...  270  2013    7    7   \n",
       "\n",
       "       HR  WK      DESCR        LAT       LON  \n",
       "33228  15   6  So Bento  41.145719 -8.610707  \n",
       "33350  15   6        NaN        NaN       NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['TRIP_ID']==1373210896620000598]#['TAXI_ID'].reset_index().iloc[0]['TAXI_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39d071cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TRIP_ID, TAXI_ID, YEAR, MONTH, WEEK, DAY, HOUR, MIN, WEEKDAY, CALL_TYPE_A, CALL_TYPE_B, CALL_TYPE_C, ORIGIN_CALL, ORIGIN_STAND, MISSING_DATA]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest['TAXI_ID']==20000598]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "706b69b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20000598 in test_data['TAXI_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcfea46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['TRIP_ID'][df.duplicated('TRIP_ID')]:\n",
    "    if i in test_data['TAXI_ID']:\n",
    "        print(i, df[df['TRIP_ID']==i]['TAXI_ID'].reset_index().iloc[0]['TAXI_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc17364",
   "metadata": {},
   "source": [
    "- There are 81 trip_id that is duplicated, and the taxi_id associated with them is not found in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f78b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = dftrain[~dftrain['TRIP_ID'].isin(dftrain['TRIP_ID'][dftrain.duplicated('TRIP_ID')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57c5ca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674139"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "200856b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>20000589</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>20000596</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>20000320</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>20000520</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>20000337</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674155</th>\n",
       "      <td>1388660427620000585</td>\n",
       "      <td>20000585</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674156</th>\n",
       "      <td>1404171463620000698</td>\n",
       "      <td>20000698</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674157</th>\n",
       "      <td>1404171367620000670</td>\n",
       "      <td>20000670</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674158</th>\n",
       "      <td>1404141826620000248</td>\n",
       "      <td>20000248</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674159</th>\n",
       "      <td>1404157147620000079</td>\n",
       "      <td>20000079</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1674160 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  \\\n",
       "0        1372636858620000589  20000589  2013      7    27    1     0    0   \n",
       "1        1372637303620000596  20000596  2013      7    27    1     0    8   \n",
       "2        1372636951620000320  20000320  2013      7    27    1     0    2   \n",
       "3        1372636854620000520  20000520  2013      7    27    1     0    0   \n",
       "4        1372637091620000337  20000337  2013      7    27    1     0    4   \n",
       "...                      ...       ...   ...    ...   ...  ...   ...  ...   \n",
       "1674155  1388660427620000585  20000585  2014      1     1    2    11    0   \n",
       "1674156  1404171463620000698  20000698  2014      6    27   30    23   37   \n",
       "1674157  1404171367620000670  20000670  2014      6    27   30    23   36   \n",
       "1674158  1404141826620000248  20000248  2014      6    27   30    15   23   \n",
       "1674159  1404157147620000079  20000079  2014      6    27   30    19   39   \n",
       "\n",
       "         WEEKDAY  CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  \\\n",
       "0              0            0            0            1            1   \n",
       "1              0            0            1            0            1   \n",
       "2              0            0            0            1            1   \n",
       "3              0            0            0            1            1   \n",
       "4              0            0            0            1            1   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1674155        3            0            0            1            1   \n",
       "1674156        0            0            0            1            1   \n",
       "1674157        0            0            0            1            1   \n",
       "1674158        0            0            1            0            1   \n",
       "1674159        0            0            1            0            1   \n",
       "\n",
       "         ORIGIN_STAND  MISSING_DATA  TRAVEL_TIME  \n",
       "0                   1             0        330.0  \n",
       "1                   1             0        270.0  \n",
       "2                   1             0        960.0  \n",
       "3                   1             0        630.0  \n",
       "4                   1             0        420.0  \n",
       "...               ...           ...          ...  \n",
       "1674155             1             0       2895.0  \n",
       "1674156             1             0        465.0  \n",
       "1674157             1             0        435.0  \n",
       "1674158             1             0        915.0  \n",
       "1674159             1             0        390.0  \n",
       "\n",
       "[1674160 rows x 16 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75c83511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>A</td>\n",
       "      <td>70885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000430</td>\n",
       "      <td>1419171485</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000020</td>\n",
       "      <td>1419170802</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000207</td>\n",
       "      <td>1419172121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>A</td>\n",
       "      <td>76232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000667</td>\n",
       "      <td>1419171980</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>A</td>\n",
       "      <td>31208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000255</td>\n",
       "      <td>1419171420</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0        T1         B          NaN          15.0  20000542  1408039037   \n",
       "1        T2         B          NaN          57.0  20000108  1408038611   \n",
       "2        T3         B          NaN          15.0  20000370  1408038568   \n",
       "3        T4         B          NaN          53.0  20000492  1408039090   \n",
       "4        T5         B          NaN          18.0  20000621  1408039177   \n",
       "..      ...       ...          ...           ...       ...         ...   \n",
       "315    T323         A      70885.0           NaN  20000430  1419171485   \n",
       "316    T324         B          NaN          53.0  20000020  1419170802   \n",
       "317    T325         C          NaN           NaN  20000207  1419172121   \n",
       "318    T326         A      76232.0           NaN  20000667  1419171980   \n",
       "319    T327         A      31208.0           NaN  20000255  1419171420   \n",
       "\n",
       "    DAY_TYPE  MISSING_DATA  \n",
       "0          A         False  \n",
       "1          A         False  \n",
       "2          A         False  \n",
       "3          A         False  \n",
       "4          A         False  \n",
       "..       ...           ...  \n",
       "315        A         False  \n",
       "316        A         False  \n",
       "317        A         False  \n",
       "318        A         False  \n",
       "319        A         False  \n",
       "\n",
       "[320 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "666d3017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as st\n",
    "st.median(df[df['ORIGIN_STAND']==15]['LEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "077fa223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>20000108</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>20000370</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>20000492</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>20000621</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>T298</td>\n",
       "      <td>20000158</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>T303</td>\n",
       "      <td>20000067</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>T305</td>\n",
       "      <td>20000320</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>T318</td>\n",
       "      <td>20000325</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>20000020</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "0        T1  20000542  2014      8    33   14    17   57        3   \n",
       "1        T2  20000108  2014      8    33   14    17   50        3   \n",
       "2        T3  20000370  2014      8    33   14    17   49        3   \n",
       "3        T4  20000492  2014      8    33   14    17   58        3   \n",
       "4        T5  20000621  2014      8    33   14    17   59        3   \n",
       "..      ...       ...   ...    ...   ...  ...   ...  ...      ...   \n",
       "290    T298  20000158  2014     12    51   21    14   26        6   \n",
       "295    T303  20000067  2014     12    51   21    14   29        6   \n",
       "297    T305  20000320  2014     12    51   21    14   22        6   \n",
       "310    T318  20000325  2014     12    51   21    14   25        6   \n",
       "316    T324  20000020  2014     12    51   21    14    6        6   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0              0            1            0            1             1   \n",
       "1              0            1            0            1             1   \n",
       "2              0            1            0            1             1   \n",
       "3              0            1            0            1             1   \n",
       "4              0            1            0            1             1   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "290            0            1            0            1             1   \n",
       "295            0            1            0            1             1   \n",
       "297            0            1            0            1             1   \n",
       "310            0            1            0            1             1   \n",
       "316            0            1            0            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "290             0  \n",
       "295             0  \n",
       "297             0  \n",
       "310             0  \n",
       "316             0  \n",
       "\n",
       "[123 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest['CALL_TYPE_B']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b5a1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['TAXI_ID'].isin(dftest['TAXI_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "61d3fa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='MON', ylabel='Count'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered = df_filtered[df_filtered.LEN==150]\n",
    "sns.histplot(df_filtered.MON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "96d95f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRIP_ID               T1\n",
       "TAXI_ID         20000542\n",
       "YEAR                2014\n",
       "MONTH                  8\n",
       "WEEK                  33\n",
       "DAY                   14\n",
       "HOUR                  17\n",
       "MIN                   57\n",
       "WEEKDAY                3\n",
       "CALL_TYPE_A            0\n",
       "CALL_TYPE_B            1\n",
       "CALL_TYPE_C            0\n",
       "ORIGIN_CALL            1\n",
       "ORIGIN_STAND           1\n",
       "MISSING_DATA           0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a79130aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TRAVEL_TIME'>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(dftrain[(dftrain.TAXI_ID==20000542) & (dftrain.WEEK==33)]['TRAVEL_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "778b6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570.0\n"
     ]
    }
   ],
   "source": [
    "# taxis=list(dftest['TAXI_ID'])\n",
    "# weeks=list(dftest['WEEK'])\n",
    "# for i in [20000434]:\n",
    "# taxi=taxis[i]\n",
    "# week=weeks[i]\n",
    "tmpdf = dftrain[(dftrain.TAXI_ID==20000434) & (dftrain.WEEK==41)]\n",
    "Q1 = tmpdf['TRAVEL_TIME'].quantile(0.25)\n",
    "Q3 = tmpdf['TRAVEL_TIME'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the DataFrame to remove outliers\n",
    "df_filtered = tmpdf[(tmpdf['TRAVEL_TIME'] >= lower_bound) \n",
    "                    & (tmpdf['TRAVEL_TIME'] <= upper_bound)]\n",
    "if len(df_filtered) > 0:\n",
    "    print(st.mode(df_filtered['TRAVEL_TIME']))\n",
    "else:\n",
    "    print('skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dc179605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.mode(tmpdf['TRAVEL_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e581495b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150 in list(df_filtered['TRAVEL_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "38849f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      20000542\n",
       "1      20000108\n",
       "2      20000370\n",
       "3      20000492\n",
       "4      20000621\n",
       "         ...   \n",
       "315    20000430\n",
       "316    20000020\n",
       "317    20000207\n",
       "318    20000667\n",
       "319    20000255\n",
       "Name: TAXI_ID, Length: 320, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['TAXI_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "456f0718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>T158</td>\n",
       "      <td>20000698</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>T160</td>\n",
       "      <td>20000657</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>T164</td>\n",
       "      <td>20000410</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>T168</td>\n",
       "      <td>20000180</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>T170</td>\n",
       "      <td>20000128</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>T172</td>\n",
       "      <td>20000054</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>T175</td>\n",
       "      <td>20000453</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>T185</td>\n",
       "      <td>20000166</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>T186</td>\n",
       "      <td>20000377</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>T187</td>\n",
       "      <td>20000146</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>T190</td>\n",
       "      <td>20000653</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>T194</td>\n",
       "      <td>20000349</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>T198</td>\n",
       "      <td>20000347</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>T200</td>\n",
       "      <td>20000502</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>T209</td>\n",
       "      <td>20000312</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>T215</td>\n",
       "      <td>20000450</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>T216</td>\n",
       "      <td>20000632</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>T223</td>\n",
       "      <td>20000067</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>T230</td>\n",
       "      <td>20000434</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>T235</td>\n",
       "      <td>20000454</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "151    T158  20000698  2014     10    41    6    17   42        0   \n",
       "153    T160  20000657  2014     10    41    6    17   42        0   \n",
       "157    T164  20000410  2014     10    41    6    17   43        0   \n",
       "160    T168  20000180  2014     10    41    6    17   36        0   \n",
       "162    T170  20000128  2014     10    41    6    17   38        0   \n",
       "164    T172  20000054  2014     10    41    6    17   40        0   \n",
       "167    T175  20000453  2014     10    41    6    17   40        0   \n",
       "177    T185  20000166  2014     10    41    6    17   43        0   \n",
       "178    T186  20000377  2014     10    41    6    17   30        0   \n",
       "179    T187  20000146  2014     10    41    6    17   38        0   \n",
       "182    T190  20000653  2014     10    41    6    17   37        0   \n",
       "186    T194  20000349  2014     10    41    6    17   38        0   \n",
       "190    T198  20000347  2014     10    41    6    17   39        0   \n",
       "192    T200  20000502  2014     10    41    6    17   41        0   \n",
       "201    T209  20000312  2014     10    41    6    17   42        0   \n",
       "207    T215  20000450  2014     10    41    6    17   43        0   \n",
       "208    T216  20000632  2014     10    41    6    17   42        0   \n",
       "215    T223  20000067  2014     10    41    6    17   16        0   \n",
       "222    T230  20000434  2014     10    41    6    16   14        0   \n",
       "227    T235  20000454  2014     10    41    6    17   39        0   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "151            1            0            0            1             1   \n",
       "153            1            0            0            1             1   \n",
       "157            1            0            0            1             1   \n",
       "160            1            0            0            1             1   \n",
       "162            1            0            0            1             1   \n",
       "164            1            0            0            1             1   \n",
       "167            1            0            0            1             1   \n",
       "177            1            0            0            1             1   \n",
       "178            1            0            0            1             1   \n",
       "179            1            0            0            1             1   \n",
       "182            1            0            0            1             1   \n",
       "186            1            0            0            1             1   \n",
       "190            1            0            0            1             1   \n",
       "192            1            0            0            1             1   \n",
       "201            1            0            0            1             1   \n",
       "207            1            0            0            1             1   \n",
       "208            1            0            0            1             1   \n",
       "215            1            0            0            1             1   \n",
       "222            1            0            0            1             1   \n",
       "227            1            0            0            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "151             0  \n",
       "153             0  \n",
       "157             0  \n",
       "160             0  \n",
       "162             0  \n",
       "164             0  \n",
       "167             0  \n",
       "177             0  \n",
       "178             0  \n",
       "179             0  \n",
       "182             0  \n",
       "186             0  \n",
       "190             0  \n",
       "192             0  \n",
       "201             0  \n",
       "207             0  \n",
       "208             0  \n",
       "215             0  \n",
       "222             0  \n",
       "227             0  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[(dftest['MONTH']==10)&(dftest['DAY']<=6) &(dftest['DAY']>=5)&(dftest['CALL_TYPE_A']==1)]#['TAXI_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bf84b70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5460.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dftrain.TRAVEL_TIME,99.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "bf1794e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>T174</td>\n",
       "      <td>20000624</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "166    T174  20000624  2014     10    41    6    16   12        0   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "166            0            0            1            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "166             0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest['TRIP_ID']=='T174']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7d1bf0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>20000108</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>20000370</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>20000492</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>20000621</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>20000430</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>20000020</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>20000207</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>20000667</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>20000255</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "0        T1  20000542  2014      8    33   14    17   57        3   \n",
       "1        T2  20000108  2014      8    33   14    17   50        3   \n",
       "2        T3  20000370  2014      8    33   14    17   49        3   \n",
       "3        T4  20000492  2014      8    33   14    17   58        3   \n",
       "4        T5  20000621  2014      8    33   14    17   59        3   \n",
       "..      ...       ...   ...    ...   ...  ...   ...  ...      ...   \n",
       "315    T323  20000430  2014     12    51   21    14   18        6   \n",
       "316    T324  20000020  2014     12    51   21    14    6        6   \n",
       "317    T325  20000207  2014     12    51   21    14   28        6   \n",
       "318    T326  20000667  2014     12    51   21    14   26        6   \n",
       "319    T327  20000255  2014     12    51   21    14   17        6   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0              0            1            0            1             1   \n",
       "1              0            1            0            1             1   \n",
       "2              0            1            0            1             1   \n",
       "3              0            1            0            1             1   \n",
       "4              0            1            0            1             1   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "315            1            0            0            1             1   \n",
       "316            0            1            0            1             1   \n",
       "317            0            0            1            1             1   \n",
       "318            1            0            0            1             1   \n",
       "319            1            0            0            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "315             0  \n",
       "316             0  \n",
       "317             0  \n",
       "318             0  \n",
       "319             0  \n",
       "\n",
       "[320 rows x 15 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3cb8833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(dftest['TAXI_ID']):\n",
    "    if i not in list(dftrain['TAXI_ID']):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1016a7ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip= 1 ; taxi_id= 20000542 ; min= 15.0 max= 17040.0 ; mode= 480.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1965.0 ; 99.5th percentile= 3780.0\n",
      "\n",
      "trip= 2 ; taxi_id= 20000108 ; min= 15.0 max= 14880.0 ; mode= 600.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2869.499999999989\n",
      "\n",
      "trip= 3 ; taxi_id= 20000370 ; min= 15.0 max= 13860.0 ; mode= 405.0 ; median= 555.0 ; 25th percentile= 390.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1560.0 ; 99.5th percentile= 2229.2999999999847\n",
      "\n",
      "trip= 4 ; taxi_id= 20000492 ; min= 15.0 max= 10650.0 ; mode= 390.0 ; median= 540.0 ; 25th percentile= 375.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1665.0 ; 99.5th percentile= 2840.625\n",
      "\n",
      "trip= 5 ; taxi_id= 20000621 ; min= 15.0 max= 10650.0 ; mode= 435.0 ; median= 540.0 ; 25th percentile= 375.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1605.0 ; 99.5th percentile= 2665.8750000000055\n",
      "\n",
      "trip= 6 ; taxi_id= 20000607 ; min= 15.0 max= 15000.0 ; mode= 645.0 ; median= 795.0 ; 25th percentile= 540.0 ; 75th percentile= 1260.0 ; 97.5th percentile= 5385.0 ; 99.5th percentile= 8603.85000000001\n",
      "\n",
      "trip= 7 ; taxi_id= 20000310 ; min= 15.0 max= 18405.0 ; mode= 405.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1695.0 ; 99.5th percentile= 2487.0000000000164\n",
      "\n",
      "trip= 8 ; taxi_id= 20000619 ; min= 15.0 max= 10245.0 ; mode= 435.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1967.9999999999973 ; 99.5th percentile= 3616.7999999999984\n",
      "\n",
      "trip= 9 ; taxi_id= 20000503 ; min= 15.0 max= 8595.0 ; mode= 390.0 ; median= 525.0 ; 25th percentile= 345.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2431.199999999999\n",
      "\n",
      "trip= 10 ; taxi_id= 20000327 ; min= 15.0 max= 5970.0 ; mode= 585.0 ; median= 690.0 ; 25th percentile= 487.5 ; 75th percentile= 900.0 ; 97.5th percentile= 1761.7499999999973 ; 99.5th percentile= 3136.350000000002\n",
      "\n",
      "trip= 11 ; taxi_id= 20000664 ; min= 15.0 max= 8670.0 ; mode= 510.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 2145.0 ; 99.5th percentile= 3688.799999999974\n",
      "\n",
      "trip= 12 ; taxi_id= 20000160 ; min= 15.0 max= 14610.0 ; mode= 525.0 ; median= 630.0 ; 25th percentile= 450.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1755.0 ; 99.5th percentile= 3129.9749999999995\n",
      "\n",
      "trip= 13 ; taxi_id= 20000017 ; min= 15.0 max= 6495.0 ; mode= 330.0 ; median= 570.0 ; 25th percentile= 375.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2916.7499999999973\n",
      "\n",
      "trip= 14 ; taxi_id= 20000312 ; min= 15.0 max= 15675.0 ; mode= 840.0 ; median= 1005.0 ; 25th percentile= 570.0 ; 75th percentile= 1710.0 ; 97.5th percentile= 4319.249999999991 ; 99.5th percentile= 7246.500000000033\n",
      "\n",
      "trip= 15 ; taxi_id= 20000497 ; min= 15.0 max= 19215.0 ; mode= 525.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1800.0 ; 99.5th percentile= 3577.3499999999967\n",
      "\n",
      "trip= 16 ; taxi_id= 20000440 ; min= 15.0 max= 7740.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 881.25 ; 97.5th percentile= 2010.0 ; 99.5th percentile= 3721.649999999995\n",
      "\n",
      "trip= 17 ; taxi_id= 20000467 ; min= 15.0 max= 5355.0 ; mode= 570.0 ; median= 645.0 ; 25th percentile= 465.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1635.0 ; 99.5th percentile= 2410.4250000000025\n",
      "\n",
      "trip= 18 ; taxi_id= 20000338 ; min= 15.0 max= 25035.0 ; mode= 330.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 915.0 ; 97.5th percentile= 2624.2499999999973 ; 99.5th percentile= 4796.550000000007\n",
      "\n",
      "trip= 19 ; taxi_id= 20000101 ; min= 15.0 max= 10950.0 ; mode= 645.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 2127.749999999992 ; 99.5th percentile= 3695.5499999999984\n",
      "\n",
      "trip= 20 ; taxi_id= 20000523 ; min= 15.0 max= 11505.0 ; mode= 555.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1998.75 ; 99.5th percentile= 3502.125000000019\n",
      "\n",
      "trip= 21 ; taxi_id= 20000460 ; min= 15.0 max= 4080.0 ; mode= 555.0 ; median= 645.0 ; 25th percentile= 465.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2199.2999999999984\n",
      "\n",
      "trip= 22 ; taxi_id= 20000199 ; min= 15.0 max= 12030.0 ; mode= 480.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3154.125000000008\n",
      "\n",
      "trip= 23 ; taxi_id= 20000480 ; min= 15.0 max= 6630.0 ; mode= 750.0 ; median= 660.0 ; 25th percentile= 435.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1742.6250000000027 ; 99.5th percentile= 2760.0\n",
      "\n",
      "trip= 24 ; taxi_id= 20000250 ; min= 15.0 max= 33645.0 ; mode= 510.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 2116.875 ; 99.5th percentile= 4908.75\n",
      "\n",
      "trip= 25 ; taxi_id= 20000903 ; min= 15.0 max= 9270.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2055.0 ; 99.5th percentile= 3484.1999999999825\n",
      "\n",
      "trip= 26 ; taxi_id= 20000247 ; min= 15.0 max= 14655.0 ; mode= 510.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2191.4999999999986 ; 99.5th percentile= 4398.900000000003\n",
      "\n",
      "trip= 27 ; taxi_id= 20000263 ; min= 15.0 max= 34845.0 ; mode= 450.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1635.0 ; 99.5th percentile= 2790.0\n",
      "\n",
      "trip= 28 ; taxi_id= 20000500 ; min= 15.0 max= 23115.0 ; mode= 660.0 ; median= 720.0 ; 25th percentile= 525.0 ; 75th percentile= 960.0 ; 97.5th percentile= 1891.1249999999973 ; 99.5th percentile= 3392.250000000008\n",
      "\n",
      "trip= 29 ; taxi_id= 20000617 ; min= 15.0 max= 11445.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 945.0 ; 97.5th percentile= 2040.0 ; 99.5th percentile= 3132.2999999999956\n",
      "\n",
      "trip= 30 ; taxi_id= 20000288 ; min= 15.0 max= 8775.0 ; mode= 465.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 930.0 ; 97.5th percentile= 2040.0 ; 99.5th percentile= 2762.550000000001\n",
      "\n",
      "trip= 31 ; taxi_id= 20000268 ; min= 15.0 max= 23490.0 ; mode= 495.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1605.0 ; 99.5th percentile= 2741.849999999986\n",
      "\n",
      "trip= 32 ; taxi_id= 20000495 ; min= 15.0 max= 9090.0 ; mode= 495.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1905.0 ; 99.5th percentile= 2891.25\n",
      "\n",
      "trip= 33 ; taxi_id= 20000328 ; min= 15.0 max= 8295.0 ; mode= 465.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1695.0 ; 99.5th percentile= 2477.4000000000115\n",
      "\n",
      "trip= 34 ; taxi_id= 20000129 ; min= 15.0 max= 12690.0 ; mode= 735.0 ; median= 720.0 ; 25th percentile= 525.0 ; 75th percentile= 1005.0 ; 97.5th percentile= 2025.0 ; 99.5th percentile= 3097.1999999999935\n",
      "\n",
      "trip= 35 ; taxi_id= 20000434 ; min= 15.0 max= 15150.0 ; mode= 405.0 ; median= 690.0 ; 25th percentile= 480.0 ; 75th percentile= 1050.0 ; 97.5th percentile= 2201.25 ; 99.5th percentile= 3915.0\n",
      "\n",
      "trip= 36 ; taxi_id= 20000381 ; min= 15.0 max= 9855.0 ; mode= 465.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1965.0 ; 99.5th percentile= 3255.900000000006\n",
      "\n",
      "trip= 37 ; taxi_id= 20000159 ; min= 15.0 max= 12720.0 ; mode= 525.0 ; median= 765.0 ; 25th percentile= 525.0 ; 75th percentile= 1035.0 ; 97.5th percentile= 2955.0 ; 99.5th percentile= 6121.724999999997\n",
      "\n",
      "trip= 38 ; taxi_id= 20000048 ; min= 15.0 max= 8850.0 ; mode= 570.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2175.0 ; 99.5th percentile= 3375.3000000000065\n",
      "\n",
      "trip= 39 ; taxi_id= 20000008 ; min= 15.0 max= 18195.0 ; mode= 570.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1738.4999999999945 ; 99.5th percentile= 2805.0\n",
      "\n",
      "trip= 40 ; taxi_id= 20000285 ; min= 15.0 max= 10365.0 ; mode= 540.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1933.125 ; 99.5th percentile= 3030.0\n",
      "\n",
      "trip= 41 ; taxi_id= 20000546 ; min= 15.0 max= 12120.0 ; mode= 435.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1692.3749999999973 ; 99.5th percentile= 2528.475000000001\n",
      "\n",
      "trip= 42 ; taxi_id= 20000353 ; min= 15.0 max= 6765.0 ; mode= 435.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2825.9999999999945\n",
      "\n",
      "trip= 43 ; taxi_id= 20000569 ; min= 15.0 max= 14925.0 ; mode= 510.0 ; median= 630.0 ; 25th percentile= 405.0 ; 75th percentile= 960.0 ; 97.5th percentile= 3497.2500000000014 ; 99.5th percentile= 7180.200000000004\n",
      "\n",
      "trip= 44 ; taxi_id= 20000384 ; min= 15.0 max= 22350.0 ; mode= 495.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1875.0 ; 99.5th percentile= 2936.5500000000065\n",
      "\n",
      "trip= 45 ; taxi_id= 20000653 ; min= 15.0 max= 10155.0 ; mode= 465.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2727.449999999999\n",
      "\n",
      "trip= 46 ; taxi_id= 20000540 ; min= 15.0 max= 21870.0 ; mode= 405.0 ; median= 645.0 ; 25th percentile= 375.0 ; 75th percentile= 1065.0 ; 97.5th percentile= 2485.874999999992 ; 99.5th percentile= 5414.174999999996\n",
      "\n",
      "trip= 47 ; taxi_id= 20000280 ; min= 15.0 max= 7380.0 ; mode= 465.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1515.0 ; 99.5th percentile= 2308.500000000008\n",
      "\n",
      "trip= 48 ; taxi_id= 20000177 ; min= 15.0 max= 20625.0 ; mode= 585.0 ; median= 705.0 ; 25th percentile= 495.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2820.0\n",
      "\n",
      "trip= 49 ; taxi_id= 20000085 ; min= 15.0 max= 20250.0 ; mode= 735.0 ; median= 765.0 ; 25th percentile= 525.0 ; 75th percentile= 1095.0 ; 97.5th percentile= 2955.3750000000014 ; 99.5th percentile= 5892.5250000000215\n",
      "\n",
      "trip= 50 ; taxi_id= 20000022 ; min= 15.0 max= 9060.0 ; mode= 540.0 ; median= 600.0 ; 25th percentile= 435.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2507.7000000000044\n",
      "\n",
      "trip= 51 ; taxi_id= 20000311 ; min= 15.0 max= 8985.0 ; mode= 840.0 ; median= 750.0 ; 25th percentile= 525.0 ; 75th percentile= 1050.0 ; 97.5th percentile= 2325.0 ; 99.5th percentile= 3627.2999999999956\n",
      "\n",
      "trip= 52 ; taxi_id= 20000294 ; min= 15.0 max= 12660.0 ; mode= 540.0 ; median= 705.0 ; 25th percentile= 495.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2318.249999999999 ; 99.5th percentile= 4897.65\n",
      "\n",
      "trip= 53 ; taxi_id= 20000081 ; min= 15.0 max= 27570.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1999.1249999999945 ; 99.5th percentile= 5368.649999999998\n",
      "\n",
      "trip= 54 ; taxi_id= 20000561 ; min= 15.0 max= 8100.0 ; mode= 495.0 ; median= 630.0 ; 25th percentile= 450.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 3247.3499999999967\n",
      "\n",
      "trip= 55 ; taxi_id= 20000178 ; min= 15.0 max= 14025.0 ; mode= 480.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1905.0 ; 99.5th percentile= 2741.999999999989\n",
      "\n",
      "trip= 56 ; taxi_id= 20000255 ; min= 15.0 max= 6660.0 ; mode= 465.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2310.0\n",
      "\n",
      "trip= 57 ; taxi_id= 20000547 ; min= 15.0 max= 3705.0 ; mode= 450.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 795.0 ; 97.5th percentile= 1606.1249999999973 ; 99.5th percentile= 2229.4500000000016\n",
      "\n",
      "trip= 58 ; taxi_id= 20000603 ; min= 15.0 max= 7755.0 ; mode= 510.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 881.25 ; 97.5th percentile= 1774.1250000000014 ; 99.5th percentile= 2711.475000000005\n",
      "\n",
      "trip= 59 ; taxi_id= 20000668 ; min= 15.0 max= 18945.0 ; mode= 540.0 ; median= 795.0 ; 25th percentile= 540.0 ; 75th percentile= 1185.0 ; 97.5th percentile= 3915.0 ; 99.5th percentile= 8324.250000000025\n",
      "\n",
      "trip= 60 ; taxi_id= 20000044 ; min= 15.0 max= 9015.0 ; mode= 600.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1789.499999999996 ; 99.5th percentile= 3639.899999999998\n",
      "\n",
      "trip= 61 ; taxi_id= 20000041 ; min= 15.0 max= 18315.0 ; mode= 675.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1875.0 ; 99.5th percentile= 3210.299999999993\n",
      "\n",
      "trip= 62 ; taxi_id= 20000245 ; min= 15.0 max= 9390.0 ; mode= 555.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1605.0 ; 99.5th percentile= 2840.7000000000016\n",
      "\n",
      "trip= 63 ; taxi_id= 20000649 ; min= 15.0 max= 8205.0 ; mode= 570.0 ; median= 555.0 ; 25th percentile= 360.0 ; 75th percentile= 765.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2475.0\n",
      "\n",
      "trip= 64 ; taxi_id= 20000662 ; min= 15.0 max= 11340.0 ; mode= 690.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1984.8749999999973 ; 99.5th percentile= 3111.975000000002\n",
      "\n",
      "trip= 65 ; taxi_id= 20000055 ; min= 15.0 max= 3855.0 ; mode= 510.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1514.6249999999986 ; 99.5th percentile= 2195.5499999999984\n",
      "\n",
      "trip= 66 ; taxi_id= 20000595 ; min= 15.0 max= 8340.0 ; mode= 570.0 ; median= 630.0 ; 25th percentile= 450.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1815.0 ; 99.5th percentile= 3935.9999999999673\n",
      "\n",
      "trip= 67 ; taxi_id= 20000140 ; min= 15.0 max= 14010.0 ; mode= 555.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1541.6249999999945 ; 99.5th percentile= 2643.3000000000175\n",
      "\n",
      "trip= 68 ; taxi_id= 20000260 ; min= 15.0 max= 16050.0 ; mode= 450.0 ; median= 510.0 ; 25th percentile= 330.0 ; 75th percentile= 735.0 ; 97.5th percentile= 1735.1250000000027 ; 99.5th percentile= 3272.0250000000033\n",
      "\n",
      "trip= 69 ; taxi_id= 20000576 ; min= 15.0 max= 9345.0 ; mode= 705.0 ; median= 705.0 ; 25th percentile= 495.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1800.0 ; 99.5th percentile= 3088.1999999999607\n",
      "\n",
      "trip= 70 ; taxi_id= 20000047 ; min= 15.0 max= 3510.0 ; mode= 555.0 ; median= 555.0 ; 25th percentile= 405.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1455.0 ; 99.5th percentile= 2456.0999999999967\n",
      "\n",
      "trip= 71 ; taxi_id= 20000010 ; min= 15.0 max= 9660.0 ; mode= 510.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1890.0 ; 99.5th percentile= 3345.0\n",
      "\n",
      "trip= 72 ; taxi_id= 20000004 ; min= 15.0 max= 4830.0 ; mode= 555.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 971.25 ; 97.5th percentile= 2025.0 ; 99.5th percentile= 3165.0\n",
      "\n",
      "trip= 73 ; taxi_id= 20000334 ; min= 15.0 max= 32910.0 ; mode= 510.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3033.5999999999967\n",
      "\n",
      "trip= 74 ; taxi_id= 20000256 ; min= 15.0 max= 32100.0 ; mode= 555.0 ; median= 645.0 ; 25th percentile= 420.0 ; 75th percentile= 945.0 ; 97.5th percentile= 2692.124999999992 ; 99.5th percentile= 4889.849999999997\n",
      "\n",
      "trip= 75 ; taxi_id= 20000349 ; min= 15.0 max= 11025.0 ; mode= 615.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2100.0 ; 99.5th percentile= 6367.800000000007\n",
      "\n",
      "trip= 76 ; taxi_id= 20000675 ; min= 15.0 max= 10770.0 ; mode= 495.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 896.25 ; 97.5th percentile= 2021.25 ; 99.5th percentile= 3313.500000000022\n",
      "\n",
      "trip= 77 ; taxi_id= 20000010 ; min= 15.0 max= 9660.0 ; mode= 510.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1890.0 ; 99.5th percentile= 3345.0\n",
      "\n",
      "trip= 78 ; taxi_id= 20000224 ; min= 15.0 max= 17355.0 ; mode= 495.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2115.0 ; 99.5th percentile= 4185.300000000007\n",
      "\n",
      "trip= 79 ; taxi_id= 20000901 ; min= 15.0 max= 8340.0 ; mode= 705.0 ; median= 645.0 ; 25th percentile= 420.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1815.0 ; 99.5th percentile= 2996.25\n",
      "\n",
      "trip= 80 ; taxi_id= 20000488 ; min= 30.0 max= 6270.0 ; mode= 585.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 945.0 ; 97.5th percentile= 2658.374999999992 ; 99.5th percentile= 3938.0250000000115\n",
      "\n",
      "trip= 81 ; taxi_id= 20000633 ; min= 15.0 max= 9450.0 ; mode= 465.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1718.6249999999973 ; 99.5th percentile= 2947.725000000005\n",
      "\n",
      "trip= 82 ; taxi_id= 20000617 ; min= 15.0 max= 11445.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 945.0 ; 97.5th percentile= 2040.0 ; 99.5th percentile= 3132.2999999999956\n",
      "\n",
      "trip= 83 ; taxi_id= 20000188 ; min= 15.0 max= 13470.0 ; mode= 525.0 ; median= 675.0 ; 25th percentile= 480.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1860.0 ; 99.5th percentile= 2835.0\n",
      "\n",
      "trip= 84 ; taxi_id= 20000436 ; min= 15.0 max= 31440.0 ; mode= 450.0 ; median= 705.0 ; 25th percentile= 450.0 ; 75th percentile= 1035.0 ; 97.5th percentile= 2925.0 ; 99.5th percentile= 7088.775000000028\n",
      "\n",
      "trip= 85 ; taxi_id= 20000578 ; min= 15.0 max= 19050.0 ; mode= 510.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1485.0 ; 99.5th percentile= 2287.2000000000003\n",
      "\n",
      "trip= 86 ; taxi_id= 20000116 ; min= 15.0 max= 18315.0 ; mode= 525.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 5470.499999999984 ; 99.5th percentile= 10849.64999999998\n",
      "\n",
      "trip= 87 ; taxi_id= 20000477 ; min= 15.0 max= 11025.0 ; mode= 810.0 ; median= 735.0 ; 25th percentile= 465.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1916.6249999999877 ; 99.5th percentile= 3877.4249999999847\n",
      "\n",
      "trip= 88 ; taxi_id= 20000624 ; min= 15.0 max= 16125.0 ; mode= 510.0 ; median= 600.0 ; 25th percentile= 412.5 ; 75th percentile= 885.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3108.75\n",
      "\n",
      "trip= 89 ; taxi_id= 20000572 ; min= 15.0 max= 11580.0 ; mode= 405.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2590.350000000001\n",
      "\n",
      "trip= 90 ; taxi_id= 20000249 ; min= 15.0 max= 23685.0 ; mode= 465.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1725.0 ; 99.5th percentile= 2705.0999999999885\n",
      "\n",
      "trip= 91 ; taxi_id= 20000612 ; min= 15.0 max= 12420.0 ; mode= 540.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2310.0\n",
      "\n",
      "trip= 92 ; taxi_id= 20000560 ; min= 15.0 max= 12270.0 ; mode= 510.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1672.1249999999918 ; 99.5th percentile= 2969.8499999999967\n",
      "\n",
      "trip= 93 ; taxi_id= 20000372 ; min= 15.0 max= 13590.0 ; mode= 555.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 885.0 ; 97.5th percentile= 3275.9999999999945 ; 99.5th percentile= 4360.200000000004\n",
      "\n",
      "trip= 94 ; taxi_id= 20000071 ; min= 15.0 max= 17130.0 ; mode= 435.0 ; median= 615.0 ; 25th percentile= 450.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1697.9999999999973 ; 99.5th percentile= 2787.600000000009\n",
      "\n",
      "trip= 95 ; taxi_id= 20000688 ; min= 15.0 max= 15630.0 ; mode= 465.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 840.0 ; 97.5th percentile= 2521.875 ; 99.5th percentile= 5770.500000000011\n",
      "\n",
      "trip= 96 ; taxi_id= 20000904 ; min= 15.0 max= 46785.0 ; mode= 480.0 ; median= 1027.5 ; 25th percentile= 585.0 ; 75th percentile= 1545.0 ; 97.5th percentile= 5515.125000000003 ; 99.5th percentile= 12050.625000000015\n",
      "\n",
      "trip= 97 ; taxi_id= 20000060 ; min= 15.0 max= 8910.0 ; mode= 495.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1755.0 ; 99.5th percentile= 2790.0\n",
      "\n",
      "trip= 98 ; taxi_id= 20000434 ; min= 15.0 max= 15150.0 ; mode= 405.0 ; median= 690.0 ; 25th percentile= 480.0 ; 75th percentile= 1050.0 ; 97.5th percentile= 2201.25 ; 99.5th percentile= 3915.0\n",
      "\n",
      "trip= 99 ; taxi_id= 20000112 ; min= 15.0 max= 11115.0 ; mode= 480.0 ; median= 645.0 ; 25th percentile= 465.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1635.0 ; 99.5th percentile= 2415.0\n",
      "\n",
      "trip= 100 ; taxi_id= 20000286 ; min= 15.0 max= 11355.0 ; mode= 15.0 ; median= 495.0 ; 25th percentile= 300.0 ; 75th percentile= 750.0 ; 97.5th percentile= 1863.3749999999986 ; 99.5th percentile= 3670.349999999994\n",
      "\n",
      "trip= 101 ; taxi_id= 20000036 ; min= 15.0 max= 17850.0 ; mode= 540.0 ; median= 720.0 ; 25th percentile= 495.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2212.1249999999986 ; 99.5th percentile= 3885.0\n",
      "\n",
      "trip= 102 ; taxi_id= 20000086 ; min= 15.0 max= 53835.0 ; mode= 615.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 926.25 ; 97.5th percentile= 1830.0 ; 99.5th percentile= 3330.0\n",
      "\n",
      "trip= 103 ; taxi_id= 20000574 ; min= 15.0 max= 21105.0 ; mode= 405.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2554.5000000000027 ; 99.5th percentile= 5214.899999999998\n",
      "\n",
      "trip= 104 ; taxi_id= 20000331 ; min= 15.0 max= 7635.0 ; mode= 450.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2408.0999999999995\n",
      "\n",
      "trip= 105 ; taxi_id= 20000026 ; min= 15.0 max= 8010.0 ; mode= 15.0 ; median= 660.0 ; 25th percentile= 420.0 ; 75th percentile= 975.0 ; 97.5th percentile= 1920.0 ; 99.5th percentile= 2993.2500000000027\n",
      "\n",
      "trip= 106 ; taxi_id= 20000518 ; min= 15.0 max= 11730.0 ; mode= 480.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1795.4999999999973 ; 99.5th percentile= 2872.1999999999935\n",
      "\n",
      "trip= 107 ; taxi_id= 20000541 ; min= 15.0 max= 24930.0 ; mode= 390.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1950.0 ; 99.5th percentile= 4933.200000000002\n",
      "\n",
      "trip= 108 ; taxi_id= 20000400 ; min= 15.0 max= 13485.0 ; mode= 375.0 ; median= 555.0 ; 25th percentile= 360.0 ; 75th percentile= 810.0 ; 97.5th percentile= 4568.999999999992 ; 99.5th percentile= 8906.999999999982\n",
      "\n",
      "trip= 109 ; taxi_id= 20000682 ; min= 15.0 max= 9315.0 ; mode= 630.0 ; median= 705.0 ; 25th percentile= 510.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3307.5000000000136\n",
      "\n",
      "trip= 110 ; taxi_id= 20000039 ; min= 15.0 max= 13470.0 ; mode= 720.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1891.1249999999973 ; 99.5th percentile= 3327.225000000001\n",
      "\n",
      "trip= 111 ; taxi_id= 20000597 ; min= 15.0 max= 8145.0 ; mode= 540.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1770.0 ; 99.5th percentile= 2553.9000000000033\n",
      "\n",
      "trip= 112 ; taxi_id= 20000230 ; min= 15.0 max= 23400.0 ; mode= 720.0 ; median= 660.0 ; 25th percentile= 465.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2461.5000000000123\n",
      "\n",
      "trip= 113 ; taxi_id= 20000206 ; min= 15.0 max= 15285.0 ; mode= 555.0 ; median= 705.0 ; 25th percentile= 495.0 ; 75th percentile= 1005.0 ; 97.5th percentile= 4943.999999999992 ; 99.5th percentile= 9744.599999999951\n",
      "\n",
      "trip= 114 ; taxi_id= 20000126 ; min= 15.0 max= 5490.0 ; mode= 405.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 750.0 ; 97.5th percentile= 1530.0 ; 99.5th percentile= 2478.5999999999967\n",
      "\n",
      "trip= 115 ; taxi_id= 20000296 ; min= 15.0 max= 17880.0 ; mode= 735.0 ; median= 705.0 ; 25th percentile= 495.0 ; 75th percentile= 960.0 ; 97.5th percentile= 2062.1249999999986 ; 99.5th percentile= 4283.40000000002\n",
      "\n",
      "trip= 116 ; taxi_id= 20000049 ; min= 15.0 max= 5715.0 ; mode= 555.0 ; median= 705.0 ; 25th percentile= 510.0 ; 75th percentile= 975.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2464.499999999996\n",
      "\n",
      "trip= 117 ; taxi_id= 20000383 ; min= 15.0 max= 13020.0 ; mode= 540.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1920.0 ; 99.5th percentile= 4244.999999999986\n",
      "\n",
      "trip= 118 ; taxi_id= 20000156 ; min= 15.0 max= 13965.0 ; mode= 495.0 ; median= 690.0 ; 25th percentile= 480.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1830.0 ; 99.5th percentile= 3089.1000000000076\n",
      "\n",
      "trip= 119 ; taxi_id= 20000198 ; min= 15.0 max= 7230.0 ; mode= 615.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1530.0 ; 99.5th percentile= 2340.0\n",
      "\n",
      "trip= 120 ; taxi_id= 20000596 ; min= 15.0 max= 8925.0 ; mode= 705.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 4072.050000000004\n",
      "\n",
      "trip= 121 ; taxi_id= 20000248 ; min= 120.0 max= 4215.0 ; mode= 600.0 ; median= 600.0 ; 25th percentile= 408.75 ; 75th percentile= 825.0 ; 97.5th percentile= 1360.1250000000002 ; 99.5th percentile= 2206.3499999999817\n",
      "\n",
      "trip= 122 ; taxi_id= 20000591 ; min= 15.0 max= 19935.0 ; mode= 645.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2841.899999999987\n",
      "\n",
      "trip= 123 ; taxi_id= 20000260 ; min= 15.0 max= 16050.0 ; mode= 450.0 ; median= 510.0 ; 25th percentile= 330.0 ; 75th percentile= 735.0 ; 97.5th percentile= 1735.1250000000027 ; 99.5th percentile= 3272.0250000000033\n",
      "\n",
      "trip= 124 ; taxi_id= 20000005 ; min= 15.0 max= 13410.0 ; mode= 465.0 ; median= 555.0 ; 25th percentile= 390.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1605.0 ; 99.5th percentile= 2650.800000000004\n",
      "\n",
      "trip= 125 ; taxi_id= 20000686 ; min= 15.0 max= 23760.0 ; mode= 465.0 ; median= 540.0 ; 25th percentile= 375.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2460.0\n",
      "\n",
      "trip= 126 ; taxi_id= 20000384 ; min= 15.0 max= 22350.0 ; mode= 495.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1875.0 ; 99.5th percentile= 2936.5500000000065\n",
      "\n",
      "trip= 127 ; taxi_id= 20000272 ; min= 15.0 max= 11235.0 ; mode= 660.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1567.1249999999986 ; 99.5th percentile= 2576.8499999999995\n",
      "\n",
      "trip= 128 ; taxi_id= 20000314 ; min= 30.0 max= 7740.0 ; mode= 375.0 ; median= 660.0 ; 25th percentile= 442.5 ; 75th percentile= 930.0 ; 97.5th percentile= 1890.749999999996 ; 99.5th percentile= 2923.2000000000153\n",
      "\n",
      "trip= 129 ; taxi_id= 20000625 ; min= 15.0 max= 9075.0 ; mode= 540.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1653.3749999999918 ; 99.5th percentile= 2775.0\n",
      "\n",
      "trip= 130 ; taxi_id= 20000589 ; min= 15.0 max= 14280.0 ; mode= 405.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1633.4999999999945 ; 99.5th percentile= 2794.20000000001\n",
      "\n",
      "trip= 131 ; taxi_id= 20000476 ; min= 15.0 max= 8970.0 ; mode= 255.0 ; median= 465.0 ; 25th percentile= 300.0 ; 75th percentile= 690.0 ; 97.5th percentile= 1500.0 ; 99.5th percentile= 2371.5749999999935\n",
      "\n",
      "trip= 132 ; taxi_id= 20000523 ; min= 15.0 max= 11505.0 ; mode= 555.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1998.75 ; 99.5th percentile= 3502.125000000019\n",
      "\n",
      "trip= 133 ; taxi_id= 20000503 ; min= 15.0 max= 8595.0 ; mode= 390.0 ; median= 525.0 ; 25th percentile= 345.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2431.199999999999\n",
      "\n",
      "trip= 134 ; taxi_id= 20000473 ; min= 15.0 max= 15195.0 ; mode= 495.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 2430.0 ; 99.5th percentile= 4368.000000000011\n",
      "\n",
      "trip= 135 ; taxi_id= 20000092 ; min= 15.0 max= 29775.0 ; mode= 480.0 ; median= 585.0 ; 25th percentile= 375.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1665.0 ; 99.5th percentile= 2650.274999999999\n",
      "\n",
      "trip= 136 ; taxi_id= 20000085 ; min= 15.0 max= 20250.0 ; mode= 735.0 ; median= 765.0 ; 25th percentile= 525.0 ; 75th percentile= 1095.0 ; 97.5th percentile= 2955.3750000000014 ; 99.5th percentile= 5892.5250000000215\n",
      "\n",
      "trip= 137 ; taxi_id= 20000159 ; min= 15.0 max= 12720.0 ; mode= 525.0 ; median= 765.0 ; 25th percentile= 525.0 ; 75th percentile= 1035.0 ; 97.5th percentile= 2955.0 ; 99.5th percentile= 6121.724999999997\n",
      "\n",
      "trip= 138 ; taxi_id= 20000410 ; min= 15.0 max= 6720.0 ; mode= 690.0 ; median= 675.0 ; 25th percentile= 480.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1755.0 ; 99.5th percentile= 2621.25\n",
      "\n",
      "trip= 139 ; taxi_id= 20000123 ; min= 15.0 max= 21480.0 ; mode= 540.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1785.0 ; 99.5th percentile= 3375.0\n",
      "\n",
      "trip= 140 ; taxi_id= 20000040 ; min= 15.0 max= 8610.0 ; mode= 510.0 ; median= 675.0 ; 25th percentile= 480.0 ; 75th percentile= 945.0 ; 97.5th percentile= 1895.2499999999986 ; 99.5th percentile= 2928.1500000000074\n",
      "\n",
      "trip= 141 ; taxi_id= 20000502 ; min= 15.0 max= 27540.0 ; mode= 630.0 ; median= 735.0 ; 25th percentile= 525.0 ; 75th percentile= 1065.0 ; 97.5th percentile= 3703.500000000008 ; 99.5th percentile= 6334.50000000003\n",
      "\n",
      "trip= 142 ; taxi_id= 20000144 ; min= 15.0 max= 39780.0 ; mode= 525.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 2022.7499999999918 ; 99.5th percentile= 4238.249999999894\n",
      "\n",
      "trip= 143 ; taxi_id= 20000053 ; min= 15.0 max= 31455.0 ; mode= 435.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1920.0 ; 99.5th percentile= 3771.000000000049\n",
      "\n",
      "trip= 144 ; taxi_id= 20000510 ; min= 15.0 max= 37470.0 ; mode= 960.0 ; median= 825.0 ; 25th percentile= 450.0 ; 75th percentile= 1233.75 ; 97.5th percentile= 11974.124999999984 ; 99.5th percentile= 26160.224999999868\n",
      "\n",
      "trip= 145 ; taxi_id= 20000171 ; min= 15.0 max= 17445.0 ; mode= 480.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1762.1249999999918 ; 99.5th percentile= 3105.0\n",
      "\n",
      "trip= 146 ; taxi_id= 20000207 ; min= 15.0 max= 12600.0 ; mode= 525.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2910.0 ; 99.5th percentile= 4641.449999999997\n",
      "\n",
      "trip= 147 ; taxi_id= 20000099 ; min= 15.0 max= 6855.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 465.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1785.0 ; 99.5th percentile= 2631.000000000022\n",
      "\n",
      "trip= 148 ; taxi_id= 20000440 ; min= 15.0 max= 7740.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 881.25 ; 97.5th percentile= 2010.0 ; 99.5th percentile= 3721.649999999995\n",
      "\n",
      "trip= 149 ; taxi_id= 20000158 ; min= 15.0 max= 11880.0 ; mode= 420.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1590.0 ; 99.5th percentile= 2724.899999999998\n",
      "\n",
      "trip= 150 ; taxi_id= 20000543 ; min= 15.0 max= 8745.0 ; mode= 630.0 ; median= 660.0 ; 25th percentile= 465.0 ; 75th percentile= 960.0 ; 97.5th percentile= 2197.5 ; 99.5th percentile= 3721.500000000019\n",
      "\n",
      "trip= 151 ; taxi_id= 20000017 ; min= 15.0 max= 6495.0 ; mode= 330.0 ; median= 570.0 ; 25th percentile= 375.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2916.7499999999973\n",
      "\n",
      "trip= 152 ; taxi_id= 20000698 ; min= 15.0 max= 6240.0 ; mode= 405.0 ; median= 615.0 ; 25th percentile= 405.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1935.0 ; 99.5th percentile= 3764.399999999987\n",
      "\n",
      "trip= 153 ; taxi_id= 20000391 ; min= 30.0 max= 25215.0 ; mode= 510.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1860.0 ; 99.5th percentile= 3258.8250000000153\n",
      "\n",
      "trip= 154 ; taxi_id= 20000657 ; min= 15.0 max= 8460.0 ; mode= 480.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1770.0 ; 99.5th percentile= 2689.949999999999\n",
      "\n",
      "trip= 155 ; taxi_id= 20000429 ; min= 15.0 max= 5835.0 ; mode= 465.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1554.7499999999945 ; 99.5th percentile= 2500.8000000000175\n",
      "\n",
      "trip= 156 ; taxi_id= 20000249 ; min= 15.0 max= 23685.0 ; mode= 465.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1725.0 ; 99.5th percentile= 2705.0999999999885\n",
      "\n",
      "trip= 157 ; taxi_id= 20000171 ; min= 15.0 max= 17445.0 ; mode= 480.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1762.1249999999918 ; 99.5th percentile= 3105.0\n",
      "\n",
      "trip= 158 ; taxi_id= 20000410 ; min= 15.0 max= 6720.0 ; mode= 690.0 ; median= 675.0 ; 25th percentile= 480.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1755.0 ; 99.5th percentile= 2621.25\n",
      "\n",
      "trip= 159 ; taxi_id= 20000407 ; min= 15.0 max= 15420.0 ; mode= 555.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1978.5000000000014 ; 99.5th percentile= 5824.799999999996\n",
      "\n",
      "trip= 160 ; taxi_id= 20000109 ; min= 15.0 max= 14640.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1740.0 ; 99.5th percentile= 3039.3750000000136\n",
      "\n",
      "trip= 161 ; taxi_id= 20000180 ; min= 15.0 max= 11835.0 ; mode= 465.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1815.0 ; 99.5th percentile= 3150.0\n",
      "\n",
      "trip= 162 ; taxi_id= 20000649 ; min= 15.0 max= 8205.0 ; mode= 570.0 ; median= 555.0 ; 25th percentile= 360.0 ; 75th percentile= 765.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2475.0\n",
      "\n",
      "trip= 163 ; taxi_id= 20000128 ; min= 15.0 max= 8595.0 ; mode= 540.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1989.7499999999945 ; 99.5th percentile= 3710.850000000005\n",
      "\n",
      "trip= 164 ; taxi_id= 20000685 ; min= 15.0 max= 4740.0 ; mode= 495.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1560.0 ; 99.5th percentile= 2869.7999999999956\n",
      "\n",
      "trip= 165 ; taxi_id= 20000054 ; min= 15.0 max= 13755.0 ; mode= 555.0 ; median= 630.0 ; 25th percentile= 450.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1695.0 ; 99.5th percentile= 2695.199999999977\n",
      "\n",
      "trip= 166 ; taxi_id= 20000118 ; min= 15.0 max= 5475.0 ; mode= 420.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1530.0 ; 99.5th percentile= 2280.0\n",
      "\n",
      "trip= 167 ; taxi_id= 20000624 ; min= 15.0 max= 16125.0 ; mode= 510.0 ; median= 600.0 ; 25th percentile= 412.5 ; 75th percentile= 885.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3108.75\n",
      "\n",
      "trip= 168 ; taxi_id= 20000453 ; min= 15.0 max= 8550.0 ; mode= 345.0 ; median= 585.0 ; 25th percentile= 375.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1908.3749999999986 ; 99.5th percentile= 3187.724999999998\n",
      "\n",
      "trip= 169 ; taxi_id= 20000488 ; min= 30.0 max= 6270.0 ; mode= 585.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 945.0 ; 97.5th percentile= 2658.374999999992 ; 99.5th percentile= 3938.0250000000115\n",
      "\n",
      "trip= 170 ; taxi_id= 20000163 ; min= 15.0 max= 32745.0 ; mode= 765.0 ; median= 870.0 ; 25th percentile= 570.0 ; 75th percentile= 1278.75 ; 97.5th percentile= 4095.0 ; 99.5th percentile= 11191.874999999965\n",
      "\n",
      "trip= 171 ; taxi_id= 20000261 ; min= 15.0 max= 17550.0 ; mode= 375.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 2033.6249999999973 ; 99.5th percentile= 3898.7249999999995\n",
      "\n",
      "trip= 172 ; taxi_id= 20000452 ; min= 15.0 max= 18300.0 ; mode= 660.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2190.0 ; 99.5th percentile= 3924.2999999999847\n",
      "\n",
      "trip= 173 ; taxi_id= 20000403 ; min= 15.0 max= 13095.0 ; mode= 15.0 ; median= 465.0 ; 25th percentile= 255.0 ; 75th percentile= 735.0 ; 97.5th percentile= 1885.4999999999973 ; 99.5th percentile= 3442.1999999999935\n",
      "\n",
      "trip= 174 ; taxi_id= 20000235 ; min= 15.0 max= 9375.0 ; mode= 480.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1833.3749999999918 ; 99.5th percentile= 2985.0\n",
      "\n",
      "trip= 175 ; taxi_id= 20000464 ; min= 15.0 max= 10200.0 ; mode= 360.0 ; median= 690.0 ; 25th percentile= 450.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2441.25 ; 99.5th percentile= 4496.249999999993\n",
      "\n",
      "trip= 176 ; taxi_id= 20000276 ; min= 15.0 max= 36900.0 ; mode= 450.0 ; median= 690.0 ; 25th percentile= 461.25 ; 75th percentile= 1020.0 ; 97.5th percentile= 2800.874999999992 ; 99.5th percentile= 5743.349999999991\n",
      "\n",
      "trip= 177 ; taxi_id= 20000250 ; min= 15.0 max= 33645.0 ; mode= 510.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 2116.875 ; 99.5th percentile= 4908.75\n",
      "\n",
      "trip= 178 ; taxi_id= 20000166 ; min= 15.0 max= 18165.0 ; mode= 435.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1816.875 ; 99.5th percentile= 3624.7499999999945\n",
      "\n",
      "trip= 179 ; taxi_id= 20000377 ; min= 15.0 max= 4470.0 ; mode= 495.0 ; median= 652.5 ; 25th percentile= 465.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1611.374999999996 ; 99.5th percentile= 2530.274999999999\n",
      "\n",
      "trip= 180 ; taxi_id= 20000146 ; min= 15.0 max= 5445.0 ; mode= 375.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1545.0 ; 99.5th percentile= 2340.0\n",
      "\n",
      "trip= 181 ; taxi_id= 20000436 ; min= 15.0 max= 31440.0 ; mode= 450.0 ; median= 705.0 ; 25th percentile= 450.0 ; 75th percentile= 1035.0 ; 97.5th percentile= 2925.0 ; 99.5th percentile= 7088.775000000028\n",
      "\n",
      "trip= 182 ; taxi_id= 20000483 ; min= 15.0 max= 8985.0 ; mode= 510.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2415.0\n",
      "\n",
      "trip= 183 ; taxi_id= 20000653 ; min= 15.0 max= 10155.0 ; mode= 465.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2727.449999999999\n",
      "\n",
      "trip= 184 ; taxi_id= 20000352 ; min= 15.0 max= 11790.0 ; mode= 630.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1826.6250000000014 ; 99.5th percentile= 3295.575000000033\n",
      "\n",
      "trip= 185 ; taxi_id= 20000295 ; min= 15.0 max= 12060.0 ; mode= 360.0 ; median= 540.0 ; 25th percentile= 360.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2775.599999999986\n",
      "\n",
      "trip= 186 ; taxi_id= 20000121 ; min= 15.0 max= 8880.0 ; mode= 435.0 ; median= 750.0 ; 25th percentile= 506.25 ; 75th percentile= 1170.0 ; 97.5th percentile= 3989.250000000004 ; 99.5th percentile= 6811.874999999986\n",
      "\n",
      "trip= 187 ; taxi_id= 20000349 ; min= 15.0 max= 11025.0 ; mode= 615.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2100.0 ; 99.5th percentile= 6367.800000000007\n",
      "\n",
      "trip= 188 ; taxi_id= 20000340 ; min= 15.0 max= 6990.0 ; mode= 405.0 ; median= 645.0 ; 25th percentile= 465.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1710.7499999999993 ; 99.5th percentile= 2424.4500000000016\n",
      "\n",
      "trip= 189 ; taxi_id= 20000129 ; min= 15.0 max= 12690.0 ; mode= 735.0 ; median= 720.0 ; 25th percentile= 525.0 ; 75th percentile= 1005.0 ; 97.5th percentile= 2025.0 ; 99.5th percentile= 3097.1999999999935\n",
      "\n",
      "trip= 190 ; taxi_id= 20000206 ; min= 15.0 max= 15285.0 ; mode= 555.0 ; median= 705.0 ; 25th percentile= 495.0 ; 75th percentile= 1005.0 ; 97.5th percentile= 4943.999999999992 ; 99.5th percentile= 9744.599999999951\n",
      "\n",
      "trip= 191 ; taxi_id= 20000347 ; min= 15.0 max= 5310.0 ; mode= 585.0 ; median= 705.0 ; 25th percentile= 510.0 ; 75th percentile= 960.0 ; 97.5th percentile= 1770.0 ; 99.5th percentile= 2486.250000000007\n",
      "\n",
      "trip= 192 ; taxi_id= 20000057 ; min= 15.0 max= 6315.0 ; mode= 450.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2790.0\n",
      "\n",
      "trip= 193 ; taxi_id= 20000502 ; min= 15.0 max= 27540.0 ; mode= 630.0 ; median= 735.0 ; 25th percentile= 525.0 ; 75th percentile= 1065.0 ; 97.5th percentile= 3703.500000000008 ; 99.5th percentile= 6334.50000000003\n",
      "\n",
      "trip= 194 ; taxi_id= 20000596 ; min= 15.0 max= 8925.0 ; mode= 705.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 4072.050000000004\n",
      "\n",
      "trip= 195 ; taxi_id= 20000574 ; min= 15.0 max= 21105.0 ; mode= 405.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2554.5000000000027 ; 99.5th percentile= 5214.899999999998\n",
      "\n",
      "trip= 196 ; taxi_id= 20000222 ; min= 15.0 max= 22050.0 ; mode= 705.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2539.499999999989\n",
      "\n",
      "trip= 197 ; taxi_id= 20000338 ; min= 15.0 max= 25035.0 ; mode= 330.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 915.0 ; 97.5th percentile= 2624.2499999999973 ; 99.5th percentile= 4796.550000000007\n",
      "\n",
      "trip= 198 ; taxi_id= 20000381 ; min= 15.0 max= 9855.0 ; mode= 465.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1965.0 ; 99.5th percentile= 3255.900000000006\n",
      "\n",
      "trip= 199 ; taxi_id= 20000213 ; min= 15.0 max= 13770.0 ; mode= 480.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 843.75 ; 97.5th percentile= 2682.3749999999973 ; 99.5th percentile= 7592.999999999956\n",
      "\n",
      "trip= 200 ; taxi_id= 20000687 ; min= 15.0 max= 7770.0 ; mode= 375.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1890.0 ; 99.5th percentile= 3312.899999999995\n",
      "\n",
      "trip= 201 ; taxi_id= 20000356 ; min= 15.0 max= 11970.0 ; mode= 645.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1890.0 ; 99.5th percentile= 3892.5\n",
      "\n",
      "trip= 202 ; taxi_id= 20000312 ; min= 15.0 max= 15675.0 ; mode= 840.0 ; median= 1005.0 ; 25th percentile= 570.0 ; 75th percentile= 1710.0 ; 97.5th percentile= 4319.249999999991 ; 99.5th percentile= 7246.500000000033\n",
      "\n",
      "trip= 203 ; taxi_id= 20000591 ; min= 15.0 max= 19935.0 ; mode= 645.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2841.899999999987\n",
      "\n",
      "trip= 204 ; taxi_id= 20000361 ; min= 15.0 max= 20805.0 ; mode= 480.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1846.1249999999973 ; 99.5th percentile= 4431.149999999916\n",
      "\n",
      "trip= 205 ; taxi_id= 20000446 ; min= 15.0 max= 15435.0 ; mode= 480.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 915.0 ; 97.5th percentile= 3435.749999999989 ; 99.5th percentile= 6939.074999999993\n",
      "\n",
      "trip= 206 ; taxi_id= 20000243 ; min= 15.0 max= 28245.0 ; mode= 600.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1860.0 ; 99.5th percentile= 3588.000000000011\n",
      "\n",
      "trip= 207 ; taxi_id= 20000456 ; min= 15.0 max= 12675.0 ; mode= 540.0 ; median= 630.0 ; 25th percentile= 450.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1696.4999999999986 ; 99.5th percentile= 2742.600000000002\n",
      "\n",
      "trip= 208 ; taxi_id= 20000450 ; min= 15.0 max= 7890.0 ; mode= 495.0 ; median= 570.0 ; 25th percentile= 401.25 ; 75th percentile= 795.0 ; 97.5th percentile= 1560.0 ; 99.5th percentile= 2250.0\n",
      "\n",
      "trip= 209 ; taxi_id= 20000632 ; min= 15.0 max= 9945.0 ; mode= 450.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 3015.0\n",
      "\n",
      "trip= 210 ; taxi_id= 20000387 ; min= 15.0 max= 8310.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 457.5 ; 75th percentile= 885.0 ; 97.5th percentile= 2145.0 ; 99.5th percentile= 3313.0499999999984\n",
      "\n",
      "trip= 211 ; taxi_id= 20000421 ; min= 15.0 max= 6255.0 ; mode= 525.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1665.0 ; 99.5th percentile= 2500.500000000011\n",
      "\n",
      "trip= 212 ; taxi_id= 20000562 ; min= 15.0 max= 58065.0 ; mode= 510.0 ; median= 645.0 ; 25th percentile= 435.0 ; 75th percentile= 1005.0 ; 97.5th percentile= 2663.9999999999986 ; 99.5th percentile= 6294.5999999999985\n",
      "\n",
      "trip= 213 ; taxi_id= 20000455 ; min= 15.0 max= 25410.0 ; mode= 345.0 ; median= 615.0 ; 25th percentile= 390.0 ; 75th percentile= 960.0 ; 97.5th percentile= 4322.2499999999945 ; 99.5th percentile= 8775.449999999997\n",
      "\n",
      "trip= 214 ; taxi_id= 20000362 ; min= 15.0 max= 7875.0 ; mode= 495.0 ; median= 540.0 ; 25th percentile= 360.0 ; 75th percentile= 761.25 ; 97.5th percentile= 1485.0 ; 99.5th percentile= 2217.67499999999\n",
      "\n",
      "trip= 215 ; taxi_id= 20000311 ; min= 15.0 max= 8985.0 ; mode= 840.0 ; median= 750.0 ; 25th percentile= 525.0 ; 75th percentile= 1050.0 ; 97.5th percentile= 2325.0 ; 99.5th percentile= 3627.2999999999956\n",
      "\n",
      "trip= 216 ; taxi_id= 20000067 ; min= 15.0 max= 8370.0 ; mode= 465.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1785.0 ; 99.5th percentile= 3179.174999999982\n",
      "\n",
      "trip= 217 ; taxi_id= 20000363 ; min= 15.0 max= 16245.0 ; mode= 645.0 ; median= 780.0 ; 25th percentile= 510.0 ; 75th percentile= 1185.0 ; 97.5th percentile= 3180.0 ; 99.5th percentile= 5115.0\n",
      "\n",
      "trip= 218 ; taxi_id= 20000612 ; min= 15.0 max= 12420.0 ; mode= 540.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2310.0\n",
      "\n",
      "trip= 219 ; taxi_id= 20000154 ; min= 15.0 max= 13305.0 ; mode= 390.0 ; median= 570.0 ; 25th percentile= 405.0 ; 75th percentile= 795.0 ; 97.5th percentile= 1545.0 ; 99.5th percentile= 2250.0\n",
      "\n",
      "trip= 220 ; taxi_id= 20000334 ; min= 15.0 max= 32910.0 ; mode= 510.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3033.5999999999967\n",
      "\n",
      "trip= 221 ; taxi_id= 20000540 ; min= 15.0 max= 21870.0 ; mode= 405.0 ; median= 645.0 ; 25th percentile= 375.0 ; 75th percentile= 1065.0 ; 97.5th percentile= 2485.874999999992 ; 99.5th percentile= 5414.174999999996\n",
      "\n",
      "trip= 222 ; taxi_id= 20000539 ; min= 15.0 max= 15795.0 ; mode= 435.0 ; median= 720.0 ; 25th percentile= 480.0 ; 75th percentile= 1110.0 ; 97.5th percentile= 4437.375000000001 ; 99.5th percentile= 9721.800000000012\n",
      "\n",
      "trip= 223 ; taxi_id= 20000434 ; min= 15.0 max= 15150.0 ; mode= 405.0 ; median= 690.0 ; 25th percentile= 480.0 ; 75th percentile= 1050.0 ; 97.5th percentile= 2201.25 ; 99.5th percentile= 3915.0\n",
      "\n",
      "trip= 224 ; taxi_id= 20000144 ; min= 15.0 max= 39780.0 ; mode= 525.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 2022.7499999999918 ; 99.5th percentile= 4238.249999999894\n",
      "\n",
      "trip= 225 ; taxi_id= 20000900 ; min= 15.0 max= 12825.0 ; mode= 345.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2428.6500000000115\n",
      "\n",
      "trip= 226 ; taxi_id= 20000167 ; min= 15.0 max= 3870.0 ; mode= 465.0 ; median= 525.0 ; 25th percentile= 345.0 ; 75th percentile= 735.0 ; 97.5th percentile= 1305.0 ; 99.5th percentile= 1875.0\n",
      "\n",
      "trip= 227 ; taxi_id= 20000668 ; min= 15.0 max= 18945.0 ; mode= 540.0 ; median= 795.0 ; 25th percentile= 540.0 ; 75th percentile= 1185.0 ; 97.5th percentile= 3915.0 ; 99.5th percentile= 8324.250000000025\n",
      "\n",
      "trip= 228 ; taxi_id= 20000454 ; min= 15.0 max= 7215.0 ; mode= 330.0 ; median= 540.0 ; 25th percentile= 360.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2940.7500000000164\n",
      "\n",
      "trip= 229 ; taxi_id= 20000252 ; min= 15.0 max= 9510.0 ; mode= 495.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1800.0 ; 99.5th percentile= 3193.49999999994\n",
      "\n",
      "trip= 230 ; taxi_id= 20000304 ; min= 15.0 max= 7110.0 ; mode= 420.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1815.0 ; 99.5th percentile= 2670.0\n",
      "\n",
      "trip= 231 ; taxi_id= 20000554 ; min= 15.0 max= 18390.0 ; mode= 555.0 ; median= 585.0 ; 25th percentile= 375.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1860.749999999996 ; 99.5th percentile= 3721.500000000019\n",
      "\n",
      "trip= 232 ; taxi_id= 20000112 ; min= 15.0 max= 11115.0 ; mode= 480.0 ; median= 645.0 ; 25th percentile= 465.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1635.0 ; 99.5th percentile= 2415.0\n",
      "\n",
      "trip= 233 ; taxi_id= 20000185 ; min= 15.0 max= 3735.0 ; mode= 600.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 941.25 ; 97.5th percentile= 1849.1249999999995 ; 99.5th percentile= 2739.2999999999984\n",
      "\n",
      "trip= 234 ; taxi_id= 20000303 ; min= 15.0 max= 8235.0 ; mode= 435.0 ; median= 585.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1637.9999999999973 ; 99.5th percentile= 2656.199999999999\n",
      "\n",
      "trip= 235 ; taxi_id= 20000081 ; min= 15.0 max= 27570.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1999.1249999999945 ; 99.5th percentile= 5368.649999999998\n",
      "\n",
      "trip= 236 ; taxi_id= 20000424 ; min= 15.0 max= 7455.0 ; mode= 435.0 ; median= 540.0 ; 25th percentile= 345.0 ; 75th percentile= 750.0 ; 97.5th percentile= 1485.0 ; 99.5th percentile= 2404.1999999999825\n",
      "\n",
      "trip= 237 ; taxi_id= 20000665 ; min= 15.0 max= 36000.0 ; mode= 495.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 885.0 ; 97.5th percentile= 2458.125 ; 99.5th percentile= 4410.0\n",
      "\n",
      "trip= 238 ; taxi_id= 20000026 ; min= 15.0 max= 8010.0 ; mode= 15.0 ; median= 660.0 ; 25th percentile= 420.0 ; 75th percentile= 975.0 ; 97.5th percentile= 1920.0 ; 99.5th percentile= 2993.2500000000027\n",
      "\n",
      "trip= 239 ; taxi_id= 20000012 ; min= 15.0 max= 21525.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1875.0 ; 99.5th percentile= 3522.449999999999\n",
      "\n",
      "trip= 240 ; taxi_id= 20000603 ; min= 15.0 max= 7755.0 ; mode= 510.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 881.25 ; 97.5th percentile= 1774.1250000000014 ; 99.5th percentile= 2711.475000000005\n",
      "\n",
      "trip= 241 ; taxi_id= 20000525 ; min= 15.0 max= 6765.0 ; mode= 435.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1560.0 ; 99.5th percentile= 2498.3999999999924\n",
      "\n",
      "trip= 242 ; taxi_id= 20000108 ; min= 15.0 max= 14880.0 ; mode= 600.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2869.499999999989\n",
      "\n",
      "trip= 243 ; taxi_id= 20000492 ; min= 15.0 max= 10650.0 ; mode= 390.0 ; median= 540.0 ; 25th percentile= 375.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1665.0 ; 99.5th percentile= 2840.625\n",
      "\n",
      "trip= 244 ; taxi_id= 20000664 ; min= 15.0 max= 8670.0 ; mode= 510.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 2145.0 ; 99.5th percentile= 3688.799999999974\n",
      "\n",
      "trip= 245 ; taxi_id= 20000503 ; min= 15.0 max= 8595.0 ; mode= 390.0 ; median= 525.0 ; 25th percentile= 345.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2431.199999999999\n",
      "\n",
      "trip= 246 ; taxi_id= 20000256 ; min= 15.0 max= 32100.0 ; mode= 555.0 ; median= 645.0 ; 25th percentile= 420.0 ; 75th percentile= 945.0 ; 97.5th percentile= 2692.124999999992 ; 99.5th percentile= 4889.849999999997\n",
      "\n",
      "trip= 247 ; taxi_id= 20000285 ; min= 15.0 max= 10365.0 ; mode= 540.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1933.125 ; 99.5th percentile= 3030.0\n",
      "\n",
      "trip= 248 ; taxi_id= 20000245 ; min= 15.0 max= 9390.0 ; mode= 555.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1605.0 ; 99.5th percentile= 2840.7000000000016\n",
      "\n",
      "trip= 249 ; taxi_id= 20000434 ; min= 15.0 max= 15150.0 ; mode= 405.0 ; median= 690.0 ; 25th percentile= 480.0 ; 75th percentile= 1050.0 ; 97.5th percentile= 2201.25 ; 99.5th percentile= 3915.0\n",
      "\n",
      "trip= 250 ; taxi_id= 20000406 ; min= 15.0 max= 6990.0 ; mode= 270.0 ; median= 615.0 ; 25th percentile= 375.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 2852.550000000001\n",
      "\n",
      "trip= 251 ; taxi_id= 20000239 ; min= 15.0 max= 15930.0 ; mode= 510.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1740.0 ; 99.5th percentile= 2715.5999999999995\n",
      "\n",
      "trip= 252 ; taxi_id= 20000426 ; min= 15.0 max= 8550.0 ; mode= 465.0 ; median= 705.0 ; 25th percentile= 480.0 ; 75th percentile= 960.0 ; 97.5th percentile= 2127.3749999999973 ; 99.5th percentile= 3417.3749999999836\n",
      "\n",
      "trip= 253 ; taxi_id= 20000190 ; min= 15.0 max= 12390.0 ; mode= 435.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 870.0 ; 97.5th percentile= 2100.0 ; 99.5th percentile= 5585.9999999999945\n",
      "\n",
      "trip= 254 ; taxi_id= 20000192 ; min= 15.0 max= 12465.0 ; mode= 480.0 ; median= 615.0 ; 25th percentile= 431.25 ; 75th percentile= 870.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2699.2499999999836\n",
      "\n",
      "trip= 255 ; taxi_id= 20000361 ; min= 15.0 max= 20805.0 ; mode= 480.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1846.1249999999973 ; 99.5th percentile= 4431.149999999916\n",
      "\n",
      "trip= 256 ; taxi_id= 20000129 ; min= 15.0 max= 12690.0 ; mode= 735.0 ; median= 720.0 ; 25th percentile= 525.0 ; 75th percentile= 1005.0 ; 97.5th percentile= 2025.0 ; 99.5th percentile= 3097.1999999999935\n",
      "\n",
      "trip= 257 ; taxi_id= 20000548 ; min= 15.0 max= 12150.0 ; mode= 570.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1875.749999999996 ; 99.5th percentile= 2811.149999999998\n",
      "\n",
      "trip= 258 ; taxi_id= 20000263 ; min= 15.0 max= 34845.0 ; mode= 450.0 ; median= 585.0 ; 25th percentile= 390.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1635.0 ; 99.5th percentile= 2790.0\n",
      "\n",
      "trip= 259 ; taxi_id= 20000333 ; min= 15.0 max= 14745.0 ; mode= 360.0 ; median= 570.0 ; 25th percentile= 375.0 ; 75th percentile= 885.0 ; 97.5th percentile= 2340.0 ; 99.5th percentile= 5742.67499999999\n",
      "\n",
      "trip= 260 ; taxi_id= 20000197 ; min= 15.0 max= 12345.0 ; mode= 510.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 2014.8749999999973 ; 99.5th percentile= 4077.9000000000087\n",
      "\n",
      "trip= 261 ; taxi_id= 20000565 ; min= 15.0 max= 7710.0 ; mode= 465.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1525.124999999996 ; 99.5th percentile= 2637.0749999999975\n",
      "\n",
      "trip= 262 ; taxi_id= 20000307 ; min= 15.0 max= 16335.0 ; mode= 495.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 960.0 ; 97.5th percentile= 2100.0 ; 99.5th percentile= 3452.99999999997\n",
      "\n",
      "trip= 263 ; taxi_id= 20000678 ; min= 15.0 max= 12585.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1695.0 ; 99.5th percentile= 2858.6249999999973\n",
      "\n",
      "trip= 264 ; taxi_id= 20000351 ; min= 15.0 max= 21960.0 ; mode= 375.0 ; median= 585.0 ; 25th percentile= 375.0 ; 75th percentile= 915.0 ; 97.5th percentile= 2355.0 ; 99.5th percentile= 4932.675000000004\n",
      "\n",
      "trip= 265 ; taxi_id= 20000560 ; min= 15.0 max= 12270.0 ; mode= 510.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1672.1249999999918 ; 99.5th percentile= 2969.8499999999967\n",
      "\n",
      "trip= 266 ; taxi_id= 20000431 ; min= 15.0 max= 4830.0 ; mode= 585.0 ; median= 585.0 ; 25th percentile= 405.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2553.5999999999967\n",
      "\n",
      "trip= 267 ; taxi_id= 20000686 ; min= 15.0 max= 23760.0 ; mode= 465.0 ; median= 540.0 ; 25th percentile= 375.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2460.0\n",
      "\n",
      "trip= 268 ; taxi_id= 20000079 ; min= 15.0 max= 8835.0 ; mode= 390.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2565.0 ; 99.5th percentile= 8332.5\n",
      "\n",
      "trip= 269 ; taxi_id= 20000005 ; min= 15.0 max= 13410.0 ; mode= 465.0 ; median= 555.0 ; 25th percentile= 390.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1605.0 ; 99.5th percentile= 2650.800000000004\n",
      "\n",
      "trip= 270 ; taxi_id= 20000395 ; min= 15.0 max= 28470.0 ; mode= 600.0 ; median= 705.0 ; 25th percentile= 480.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2426.999999999989 ; 99.5th percentile= 4136.099999999997\n",
      "\n",
      "trip= 271 ; taxi_id= 20000529 ; min= 15.0 max= 10125.0 ; mode= 405.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2520.0 ; 99.5th percentile= 3990.0\n",
      "\n",
      "trip= 272 ; taxi_id= 20000015 ; min= 15.0 max= 16050.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1725.0 ; 99.5th percentile= 3740.7000000000153\n",
      "\n",
      "trip= 273 ; taxi_id= 20000626 ; min= 15.0 max= 7650.0 ; mode= 480.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2549.399999999987\n",
      "\n",
      "trip= 274 ; taxi_id= 20000476 ; min= 15.0 max= 8970.0 ; mode= 255.0 ; median= 465.0 ; 25th percentile= 300.0 ; 75th percentile= 690.0 ; 97.5th percentile= 1500.0 ; 99.5th percentile= 2371.5749999999935\n",
      "\n",
      "trip= 275 ; taxi_id= 20000136 ; min= 15.0 max= 4935.0 ; mode= 495.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 2237.6250000000027 ; 99.5th percentile= 2890.050000000001\n",
      "\n",
      "trip= 276 ; taxi_id= 20000577 ; min= 15.0 max= 8010.0 ; mode= 555.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1695.0 ; 99.5th percentile= 2441.774999999998\n",
      "\n",
      "trip= 277 ; taxi_id= 20000517 ; min= 15.0 max= 6855.0 ; mode= 495.0 ; median= 570.0 ; 25th percentile= 405.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1545.0 ; 99.5th percentile= 2520.0\n",
      "\n",
      "trip= 278 ; taxi_id= 20000009 ; min= 15.0 max= 12555.0 ; mode= 495.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 4306.499999999992 ; 99.5th percentile= 8000.100000000002\n",
      "\n",
      "trip= 279 ; taxi_id= 20000105 ; min= 15.0 max= 10890.0 ; mode= 420.0 ; median= 555.0 ; 25th percentile= 390.0 ; 75th percentile= 795.0 ; 97.5th percentile= 1590.0 ; 99.5th percentile= 2501.1749999999984\n",
      "\n",
      "trip= 280 ; taxi_id= 20000499 ; min= 15.0 max= 5280.0 ; mode= 615.0 ; median= 630.0 ; 25th percentile= 450.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1620.0 ; 99.5th percentile= 2338.7249999999995\n",
      "\n",
      "trip= 281 ; taxi_id= 20000334 ; min= 15.0 max= 32910.0 ; mode= 510.0 ; median= 630.0 ; 25th percentile= 435.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1845.0 ; 99.5th percentile= 3033.5999999999967\n",
      "\n",
      "trip= 282 ; taxi_id= 20000463 ; min= 15.0 max= 7365.0 ; mode= 360.0 ; median= 480.0 ; 25th percentile= 300.0 ; 75th percentile= 727.5 ; 97.5th percentile= 1545.0 ; 99.5th percentile= 2391.5999999999804\n",
      "\n",
      "trip= 283 ; taxi_id= 20000118 ; min= 15.0 max= 5475.0 ; mode= 420.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1530.0 ; 99.5th percentile= 2280.0\n",
      "\n",
      "trip= 284 ; taxi_id= 20000513 ; min= 15.0 max= 8265.0 ; mode= 450.0 ; median= 600.0 ; 25th percentile= 405.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2329.3499999999995\n",
      "\n",
      "trip= 285 ; taxi_id= 20000460 ; min= 15.0 max= 4080.0 ; mode= 555.0 ; median= 645.0 ; 25th percentile= 465.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2199.2999999999984\n",
      "\n",
      "trip= 286 ; taxi_id= 20000342 ; min= 15.0 max= 13725.0 ; mode= 465.0 ; median= 570.0 ; 25th percentile= 420.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 3039.899999999998\n",
      "\n",
      "trip= 287 ; taxi_id= 20000494 ; min= 15.0 max= 16410.0 ; mode= 450.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1755.0 ; 99.5th percentile= 3501.899999999987\n",
      "\n",
      "trip= 288 ; taxi_id= 20000250 ; min= 15.0 max= 33645.0 ; mode= 510.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 2116.875 ; 99.5th percentile= 4908.75\n",
      "\n",
      "trip= 289 ; taxi_id= 20000021 ; min= 15.0 max= 6105.0 ; mode= 660.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1695.0 ; 99.5th percentile= 2377.5750000000016\n",
      "\n",
      "trip= 290 ; taxi_id= 20000148 ; min= 15.0 max= 4860.0 ; mode= 555.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 795.0 ; 97.5th percentile= 1633.5000000000014 ; 99.5th percentile= 2330.7000000000016\n",
      "\n",
      "trip= 291 ; taxi_id= 20000158 ; min= 15.0 max= 11880.0 ; mode= 420.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1590.0 ; 99.5th percentile= 2724.899999999998\n",
      "\n",
      "trip= 292 ; taxi_id= 20000693 ; min= 30.0 max= 19380.0 ; mode= 705.0 ; median= 705.0 ; 25th percentile= 480.0 ; 75th percentile= 1020.0 ; 97.5th percentile= 3247.5 ; 99.5th percentile= 9484.49999999995\n",
      "\n",
      "trip= 293 ; taxi_id= 20000051 ; min= 15.0 max= 11445.0 ; mode= 420.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1725.0 ; 99.5th percentile= 2905.3500000000417\n",
      "\n",
      "trip= 294 ; taxi_id= 20000100 ; min= 15.0 max= 20520.0 ; mode= 585.0 ; median= 720.0 ; 25th percentile= 510.0 ; 75th percentile= 1020.0 ; 97.5th percentile= 3262.5 ; 99.5th percentile= 8528.625000000051\n",
      "\n",
      "trip= 295 ; taxi_id= 20000450 ; min= 15.0 max= 7890.0 ; mode= 495.0 ; median= 570.0 ; 25th percentile= 401.25 ; 75th percentile= 795.0 ; 97.5th percentile= 1560.0 ; 99.5th percentile= 2250.0\n",
      "\n",
      "trip= 296 ; taxi_id= 20000067 ; min= 15.0 max= 8370.0 ; mode= 465.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1785.0 ; 99.5th percentile= 3179.174999999982\n",
      "\n",
      "trip= 297 ; taxi_id= 20000612 ; min= 15.0 max= 12420.0 ; mode= 540.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 840.0 ; 97.5th percentile= 1680.0 ; 99.5th percentile= 2310.0\n",
      "\n",
      "trip= 298 ; taxi_id= 20000320 ; min= 15.0 max= 14100.0 ; mode= 330.0 ; median= 585.0 ; 25th percentile= 375.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1909.8749999999973 ; 99.5th percentile= 4084.949999999999\n",
      "\n",
      "trip= 299 ; taxi_id= 20000047 ; min= 15.0 max= 3510.0 ; mode= 555.0 ; median= 555.0 ; 25th percentile= 405.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1455.0 ; 99.5th percentile= 2456.0999999999967\n",
      "\n",
      "trip= 300 ; taxi_id= 20000081 ; min= 15.0 max= 27570.0 ; mode= 450.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 870.0 ; 97.5th percentile= 1999.1249999999945 ; 99.5th percentile= 5368.649999999998\n",
      "\n",
      "trip= 301 ; taxi_id= 20000542 ; min= 15.0 max= 17040.0 ; mode= 480.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1965.0 ; 99.5th percentile= 3780.0\n",
      "\n",
      "trip= 302 ; taxi_id= 20000109 ; min= 15.0 max= 14640.0 ; mode= 570.0 ; median= 660.0 ; 25th percentile= 480.0 ; 75th percentile= 885.0 ; 97.5th percentile= 1740.0 ; 99.5th percentile= 3039.3750000000136\n",
      "\n",
      "trip= 303 ; taxi_id= 20000548 ; min= 15.0 max= 12150.0 ; mode= 570.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1875.749999999996 ; 99.5th percentile= 2811.149999999998\n",
      "\n",
      "trip= 304 ; taxi_id= 20000247 ; min= 15.0 max= 14655.0 ; mode= 510.0 ; median= 615.0 ; 25th percentile= 435.0 ; 75th percentile= 900.0 ; 97.5th percentile= 2191.4999999999986 ; 99.5th percentile= 4398.900000000003\n",
      "\n",
      "trip= 305 ; taxi_id= 20000565 ; min= 15.0 max= 7710.0 ; mode= 465.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 780.0 ; 97.5th percentile= 1525.124999999996 ; 99.5th percentile= 2637.0749999999975\n",
      "\n",
      "trip= 306 ; taxi_id= 20000383 ; min= 15.0 max= 13020.0 ; mode= 540.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 930.0 ; 97.5th percentile= 1920.0 ; 99.5th percentile= 4244.999999999986\n",
      "\n",
      "trip= 307 ; taxi_id= 20000345 ; min= 15.0 max= 6960.0 ; mode= 495.0 ; median= 660.0 ; 25th percentile= 450.0 ; 75th percentile= 915.0 ; 97.5th percentile= 1755.0 ; 99.5th percentile= 2931.3750000000027\n",
      "\n",
      "trip= 308 ; taxi_id= 20000486 ; min= 15.0 max= 25830.0 ; mode= 465.0 ; median= 630.0 ; 25th percentile= 420.0 ; 75th percentile= 870.0 ; 97.5th percentile= 2100.0 ; 99.5th percentile= 4591.800000000039\n",
      "\n",
      "trip= 309 ; taxi_id= 20000496 ; min= 15.0 max= 37725.0 ; mode= 480.0 ; median= 720.0 ; 25th percentile= 420.0 ; 75th percentile= 1173.75 ; 97.5th percentile= 3537.3749999999973 ; 99.5th percentile= 7363.425000000007\n",
      "\n",
      "trip= 310 ; taxi_id= 20000436 ; min= 15.0 max= 31440.0 ; mode= 450.0 ; median= 705.0 ; 25th percentile= 450.0 ; 75th percentile= 1035.0 ; 97.5th percentile= 2925.0 ; 99.5th percentile= 7088.775000000028\n",
      "\n",
      "trip= 311 ; taxi_id= 20000325 ; min= 15.0 max= 9540.0 ; mode= 480.0 ; median= 570.0 ; 25th percentile= 375.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1710.0 ; 99.5th percentile= 2777.550000000001\n",
      "\n",
      "trip= 312 ; taxi_id= 20000281 ; min= 15.0 max= 14865.0 ; mode= 690.0 ; median= 705.0 ; 25th percentile= 465.0 ; 75th percentile= 960.0 ; 97.5th percentile= 1796.6250000000014 ; 99.5th percentile= 2536.9500000000016\n",
      "\n",
      "trip= 313 ; taxi_id= 20000549 ; min= 15.0 max= 5955.0 ; mode= 555.0 ; median= 600.0 ; 25th percentile= 420.0 ; 75th percentile= 855.0 ; 97.5th percentile= 1650.0 ; 99.5th percentile= 2610.0\n",
      "\n",
      "trip= 314 ; taxi_id= 20000393 ; min= 15.0 max= 9465.0 ; mode= 480.0 ; median= 795.0 ; 25th percentile= 536.25 ; 75th percentile= 1095.0 ; 97.5th percentile= 3030.0 ; 99.5th percentile= 5985.0\n",
      "\n",
      "trip= 315 ; taxi_id= 20000391 ; min= 30.0 max= 25215.0 ; mode= 510.0 ; median= 645.0 ; 25th percentile= 450.0 ; 75th percentile= 900.0 ; 97.5th percentile= 1860.0 ; 99.5th percentile= 3258.8250000000153\n",
      "\n",
      "trip= 316 ; taxi_id= 20000430 ; min= 15.0 max= 9540.0 ; mode= 480.0 ; median= 570.0 ; 25th percentile= 390.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1562.6250000000027 ; 99.5th percentile= 2490.0\n",
      "\n",
      "trip= 317 ; taxi_id= 20000020 ; min= 15.0 max= 10365.0 ; mode= 420.0 ; median= 570.0 ; 25th percentile= 405.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1935.0 ; 99.5th percentile= 3478.649999999998\n",
      "\n",
      "trip= 318 ; taxi_id= 20000207 ; min= 15.0 max= 12600.0 ; mode= 525.0 ; median= 675.0 ; 25th percentile= 465.0 ; 75th percentile= 990.0 ; 97.5th percentile= 2910.0 ; 99.5th percentile= 4641.449999999997\n",
      "\n",
      "trip= 319 ; taxi_id= 20000667 ; min= 15.0 max= 10290.0 ; mode= 390.0 ; median= 555.0 ; 25th percentile= 375.0 ; 75th percentile= 810.0 ; 97.5th percentile= 1735.4999999999973 ; 99.5th percentile= 3146.0999999999967\n",
      "\n",
      "trip= 320 ; taxi_id= 20000255 ; min= 15.0 max= 6660.0 ; mode= 465.0 ; median= 615.0 ; 25th percentile= 420.0 ; 75th percentile= 825.0 ; 97.5th percentile= 1575.0 ; 99.5th percentile= 2310.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j=1\n",
    "for i in list(dftest['TAXI_ID']):\n",
    "    tmp=dftrain[dftrain.TAXI_ID==i]['TRAVEL_TIME']\n",
    "    print('trip=',j, '; taxi_id=',i, '; min=', min(tmp), 'max=', max(tmp), '; mode=',st.mode(tmp), \n",
    "          '; median=',st.median(tmp), \n",
    "          '; 25th percentile=',np.percentile(tmp,25), \n",
    "          '; 75th percentile=',np.percentile(tmp,75), \n",
    "          '; 97.5th percentile=', np.percentile(tmp,97.5),\n",
    "          '; 99.5th percentile=',np.percentile(tmp,99.5))\n",
    "    print()\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=1\n",
    "for i in list(dftest['TAXI_ID']):\n",
    "    tmp=dftrain[dftrain.TAXI_ID==i]['TRAVEL_TIME']\n",
    "    print('trip=',j, '; taxi_id=',i, '; min=', min(tmp), 'max=', max(tmp), '; mode=',st.mode(tmp), \n",
    "          '; median=',st.median(tmp), \n",
    "          '; 25th percentile=',np.percentile(tmp,25), \n",
    "          '; 75th percentile=',np.percentile(tmp,75), \n",
    "          '; 97.5th percentile=', np.percentile(tmp,97.5),\n",
    "          '; 99.5th percentile=',np.percentile(tmp,99.5))\n",
    "    print()\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fe42e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626.1187500000005\n",
      "521.25\n",
      "462.76875000000075\n",
      "483.28125\n",
      "478.125\n",
      "1206.1874999999995\n",
      "483.0000000000007\n",
      "607.8749999999997\n",
      "453.89999999999986\n",
      "556.2749999999996\n",
      "609.1500000000002\n",
      "526.8562499999996\n",
      "509.62500000000034\n",
      "1132.3687499999978\n",
      "547.5\n",
      "601.40625\n",
      "508.85624999999976\n",
      "735.6750000000011\n",
      "600.8999999999992\n",
      "610.8749999999986\n",
      "493.125\n",
      "564.375\n",
      "551.25\n",
      "657.1875\n",
      "600.0\n",
      "629.4000000000005\n",
      "498.15000000000055\n",
      "609.375\n",
      "582.7874999999995\n",
      "560.625\n",
      "488.1937499999998\n",
      "555.9375\n",
      "487.5\n",
      "602.7749999999992\n",
      "646.875\n",
      "568.2375\n",
      "911.25\n",
      "611.9249999999994\n",
      "504.30000000000007\n",
      "551.25\n",
      "502.7437500000002\n",
      "495.75000000000017\n",
      "943.8375000000002\n",
      "521.9249999999994\n",
      "509.3624999999997\n",
      "731.25\n",
      "473.92499999999956\n",
      "552.0562499999996\n",
      "802.5\n",
      "502.8374999999997\n",
      "663.4124999999995\n",
      "763.3499999999998\n",
      "592.3312499999997\n",
      "551.25\n",
      "547.1250000000003\n",
      "480.0\n",
      "473.4750000000008\n",
      "546.1499999999987\n",
      "1010.625\n",
      "553.7250000000004\n",
      "575.6624999999999\n",
      "489.375\n",
      "465.6375000000003\n",
      "582.9937500000005\n",
      "457.5\n",
      "584.9250000000001\n",
      "495.2062499999994\n",
      "519.0187499999973\n",
      "562.4625000000001\n",
      "450.8999999999992\n",
      "572.5687499999998\n",
      "590.15625\n",
      "549.375\n",
      "731.25\n",
      "683.9999999999969\n",
      "582.5624999999997\n",
      "572.5687499999998\n",
      "610.0125000000003\n",
      "539.0625\n",
      "690.974999999994\n",
      "523.1812499999995\n",
      "582.7874999999995\n",
      "559.4624999999985\n",
      "862.5187500000004\n",
      "465.0\n",
      "1357.5\n",
      "593.8312500000009\n",
      "525.9375\n",
      "486.48750000000007\n",
      "521.4750000000015\n",
      "484.59374999999966\n",
      "502.4812499999996\n",
      "755.625\n",
      "513.5250000000002\n",
      "767.6250000000027\n",
      "1400.4187500000023\n",
      "534.4312499999995\n",
      "646.875\n",
      "508.125\n",
      "513.4312500000008\n",
      "689.2124999999999\n",
      "569.4374999999989\n",
      "713.0249999999978\n",
      "480.14999999999986\n",
      "553.4999999999997\n",
      "527.7749999999992\n",
      "604.7250000000008\n",
      "1073.55\n",
      "571.7250000000001\n",
      "580.3500000000008\n",
      "508.125\n",
      "511.7249999999993\n",
      "1318.1999999999998\n",
      "450.14999999999986\n",
      "609.375\n",
      "562.5\n",
      "673.125\n",
      "572.7562499999997\n",
      "465.3562500000001\n",
      "619.6312499999997\n",
      "451.48124999999993\n",
      "528.75\n",
      "519.0187499999973\n",
      "485.625\n",
      "476.25\n",
      "521.9249999999994\n",
      "498.35624999999993\n",
      "559.6875\n",
      "501.91874999999925\n",
      "502.0500000000004\n",
      "418.91250000000014\n",
      "610.8749999999986\n",
      "453.89999999999986\n",
      "677.2499999999997\n",
      "498.75\n",
      "802.5\n",
      "911.25\n",
      "535.3125\n",
      "512.6250000000002\n",
      "568.9124999999992\n",
      "922.5\n",
      "603.4687499999998\n",
      "559.0124999999998\n",
      "2747.8500000000104\n",
      "515.9812499999992\n",
      "753.75\n",
      "524.3999999999996\n",
      "601.40625\n",
      "503.09999999999945\n",
      "639.7499999999989\n",
      "509.62500000000034\n",
      "567.3937499999994\n",
      "566.1187500000005\n",
      "526.2374999999997\n",
      "472.5\n",
      "521.4750000000015\n",
      "515.9812499999992\n",
      "535.3125\n",
      "582.562499999998\n",
      "541.0312499999995\n",
      "556.875\n",
      "465.6375000000003\n",
      "595.3500000000008\n",
      "481.875\n",
      "520.4250000000008\n",
      "460.4812500000003\n",
      "525.9375\n",
      "537.3374999999999\n",
      "690.974999999994\n",
      "1229.343749999996\n",
      "629.0437499999996\n",
      "608.1000000000004\n",
      "526.875\n",
      "547.6687500000003\n",
      "689.4374999999997\n",
      "810.7875000000018\n",
      "657.1875\n",
      "543.0937499999993\n",
      "521.6999999999996\n",
      "461.0062499999998\n",
      "862.5187500000004\n",
      "474.375\n",
      "509.3624999999997\n",
      "584.2874999999998\n",
      "480.03749999999997\n",
      "984.974999999996\n",
      "683.9999999999969\n",
      "508.125\n",
      "602.7749999999992\n",
      "1318.1999999999998\n",
      "540.5625000000003\n",
      "505.5000000000007\n",
      "922.5\n",
      "619.6312499999997\n",
      "713.0249999999978\n",
      "513.0937500000002\n",
      "735.6750000000011\n",
      "568.2375\n",
      "888.5624999999993\n",
      "569.7375000000002\n",
      "576.5625\n",
      "1132.3687499999978\n",
      "528.75\n",
      "574.9312500000002\n",
      "927.0375000000001\n",
      "560.3250000000003\n",
      "509.1000000000008\n",
      "460.78125\n",
      "517.612499999999\n",
      "613.2749999999999\n",
      "503.15624999999983\n",
      "778.125\n",
      "1163.2875000000054\n",
      "436.83750000000003\n",
      "663.4124999999995\n",
      "551.25\n",
      "813.75\n",
      "484.59374999999966\n",
      "470.625\n",
      "549.375\n",
      "731.25\n",
      "1246.2187499999998\n",
      "646.875\n",
      "603.4687499999998\n",
      "459.375\n",
      "405.0\n",
      "1010.625\n",
      "491.3062500000012\n",
      "536.9625000000002\n",
      "508.125\n",
      "559.5749999999992\n",
      "508.125\n",
      "537.2624999999991\n",
      "504.375\n",
      "592.3312499999997\n",
      "448.125\n",
      "682.3124999999993\n",
      "553.4999999999997\n",
      "579.375\n",
      "546.1499999999987\n",
      "482.92500000000075\n",
      "521.25\n",
      "483.28125\n",
      "609.1500000000002\n",
      "453.89999999999986\n",
      "731.25\n",
      "551.25\n",
      "489.375\n",
      "646.875\n",
      "532.5\n",
      "527.0249999999999\n",
      "624.2250000000001\n",
      "711.7500000000007\n",
      "520.1250000000002\n",
      "574.9312500000002\n",
      "602.7749999999992\n",
      "541.5375000000004\n",
      "498.15000000000055\n",
      "695.625\n",
      "620.625\n",
      "476.0062499999998\n",
      "603.75\n",
      "525.0\n",
      "693.75\n",
      "502.4812499999996\n",
      "483.75\n",
      "476.25\n",
      "1245.0\n",
      "485.625\n",
      "684.375\n",
      "634.8374999999999\n",
      "542.6250000000027\n",
      "498.67500000000007\n",
      "418.91250000000014\n",
      "573.75\n",
      "496.06874999999945\n",
      "482.25000000000136\n",
      "1116.3750000000027\n",
      "475.2937499999996\n",
      "500.30624999999986\n",
      "549.375\n",
      "437.8125\n",
      "460.4812500000003\n",
      "488.58749999999986\n",
      "493.125\n",
      "512.7937499999996\n",
      "542.23125\n",
      "657.1875\n",
      "517.5187499999995\n",
      "462.67499999999956\n",
      "503.09999999999945\n",
      "1005.3749999999962\n",
      "538.125\n",
      "1053.2812499999975\n",
      "460.78125\n",
      "551.25\n",
      "484.59374999999966\n",
      "574.9874999999997\n",
      "450.8999999999992\n",
      "592.3312499999997\n",
      "626.1187500000005\n",
      "541.0312499999995\n",
      "541.5375000000004\n",
      "629.4000000000005\n",
      "476.0062499999998\n",
      "673.125\n",
      "534.0937500000007\n",
      "667.6687499999986\n",
      "1008.5624999999984\n",
      "862.5187500000004\n",
      "505.0125000000003\n",
      "531.9562500000001\n",
      "502.7999999999997\n",
      "902.6250000000018\n",
      "566.1187500000005\n",
      "468.88124999999945\n",
      "589.2749999999978\n",
      "753.75\n",
      "511.79999999999836\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for i in list(dftest['TAXI_ID']):\n",
    "    tmp=dftrain[(dftrain.TAXI_ID==i)]['TRAVEL_TIME']\n",
    "#     if i in list(dftest[(dftest['MONTH']==10)&(dftest['DAY']<=6) &(dftest['DAY']>=5)&(dftest['CALL_TYPE_A']==1)]['TAXI_ID']):\n",
    "#         p = np.percentile(tmp,99)\n",
    "#     else:\n",
    "    p=(np.percentile(tmp,25)+np.percentile(tmp,50)+np.percentile(tmp,75)+np.percentile(tmp,99))/8\n",
    "    j += 1\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285eaae0",
   "metadata": {},
   "source": [
    "# Current Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16875963",
   "metadata": {},
   "source": [
    "```\n",
    "for i in list(dftest['TAXI_ID']):\n",
    "    tmp=dftrain[dftrain.TAXI_ID==i]['TRAVEL_TIME']\n",
    "    p=(np.percentile(tmp,25)+np.percentile(tmp,50)+np.percentile(tmp,75)+np.percentile(tmp,99.5))/9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a717cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 00:27:50.310826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-02 00:27:50.313746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-02 00:27:50.314872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-02 00:27:50.608469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-02 00:27:50.610417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-02 00:27:50.611683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-02 00:27:51.387399: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-02 00:27:51.389179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-02 00:27:51.390581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "trips_id = []\n",
    "travel_preds = []\n",
    "\n",
    "for taxi_id in [20000542]:\n",
    "    new_train=dftrain[dftrain['TAXI_ID'] == taxi_id]\n",
    "#     train_corr=new_train[['TRAVEL_TIME', 'YEAR', 'MONTH', 'WEEK', 'DAY', 'HOUR', 'MIN', 'WEEKDAY']].corr()\n",
    "#     positive_corr_list=list(train_corr[train_corr > 0]['TRAVEL_TIME'].dropna().keys())\n",
    "#     positive_corr_list.remove('TRAVEL_TIME')\n",
    "\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for row in new_train.iterrows():\n",
    "    lst = []\n",
    "    for elem in ['WEEK']:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    Xtrain.append(np.array(lst))\n",
    "    value = row[1]['TRAVEL_TIME'] #/ 15 + 1\n",
    "    ytrain.append(np.array([value]))\n",
    "    \n",
    "    X_train = np.array(Xtrain)\n",
    "    y_train = np.array(ytrain)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    y_train = np.reshape(y_train, (-1,1))\n",
    "\n",
    "timesteps = X_train.shape[1]\n",
    "features = X_train.shape[2]\n",
    "num_classes = 1\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, features)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10,verbose=False)#, validation_data=(X_val, y_val))\n",
    "\n",
    "tmp_test=dftest[dftest['TAXI_ID'] == taxi_id]  \n",
    "for row in tmp_test.iterrows():\n",
    "    trip_id = row[1]['TRIP_ID']\n",
    "\n",
    "    lst = []\n",
    "    for elem in ['WEEK']:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    #Reshape your data either using array.reshape(-1, 1) if your data has a single feature \n",
    "    #or array.reshape(1, -1) if it contains a single sample.\n",
    "    pred = model.predict(np.array(lst).reshape(1,-1))[0][0]\n",
    "    print(trip_id,pred)\n",
    "#         preds.append(pred)\n",
    "\n",
    "#         travel_preds.append(pred)\n",
    "#         trips_id.append(trip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ea17d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 01:45:18.599020: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-28 01:45:18.601448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-28 01:45:18.603154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 505ms/step\n",
      "T1 0.0\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "T308 0.0\n"
     ]
    }
   ],
   "source": [
    "for row in tmp_test.iterrows():\n",
    "    trip_id = row[1]['TRIP_ID']\n",
    "\n",
    "    lst = []\n",
    "    for elem in ['WEEK']:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    #Reshape your data either using array.reshape(-1, 1) if your data has a single feature \n",
    "    #or array.reshape(1, -1) if it contains a single sample.\n",
    "    pred = model.predict(np.array(lst).reshape(1,-1))[0][0]\n",
    "    print(trip_id,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82f1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "12967e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in list(dftest['TAXI_ID']):\n",
    "    tmp=dftrain[(dftrain.TAXI_ID==i)]['TRAVEL_TIME']\n",
    "#     if i in list(dftest[(dftest['MONTH']==10)&(dftest['DAY']<=6) &(dftest['DAY']>=5)&(dftest['CALL_TYPE_A']==1)]['TAXI_ID']):\n",
    "#         p = np.percentile(tmp,99)\n",
    "#     else:\n",
    "    p=(np.percentile(tmp,25)+np.percentile(tmp,50)+np.percentile(tmp,75)+np.percentile(tmp,99.5))/9\n",
    "    preds.append(p)\n",
    "    #print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "27da7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635.0\n",
      "525.4999999999987\n",
      "439.36666666666497\n",
      "503.9583333333333\n",
      "484.54166666666725\n",
      "1244.3166666666677\n",
      "476.33333333333513\n",
      "616.8666666666664\n",
      "453.4666666666665\n",
      "579.316666666667\n",
      "621.5333333333305\n",
      "564.4416666666666\n",
      "522.4166666666664\n",
      "1170.1666666666704\n",
      "607.483333333333\n",
      "628.0999999999995\n",
      "491.15833333333364\n",
      "751.2833333333341\n",
      "625.6166666666664\n",
      "615.7916666666688\n",
      "464.3666666666665\n",
      "573.7916666666675\n",
      "530.0\n",
      "770.4166666666666\n",
      "610.4666666666648\n",
      "705.4333333333337\n",
      "510.0\n",
      "621.9166666666675\n",
      "576.3666666666662\n",
      "528.6166666666668\n",
      "506.31666666666507\n",
      "549.5833333333334\n",
      "478.6000000000013\n",
      "594.1333333333326\n",
      "681.6666666666666\n",
      "573.433333333334\n",
      "938.5249999999996\n",
      "611.7000000000007\n",
      "513.3333333333334\n",
      "546.6666666666666\n",
      "490.9416666666667\n",
      "517.3333333333327\n",
      "1019.4666666666672\n",
      "524.6166666666674\n",
      "509.7166666666665\n",
      "833.2416666666662\n",
      "466.5000000000009\n",
      "551.6666666666666\n",
      "919.7250000000024\n",
      "486.96666666666715\n",
      "661.3666666666662\n",
      "787.5166666666667\n",
      "809.8499999999998\n",
      "579.1499999999996\n",
      "526.3333333333321\n",
      "463.3333333333333\n",
      "442.71666666666687\n",
      "514.1916666666672\n",
      "1204.9166666666695\n",
      "629.433333333333\n",
      "588.3666666666659\n",
      "522.3000000000002\n",
      "461.6666666666667\n",
      "572.441666666667\n",
      "437.28333333333313\n",
      "652.3333333333297\n",
      "498.7000000000019\n",
      "538.5583333333337\n",
      "581.4666666666623\n",
      "466.23333333333295\n",
      "576.6666666666666\n",
      "586.25\n",
      "555.3999999999996\n",
      "766.6499999999996\n",
      "930.8666666666674\n",
      "582.7500000000024\n",
      "576.6666666666666\n",
      "683.3666666666674\n",
      "552.9166666666666\n",
      "665.8916666666679\n",
      "542.5250000000005\n",
      "576.3666666666662\n",
      "545.0\n",
      "1030.975000000003\n",
      "460.80000000000007\n",
      "1418.8499999999976\n",
      "667.491666666665\n",
      "556.25\n",
      "494.48333333333335\n",
      "517.2333333333321\n",
      "466.6666666666667\n",
      "526.6499999999996\n",
      "701.1333333333338\n",
      "526.400000000001\n",
      "842.8333333333345\n",
      "1689.7916666666683\n",
      "518.3333333333334\n",
      "681.6666666666666\n",
      "490.0\n",
      "579.4833333333327\n",
      "676.6666666666666\n",
      "591.25\n",
      "794.433333333333\n",
      "465.8999999999999\n",
      "560.916666666667\n",
      "532.4666666666659\n",
      "774.8000000000002\n",
      "1181.3333333333312\n",
      "607.5000000000015\n",
      "599.6916666666667\n",
      "503.76666666666705\n",
      "496.83333333333474\n",
      "1327.733333333328\n",
      "462.0666666666663\n",
      "715.9333333333356\n",
      "517.1666666666663\n",
      "696.6666666666652\n",
      "578.2333333333341\n",
      "458.3333333333333\n",
      "670.7833333333338\n",
      "448.899999999998\n",
      "520.7666666666652\n",
      "538.5583333333337\n",
      "486.20000000000044\n",
      "461.6666666666667\n",
      "524.6166666666674\n",
      "491.3166666666666\n",
      "550.633333333335\n",
      "513.3333333333334\n",
      "520.4666666666677\n",
      "425.1749999999993\n",
      "615.7916666666688\n",
      "453.4666666666665\n",
      "700.3333333333345\n",
      "492.8083333333333\n",
      "919.7250000000024\n",
      "938.5249999999996\n",
      "521.25\n",
      "586.6666666666666\n",
      "558.6833333333341\n",
      "962.1666666666699\n",
      "694.2499999999882\n",
      "624.0000000000055\n",
      "3185.441666666652\n",
      "541.6666666666666\n",
      "752.383333333333\n",
      "519.0000000000024\n",
      "628.0999999999995\n",
      "509.4333333333331\n",
      "645.1666666666688\n",
      "522.4166666666664\n",
      "631.5999999999985\n",
      "583.758333333335\n",
      "512.2166666666666\n",
      "476.2000000000019\n",
      "517.2333333333321\n",
      "541.6666666666666\n",
      "521.25\n",
      "852.1999999999995\n",
      "562.7083333333348\n",
      "575.0\n",
      "461.6666666666667\n",
      "622.3166666666672\n",
      "515.5333333333328\n",
      "514.4666666666641\n",
      "446.6666666666667\n",
      "556.25\n",
      "557.5249999999999\n",
      "665.8916666666679\n",
      "1545.6249999999961\n",
      "656.525\n",
      "662.6999999999983\n",
      "544.1333333333326\n",
      "548.3333333333334\n",
      "736.2499999999992\n",
      "879.3999999999991\n",
      "770.4166666666666\n",
      "606.0833333333327\n",
      "503.64166666666665\n",
      "458.3333333333333\n",
      "1030.975000000003\n",
      "465.0\n",
      "509.7166666666665\n",
      "594.5083333333371\n",
      "495.06666666666507\n",
      "1026.4583333333317\n",
      "930.8666666666674\n",
      "492.71666666666687\n",
      "594.1333333333326\n",
      "1327.733333333328\n",
      "517.9166666666674\n",
      "511.6666666666667\n",
      "962.1666666666699\n",
      "670.7833333333338\n",
      "794.433333333333\n",
      "498.8333333333321\n",
      "751.2833333333341\n",
      "573.433333333334\n",
      "1050.7499999999952\n",
      "583.0999999999995\n",
      "645.8333333333334\n",
      "1170.1666666666704\n",
      "520.7666666666652\n",
      "697.3499999999907\n",
      "987.6749999999993\n",
      "613.6666666666679\n",
      "521.4000000000002\n",
      "446.25\n",
      "531.6666666666666\n",
      "590.6166666666664\n",
      "491.1666666666679\n",
      "931.0666666666665\n",
      "1193.383333333333\n",
      "430.9916666666656\n",
      "661.3666666666662\n",
      "561.574999999998\n",
      "843.3333333333334\n",
      "466.6666666666667\n",
      "446.6666666666667\n",
      "555.3999999999996\n",
      "833.2416666666662\n",
      "1336.866666666668\n",
      "681.6666666666666\n",
      "694.2499999999882\n",
      "466.51666666666796\n",
      "386.6666666666667\n",
      "1204.9166666666695\n",
      "513.4166666666684\n",
      "559.8333333333267\n",
      "501.6666666666667\n",
      "616.8333333333354\n",
      "490.0\n",
      "523.9499999999998\n",
      "500.1333333333332\n",
      "809.8499999999998\n",
      "448.7999999999981\n",
      "700.0\n",
      "560.916666666667\n",
      "601.3833333333332\n",
      "514.1916666666672\n",
      "475.9333333333325\n",
      "525.4999999999987\n",
      "503.9583333333333\n",
      "621.5333333333305\n",
      "453.4666666666665\n",
      "766.6499999999996\n",
      "546.6666666666666\n",
      "522.3000000000002\n",
      "681.6666666666666\n",
      "525.2833333333334\n",
      "516.7333333333332\n",
      "618.0416666666648\n",
      "830.6666666666661\n",
      "512.8333333333316\n",
      "697.3499999999907\n",
      "594.1333333333326\n",
      "527.3499999999998\n",
      "510.0\n",
      "841.4083333333323\n",
      "668.1000000000009\n",
      "486.34166666666636\n",
      "613.6666666666633\n",
      "527.6249999999997\n",
      "756.4083333333338\n",
      "526.6499999999996\n",
      "483.73333333333295\n",
      "461.6666666666667\n",
      "1162.5\n",
      "486.20000000000044\n",
      "701.233333333333\n",
      "655.0\n",
      "627.3000000000017\n",
      "488.26666666666523\n",
      "425.1749999999993\n",
      "546.1166666666668\n",
      "482.97499999999974\n",
      "478.3333333333333\n",
      "1112.2333333333336\n",
      "471.2416666666665\n",
      "476.5249999999999\n",
      "555.3999999999996\n",
      "433.23333333333113\n",
      "446.6666666666667\n",
      "465.4833333333333\n",
      "464.3666666666665\n",
      "534.433333333333\n",
      "579.0999999999985\n",
      "770.4166666666666\n",
      "490.84166666666687\n",
      "450.6333333333335\n",
      "509.4333333333331\n",
      "1298.8333333333278\n",
      "551.1500000000046\n",
      "1197.6250000000057\n",
      "446.25\n",
      "561.574999999998\n",
      "466.6666666666667\n",
      "657.2166666666666\n",
      "466.23333333333295\n",
      "809.8499999999998\n",
      "635.0\n",
      "562.7083333333348\n",
      "527.3499999999998\n",
      "705.4333333333337\n",
      "486.34166666666636\n",
      "696.6666666666652\n",
      "550.7083333333336\n",
      "723.5333333333377\n",
      "1075.2416666666675\n",
      "1030.975000000003\n",
      "505.2833333333335\n",
      "518.5500000000002\n",
      "498.3333333333333\n",
      "934.5833333333334\n",
      "583.758333333335\n",
      "473.3333333333333\n",
      "584.8499999999998\n",
      "752.383333333333\n",
      "542.8999999999996\n",
      "463.3333333333333\n"
     ]
    }
   ],
   "source": [
    "all_ids = list(test_data.TRIP_ID)\n",
    "\n",
    "file1 = open(\"pred_151b.csv\", \"w\")\n",
    "n = len(all_ids)\n",
    "line='\"TRIP_ID\",\"TRAVEL_TIME\"\\n'\n",
    "file1.write(line)\n",
    "for i in range(n):\n",
    "    if i+1 != n:\n",
    "        line = '\"' + all_ids[i] + '\",' + str(preds[i]) + '\\n'\n",
    "    else:\n",
    "        line = '\"' + all_ids[i] + '\",'  + str(preds[i])\n",
    "    file1.write(line)\n",
    "    print(preds[i])\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a1783e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.MONTH.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "13015b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>T288</td>\n",
       "      <td>20000334</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "280    T288  20000334  2014     11    44    1     2   40        5   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "280            0            0            1            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "280             0  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[(dftest.MONTH==11) & (dftest.HOUR==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a8f6559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dftrain[(dftrain.MONTH==11) & (dftrain.HOUR==2)]['TRAVEL_TIME'],25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c29d4f",
   "metadata": {},
   "source": [
    "On the test set\n",
    "- Aug: 14/8\n",
    "- Sep: 30/9\n",
    "- Oct: 6/10\n",
    "- Nov: 1/11\n",
    "- Dec: 21/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "341bc4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TRIP_ID, TAXI_ID, YEAR, MONTH, WEEK, DAY, HOUR, MIN, WEEKDAY, CALL_TYPE_A, CALL_TYPE_B, CALL_TYPE_C, ORIGIN_CALL, ORIGIN_STAND, MISSING_DATA]\n",
       "Index: []"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate(dftest[(dftest.MONTH==10)]['TAXI_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c56d10fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>T34</td>\n",
       "      <td>20000129</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>T196</td>\n",
       "      <td>20000129</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>T263</td>\n",
       "      <td>20000129</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "33      T34  20000129  2014      8    33   14    17   59        3   \n",
       "188    T196  20000129  2014     10    41    6    17   41        0   \n",
       "255    T263  20000129  2014     11    44    1     3   56        5   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "33             0            0            1            1             1   \n",
       "188            0            1            0            1             1   \n",
       "255            0            0            1            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "33              0  \n",
       "188             0  \n",
       "255             0  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest.TAXI_ID==20000129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "45411af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000542</td>\n",
       "      <td>1408039037</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000108</td>\n",
       "      <td>1408038611</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000370</td>\n",
       "      <td>1408038568</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000492</td>\n",
       "      <td>1408039090</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20000621</td>\n",
       "      <td>1408039177</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>A</td>\n",
       "      <td>70885.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000430</td>\n",
       "      <td>1419171485</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000020</td>\n",
       "      <td>1419170802</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000207</td>\n",
       "      <td>1419172121</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>A</td>\n",
       "      <td>76232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000667</td>\n",
       "      <td>1419171980</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>A</td>\n",
       "      <td>31208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000255</td>\n",
       "      <td>1419171420</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID   TIMESTAMP  \\\n",
       "0        T1         B          NaN          15.0  20000542  1408039037   \n",
       "1        T2         B          NaN          57.0  20000108  1408038611   \n",
       "2        T3         B          NaN          15.0  20000370  1408038568   \n",
       "3        T4         B          NaN          53.0  20000492  1408039090   \n",
       "4        T5         B          NaN          18.0  20000621  1408039177   \n",
       "..      ...       ...          ...           ...       ...         ...   \n",
       "315    T323         A      70885.0           NaN  20000430  1419171485   \n",
       "316    T324         B          NaN          53.0  20000020  1419170802   \n",
       "317    T325         C          NaN           NaN  20000207  1419172121   \n",
       "318    T326         A      76232.0           NaN  20000667  1419171980   \n",
       "319    T327         A      31208.0           NaN  20000255  1419171420   \n",
       "\n",
       "    DAY_TYPE  MISSING_DATA  \n",
       "0          A         False  \n",
       "1          A         False  \n",
       "2          A         False  \n",
       "3          A         False  \n",
       "4          A         False  \n",
       "..       ...           ...  \n",
       "315        A         False  \n",
       "316        A         False  \n",
       "317        A         False  \n",
       "318        A         False  \n",
       "319        A         False  \n",
       "\n",
       "[320 rows x 8 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52297085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d1e78a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=pd.read_csv('outputs/withBracket_pred.csv')\n",
    "model2=pd.read_csv('outputs/withPercentile_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "825618c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=(model1.TRAVEL_TIME + model2.TRAVEL_TIME)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "f9ce5548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      555.000000\n",
       "1      608.750000\n",
       "2      449.183333\n",
       "3      488.854167\n",
       "4      518.020833\n",
       "          ...    \n",
       "315    484.416667\n",
       "316    521.175000\n",
       "317    851.191667\n",
       "318    605.950000\n",
       "319    549.666667\n",
       "Name: TRAVEL_TIME, Length: 320, dtype: float64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8256211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555.0\n",
      "608.7499999999993\n",
      "449.1833333333325\n",
      "488.85416666666663\n",
      "518.0208333333336\n",
      "1050.1583333333338\n",
      "532.7916666666675\n",
      "758.1833333333332\n",
      "476.23333333333323\n",
      "573.1583333333335\n",
      "567.7666666666653\n",
      "662.7208333333333\n",
      "479.9583333333332\n",
      "1123.5833333333353\n",
      "680.4916666666666\n",
      "697.5499999999997\n",
      "589.8291666666668\n",
      "797.0166666666671\n",
      "579.8083333333332\n",
      "577.3958333333344\n",
      "586.6833333333333\n",
      "662.8958333333337\n",
      "604.875\n",
      "653.7083333333333\n",
      "669.7333333333324\n",
      "631.9666666666669\n",
      "505.625\n",
      "675.7083333333337\n",
      "528.3083333333332\n",
      "595.5583333333334\n",
      "455.9083333333325\n",
      "654.2916666666667\n",
      "538.0500000000006\n",
      "636.8166666666664\n",
      "814.5833333333333\n",
      "487.466666666667\n",
      "911.7624999999998\n",
      "690.3500000000004\n",
      "561.6666666666667\n",
      "590.2083333333333\n",
      "702.0958333333333\n",
      "468.79166666666634\n",
      "856.9833333333336\n",
      "524.5583333333336\n",
      "528.1083333333332\n",
      "661.3708333333332\n",
      "599.7500000000005\n",
      "794.5833333333333\n",
      "821.8625000000012\n",
      "559.1083333333336\n",
      "667.4333333333332\n",
      "718.8833333333333\n",
      "784.3\n",
      "605.3249999999998\n",
      "626.1666666666661\n",
      "484.29166666666663\n",
      "524.2333333333335\n",
      "626.5958333333335\n",
      "1108.4583333333348\n",
      "616.2166666666665\n",
      "648.1833333333329\n",
      "643.4000000000001\n",
      "530.7083333333334\n",
      "555.0958333333335\n",
      "549.3916666666665\n",
      "600.6666666666649\n",
      "542.1000000000009\n",
      "671.0291666666669\n",
      "575.1083333333311\n",
      "485.86666666666645\n",
      "647.0833333333333\n",
      "824.375\n",
      "569.6999999999998\n",
      "794.3249999999998\n",
      "751.3083333333336\n",
      "591.6250000000011\n",
      "574.5833333333333\n",
      "735.6833333333336\n",
      "705.7083333333333\n",
      "884.1958333333339\n",
      "618.5125000000003\n",
      "552.4333333333332\n",
      "654.0\n",
      "818.9875000000015\n",
      "485.40000000000003\n",
      "1027.0499999999988\n",
      "731.7458333333325\n",
      "660.25\n",
      "586.2416666666667\n",
      "487.11666666666605\n",
      "438.83333333333337\n",
      "732.0749999999998\n",
      "646.8166666666668\n",
      "635.7000000000005\n",
      "640.4166666666672\n",
      "1648.1458333333342\n",
      "584.9166666666667\n",
      "702.8333333333333\n",
      "612.5\n",
      "631.7416666666663\n",
      "576.2083333333333\n",
      "662.625\n",
      "735.2166666666665\n",
      "457.82499999999993\n",
      "521.9583333333335\n",
      "502.85833333333295\n",
      "646.6500000000001\n",
      "876.2916666666656\n",
      "671.7500000000007\n",
      "583.4708333333333\n",
      "621.3833333333336\n",
      "577.2916666666674\n",
      "937.866666666664\n",
      "502.2833333333332\n",
      "663.9666666666678\n",
      "658.5833333333331\n",
      "603.5833333333326\n",
      "587.866666666667\n",
      "586.1666666666666\n",
      "686.3916666666669\n",
      "570.449999999999\n",
      "538.8833333333325\n",
      "517.0291666666669\n",
      "621.1000000000003\n",
      "491.33333333333337\n",
      "484.0583333333337\n",
      "606.6583333333333\n",
      "653.8166666666675\n",
      "493.7916666666667\n",
      "548.9833333333338\n",
      "433.83749999999964\n",
      "626.2708333333344\n",
      "630.7333333333332\n",
      "684.0416666666672\n",
      "515.7791666666667\n",
      "871.8625000000012\n",
      "912.0124999999998\n",
      "501.625\n",
      "686.5833333333333\n",
      "591.341666666667\n",
      "838.0833333333351\n",
      "589.1249999999941\n",
      "698.7500000000027\n",
      "2277.720833333326\n",
      "607.5833333333333\n",
      "754.1916666666665\n",
      "567.0000000000011\n",
      "697.0499999999997\n",
      "525.9666666666666\n",
      "673.3333333333344\n",
      "492.2083333333332\n",
      "718.0499999999993\n",
      "738.8791666666675\n",
      "595.3583333333333\n",
      "457.72500000000093\n",
      "647.9916666666661\n",
      "481.5833333333333\n",
      "687.5\n",
      "699.5999999999997\n",
      "602.1041666666674\n",
      "600.5\n",
      "587.3333333333334\n",
      "572.5333333333335\n",
      "525.0166666666664\n",
      "575.233333333332\n",
      "466.45833333333337\n",
      "564.625\n",
      "683.2624999999999\n",
      "821.4458333333339\n",
      "1069.687499999998\n",
      "651.7625\n",
      "656.3499999999992\n",
      "483.0666666666663\n",
      "531.1666666666667\n",
      "765.6249999999995\n",
      "765.6999999999996\n",
      "702.7083333333333\n",
      "569.2916666666663\n",
      "589.0708333333333\n",
      "547.6666666666666\n",
      "794.4875000000015\n",
      "557.25\n",
      "566.9833333333332\n",
      "685.0041666666685\n",
      "433.2833333333325\n",
      "1012.7291666666658\n",
      "862.1833333333336\n",
      "531.1083333333335\n",
      "661.8166666666664\n",
      "1269.866666666664\n",
      "681.2083333333337\n",
      "573.4583333333334\n",
      "836.5833333333351\n",
      "975.5166666666669\n",
      "786.2166666666665\n",
      "635.9166666666661\n",
      "966.2666666666671\n",
      "582.0916666666669\n",
      "829.1249999999976\n",
      "586.0499999999997\n",
      "641.9166666666667\n",
      "1164.0833333333353\n",
      "517.8833333333325\n",
      "738.1749999999954\n",
      "1160.2124999999996\n",
      "554.5833333333339\n",
      "625.7\n",
      "510.625\n",
      "566.2083333333333\n",
      "659.5583333333332\n",
      "589.2083333333339\n",
      "744.7833333333332\n",
      "979.6916666666665\n",
      "558.2458333333328\n",
      "703.5583333333332\n",
      "579.412499999999\n",
      "698.4166666666667\n",
      "485.33333333333337\n",
      "464.08333333333337\n",
      "644.6999999999998\n",
      "798.1208333333332\n",
      "1165.1833333333338\n",
      "755.5833333333333\n",
      "753.6249999999941\n",
      "553.008333333334\n",
      "403.20833333333337\n",
      "1266.7083333333348\n",
      "603.2083333333342\n",
      "605.4166666666633\n",
      "543.4583333333334\n",
      "518.7916666666677\n",
      "526.25\n",
      "625.4749999999999\n",
      "472.3166666666666\n",
      "627.925\n",
      "446.02499999999907\n",
      "627.5\n",
      "536.4583333333335\n",
      "581.6916666666666\n",
      "496.5958333333336\n",
      "496.21666666666624\n",
      "524.9999999999993\n",
      "441.10416666666663\n",
      "639.5166666666653\n",
      "460.48333333333323\n",
      "711.9499999999998\n",
      "555.8333333333333\n",
      "505.6500000000001\n",
      "592.4583333333333\n",
      "511.8916666666667\n",
      "541.3666666666666\n",
      "694.5208333333323\n",
      "782.333333333333\n",
      "516.6666666666658\n",
      "630.7999999999954\n",
      "626.8166666666664\n",
      "537.925\n",
      "512.125\n",
      "601.4541666666662\n",
      "522.3000000000004\n",
      "467.79583333333323\n",
      "658.3333333333317\n",
      "533.0624999999998\n",
      "690.3291666666669\n",
      "576.0749999999998\n",
      "489.36666666666645\n",
      "472.33333333333337\n",
      "999.25\n",
      "482.35000000000025\n",
      "627.6166666666666\n",
      "568.875\n",
      "609.9000000000008\n",
      "476.3833333333326\n",
      "399.71249999999964\n",
      "540.8083333333334\n",
      "472.73749999999984\n",
      "477.91666666666663\n",
      "812.1166666666668\n",
      "498.7458333333333\n",
      "565.7624999999999\n",
      "558.8249999999998\n",
      "400.86666666666554\n",
      "437.08333333333337\n",
      "460.3666666666667\n",
      "484.4333333333333\n",
      "541.7166666666665\n",
      "516.2999999999993\n",
      "678.9583333333333\n",
      "525.1708333333335\n",
      "437.0666666666667\n",
      "526.9666666666666\n",
      "1033.9166666666638\n",
      "640.5750000000023\n",
      "1042.8125000000027\n",
      "525.625\n",
      "477.287499999999\n",
      "556.0833333333334\n",
      "556.6083333333333\n",
      "424.36666666666645\n",
      "641.925\n",
      "672.25\n",
      "505.8541666666674\n",
      "594.675\n",
      "516.7166666666669\n",
      "458.92083333333323\n",
      "592.5833333333326\n",
      "602.3541666666667\n",
      "638.0166666666689\n",
      "1022.1208333333338\n",
      "936.9875000000015\n",
      "453.64166666666677\n",
      "591.4000000000001\n",
      "586.2916666666666\n",
      "1154.7916666666667\n",
      "581.3791666666675\n",
      "484.41666666666663\n",
      "521.175\n",
      "851.1916666666665\n",
      "605.9499999999998\n",
      "549.6666666666666\n"
     ]
    }
   ],
   "source": [
    "all_ids = list(test_data.TRIP_ID)\n",
    "\n",
    "file1 = open(\"pred_151b.csv\", \"w\")\n",
    "n = len(all_ids)\n",
    "line='\"TRIP_ID\",\"TRAVEL_TIME\"\\n'\n",
    "file1.write(line)\n",
    "for i in range(n):\n",
    "    if i+1 != n:\n",
    "        line = '\"' + all_ids[i] + '\",' + str(preds[i]) + '\\n'\n",
    "    else:\n",
    "        line = '\"' + all_ids[i] + '\",'  + str(preds[i])\n",
    "    file1.write(line)\n",
    "    print(preds[i])\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ecbe0665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626.1187500000005\n",
      "521.25\n",
      "462.7687500000008\n",
      "483.28125\n",
      "478.125\n",
      "1206.1874999999995\n",
      "483.0000000000007\n",
      "607.8749999999997\n",
      "453.8999999999999\n",
      "556.2749999999996\n",
      "609.1500000000002\n",
      "526.8562499999996\n",
      "509.62500000000034\n",
      "1132.3687499999978\n",
      "547.5\n",
      "601.40625\n",
      "508.85624999999976\n",
      "735.6750000000011\n",
      "600.8999999999992\n",
      "610.8749999999986\n",
      "493.125\n",
      "564.375\n",
      "551.25\n",
      "657.1875\n",
      "600.0\n",
      "629.4000000000005\n",
      "498.15000000000055\n",
      "609.375\n",
      "582.7874999999995\n",
      "560.625\n",
      "488.1937499999998\n",
      "555.9375\n",
      "487.5\n",
      "602.7749999999992\n",
      "646.875\n",
      "568.2375\n",
      "911.25\n",
      "611.9249999999994\n",
      "504.30000000000007\n",
      "551.25\n",
      "502.7437500000002\n",
      "495.75000000000017\n",
      "943.8375000000002\n",
      "521.9249999999994\n",
      "509.3624999999997\n",
      "731.25\n",
      "473.9249999999996\n",
      "552.0562499999996\n",
      "802.5\n",
      "502.8374999999997\n",
      "663.4124999999995\n",
      "763.3499999999998\n",
      "592.3312499999997\n",
      "551.25\n",
      "547.1250000000003\n",
      "480.0\n",
      "473.4750000000008\n",
      "546.1499999999987\n",
      "1010.625\n",
      "553.7250000000004\n",
      "575.6624999999999\n",
      "489.375\n",
      "465.6375000000003\n",
      "582.9937500000005\n",
      "457.5\n",
      "584.9250000000001\n",
      "495.2062499999994\n",
      "519.0187499999973\n",
      "562.4625000000001\n",
      "450.8999999999992\n",
      "572.5687499999998\n",
      "590.15625\n",
      "549.375\n",
      "731.25\n",
      "683.9999999999969\n",
      "582.5624999999997\n",
      "572.5687499999998\n",
      "610.0125000000003\n",
      "539.0625\n",
      "690.974999999994\n",
      "523.1812499999995\n",
      "582.7874999999995\n",
      "559.4624999999985\n",
      "862.5187500000004\n",
      "465.0\n",
      "1357.5\n",
      "593.8312500000009\n",
      "525.9375\n",
      "486.48750000000007\n",
      "521.4750000000015\n",
      "484.59374999999966\n",
      "502.4812499999996\n",
      "755.625\n",
      "513.5250000000002\n",
      "767.6250000000027\n",
      "1400.4187500000023\n",
      "534.4312499999995\n",
      "646.875\n",
      "508.125\n",
      "513.4312500000008\n",
      "689.2124999999999\n",
      "569.4374999999989\n",
      "713.0249999999978\n",
      "480.1499999999999\n",
      "553.4999999999997\n",
      "527.7749999999992\n",
      "604.7250000000008\n",
      "1073.55\n",
      "571.7250000000001\n",
      "580.3500000000008\n",
      "508.125\n",
      "511.7249999999993\n",
      "1318.1999999999998\n",
      "450.1499999999999\n",
      "609.375\n",
      "562.5\n",
      "673.125\n",
      "572.7562499999997\n",
      "465.3562500000001\n",
      "619.6312499999997\n",
      "451.48124999999993\n",
      "528.75\n",
      "519.0187499999973\n",
      "485.625\n",
      "476.25\n",
      "521.9249999999994\n",
      "498.35624999999993\n",
      "559.6875\n",
      "501.9187499999993\n",
      "502.0500000000004\n",
      "418.91250000000014\n",
      "610.8749999999986\n",
      "453.8999999999999\n",
      "677.2499999999997\n",
      "498.75\n",
      "802.5\n",
      "911.25\n",
      "535.3125\n",
      "512.6250000000002\n",
      "568.9124999999992\n",
      "922.5\n",
      "603.4687499999998\n",
      "559.0124999999998\n",
      "2747.8500000000104\n",
      "515.9812499999992\n",
      "753.75\n",
      "524.3999999999996\n",
      "601.40625\n",
      "503.09999999999945\n",
      "639.7499999999989\n",
      "509.62500000000034\n",
      "567.3937499999994\n",
      "566.1187500000005\n",
      "526.2374999999997\n",
      "472.5\n",
      "521.4750000000015\n",
      "515.9812499999992\n",
      "535.3125\n",
      "582.562499999998\n",
      "541.0312499999995\n",
      "556.875\n",
      "465.6375000000003\n",
      "595.3500000000008\n",
      "481.875\n",
      "520.4250000000008\n",
      "460.4812500000003\n",
      "525.9375\n",
      "537.3374999999999\n",
      "690.974999999994\n",
      "1229.343749999996\n",
      "629.0437499999996\n",
      "608.1000000000004\n",
      "526.875\n",
      "547.6687500000003\n",
      "689.4374999999997\n",
      "810.7875000000018\n",
      "657.1875\n",
      "543.0937499999993\n",
      "521.6999999999996\n",
      "461.0062499999998\n",
      "862.5187500000004\n",
      "474.375\n",
      "509.3624999999997\n",
      "584.2874999999998\n",
      "480.0375\n",
      "984.974999999996\n",
      "683.9999999999969\n",
      "508.125\n",
      "602.7749999999992\n",
      "1318.1999999999998\n",
      "540.5625000000003\n",
      "505.5000000000007\n",
      "922.5\n",
      "619.6312499999997\n",
      "713.0249999999978\n",
      "513.0937500000002\n",
      "735.6750000000011\n",
      "568.2375\n",
      "888.5624999999993\n",
      "569.7375000000002\n",
      "576.5625\n",
      "1132.3687499999978\n",
      "528.75\n",
      "574.9312500000002\n",
      "927.0375\n",
      "560.3250000000003\n",
      "509.1000000000008\n",
      "460.78125\n",
      "517.612499999999\n",
      "613.2749999999999\n",
      "503.15624999999983\n",
      "778.125\n",
      "1163.2875000000054\n",
      "436.8375\n",
      "663.4124999999995\n",
      "551.25\n",
      "813.75\n",
      "484.59374999999966\n",
      "470.625\n",
      "549.375\n",
      "731.25\n",
      "1246.2187499999998\n",
      "646.875\n",
      "603.4687499999998\n",
      "459.375\n",
      "405.0\n",
      "1010.625\n",
      "491.3062500000012\n",
      "536.9625000000002\n",
      "508.125\n",
      "559.5749999999992\n",
      "508.125\n",
      "537.2624999999991\n",
      "504.375\n",
      "592.3312499999997\n",
      "448.125\n",
      "682.3124999999993\n",
      "553.4999999999997\n",
      "579.375\n",
      "546.1499999999987\n",
      "482.9250000000008\n",
      "521.25\n",
      "483.28125\n",
      "609.1500000000002\n",
      "453.8999999999999\n",
      "731.25\n",
      "551.25\n",
      "489.375\n",
      "646.875\n",
      "532.5\n",
      "527.0249999999999\n",
      "624.2250000000001\n",
      "711.7500000000007\n",
      "520.1250000000002\n",
      "574.9312500000002\n",
      "602.7749999999992\n",
      "541.5375000000004\n",
      "498.15000000000055\n",
      "695.625\n",
      "620.625\n",
      "476.0062499999998\n",
      "603.75\n",
      "525.0\n",
      "693.75\n",
      "502.4812499999996\n",
      "483.75\n",
      "476.25\n",
      "1245.0\n",
      "485.625\n",
      "684.375\n",
      "634.8374999999999\n",
      "542.6250000000027\n",
      "498.67500000000007\n",
      "418.91250000000014\n",
      "573.75\n",
      "496.06874999999945\n",
      "482.25000000000136\n",
      "1116.3750000000027\n",
      "475.2937499999996\n",
      "500.3062499999999\n",
      "549.375\n",
      "437.8125\n",
      "460.4812500000003\n",
      "488.5874999999999\n",
      "493.125\n",
      "512.7937499999996\n",
      "542.23125\n",
      "657.1875\n",
      "517.5187499999995\n",
      "462.6749999999996\n",
      "503.09999999999945\n",
      "1005.3749999999962\n",
      "538.125\n",
      "1053.2812499999975\n",
      "460.78125\n",
      "551.25\n",
      "484.59374999999966\n",
      "574.9874999999997\n",
      "450.8999999999992\n",
      "592.3312499999997\n",
      "626.1187500000005\n",
      "541.0312499999995\n",
      "541.5375000000004\n",
      "629.4000000000005\n",
      "476.0062499999998\n",
      "673.125\n",
      "534.0937500000007\n",
      "667.6687499999986\n",
      "1008.5624999999984\n",
      "862.5187500000004\n",
      "505.0125000000003\n",
      "531.9562500000001\n",
      "502.7999999999997\n",
      "902.6250000000018\n",
      "566.1187500000005\n",
      "468.88124999999945\n",
      "589.2749999999978\n",
      "753.75\n",
      "511.7999999999984\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "for i in model2.TRAVEL_TIME:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c58a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e95daee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='LEN'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df_cleaned.LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ce53afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxis=list(dftest['TAXI_ID'])\n",
    "# weeks=list(dftest['WEEK'])\n",
    "# for i in [20000434]:\n",
    "# taxi=taxis[i]\n",
    "# week=weeks[i]\n",
    "tmpdf = df_filtered\n",
    "Q1 = tmpdf['TRAVEL_TIME'].quantile(0.25)\n",
    "Q3 = tmpdf['TRAVEL_TIME'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the DataFrame to remove outliers\n",
    "df_filtered1 = tmpdf[(tmpdf['TRAVEL_TIME'] >= lower_bound) \n",
    "                     & (tmpdf['TRAVEL_TIME'] <= upper_bound)]\n",
    "# if len(df_filtered) > 0:\n",
    "#     print(st.mode(df_filtered['TRAVEL_TIME']))\n",
    "# else:\n",
    "#     print('skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7b99f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d268842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>1372670258620000455</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000455</td>\n",
       "      <td>1372670258</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.611101,41.15529],[-8.611902,41.155371],[-...</td>\n",
       "      <td>13815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>1372684398620000352</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000352</td>\n",
       "      <td>1372684398</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.602227,41.150583],[-8.602344,41.152077],[...</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>1372701407620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372701407</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.661789,41.147406],[-8.664183,41.147955],[...</td>\n",
       "      <td>12015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490</th>\n",
       "      <td>1372665682620000084</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000084</td>\n",
       "      <td>1372665682</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630793,41.154606],[-8.630829,41.154309],[...</td>\n",
       "      <td>13125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>1372781638620000250</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000250</td>\n",
       "      <td>1372781638</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-7.735365,41.294907],[-7.73559,41.295087],[-...</td>\n",
       "      <td>10665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708861</th>\n",
       "      <td>1404133852620000197</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20000197</td>\n",
       "      <td>1404133852</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.609643,41.151303],[-8.609652,41.151303],[...</td>\n",
       "      <td>12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708941</th>\n",
       "      <td>1404130881620000206</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000206</td>\n",
       "      <td>1404130881</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.602065,41.150232],[-8.602137,41.150313],[...</td>\n",
       "      <td>13125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709073</th>\n",
       "      <td>1404120069620000073</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000073</td>\n",
       "      <td>1404120069</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.667414,41.161671],[-8.667423,41.161671],[...</td>\n",
       "      <td>23430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709232</th>\n",
       "      <td>1404108872620000902</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000902</td>\n",
       "      <td>1404108872</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.682084,41.158773],[-8.682102,41.158764],[...</td>\n",
       "      <td>15075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709625</th>\n",
       "      <td>1404076013620000520</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1404076013</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610903,41.145741],[-8.610219,41.146317],[...</td>\n",
       "      <td>10380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1026 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "2248     1372670258620000455         C          NaN           NaN  20000455   \n",
       "3545     1372684398620000352         C          NaN           NaN  20000352   \n",
       "4029     1372701407620000520         C          NaN           NaN  20000520   \n",
       "5490     1372665682620000084         C          NaN           NaN  20000084   \n",
       "10568    1372781638620000250         C          NaN           NaN  20000250   \n",
       "...                      ...       ...          ...           ...       ...   \n",
       "1708861  1404133852620000197         B          NaN          60.0  20000197   \n",
       "1708941  1404130881620000206         C          NaN           NaN  20000206   \n",
       "1709073  1404120069620000073         C          NaN           NaN  20000073   \n",
       "1709232  1404108872620000902         C          NaN           NaN  20000902   \n",
       "1709625  1404076013620000520         B          NaN          57.0  20000520   \n",
       "\n",
       "          TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "2248     1372670258        A         False   \n",
       "3545     1372684398        A         False   \n",
       "4029     1372701407        A         False   \n",
       "5490     1372665682        A         False   \n",
       "10568    1372781638        A         False   \n",
       "...             ...      ...           ...   \n",
       "1708861  1404133852        A         False   \n",
       "1708941  1404130881        A         False   \n",
       "1709073  1404120069        A         False   \n",
       "1709232  1404108872        A         False   \n",
       "1709625  1404076013        A         False   \n",
       "\n",
       "                                                  POLYLINE  TRAVEL_TIME  \n",
       "2248     [[-8.611101,41.15529],[-8.611902,41.155371],[-...        13815  \n",
       "3545     [[-8.602227,41.150583],[-8.602344,41.152077],[...        11790  \n",
       "4029     [[-8.661789,41.147406],[-8.664183,41.147955],[...        12015  \n",
       "5490     [[-8.630793,41.154606],[-8.630829,41.154309],[...        13125  \n",
       "10568    [[-7.735365,41.294907],[-7.73559,41.295087],[-...        10665  \n",
       "...                                                    ...          ...  \n",
       "1708861  [[-8.609643,41.151303],[-8.609652,41.151303],[...        12345  \n",
       "1708941  [[-8.602065,41.150232],[-8.602137,41.150313],[...        13125  \n",
       "1709073  [[-8.667414,41.161671],[-8.667423,41.161671],[...        23430  \n",
       "1709232  [[-8.682084,41.158773],[-8.682102,41.158764],[...        15075  \n",
       "1709625  [[-8.610903,41.145741],[-8.610219,41.146317],[...        10380  \n",
       "\n",
       "[1026 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[df_filtered.TRAVEL_TIME > 10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee993966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10785.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(df_filtered.TRAVEL_TIME,99.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98a35008",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_ids=list(dftest.TAXI_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d42fb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80df1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = df.POLYLINE.apply(lambda x: max((x.count('[')-1-1)*15, 0)) # if (x.count('[')-1-1)*15 > 0 else np.nan)\n",
    "df = df.assign(TRAVEL_TIME = times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d31e6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df.MISSING_DATA != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95a271f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.TRAVEL_TIME.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5044d8",
   "metadata": {},
   "source": [
    "- no missing data in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e2201f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[df_filtered.TRAVEL_TIME < np.percentile(df_filtered.TRAVEL_TIME,99.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb944b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = df[df.TAXI_ID==taxi_ids[200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ee45260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258729</th>\n",
       "      <td>1377735814620000356</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000356</td>\n",
       "      <td>1377735814</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.586063,41.148909],[-8.58762,41.149251],[-...</td>\n",
       "      <td>11970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "258729  1377735814620000356         B          NaN          15.0  20000356   \n",
       "\n",
       "         TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "258729  1377735814        A         False   \n",
       "\n",
       "                                                 POLYLINE  TRAVEL_TIME  \n",
       "258729  [[-8.586063,41.148909],[-8.58762,41.149251],[-...        11970  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[t1.TRAVEL_TIME == t1.TRAVEL_TIME.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5f2848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2013, 8, 7, 23, 43, 21)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.fromtimestamp(1375919001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fc8bb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='TRAVEL_TIME'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(t1.TRAVEL_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "858cf59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>T208</td>\n",
       "      <td>20000356</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "200    T208  20000356  2014     10    41    6    15   12        0   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "200            0            0            1            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "200             0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest.TAXI_ID==taxi_ids[200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72dd55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = t1\n",
    "Q1 = tmpdf['TRAVEL_TIME'].quantile(0.25)\n",
    "Q3 = tmpdf['TRAVEL_TIME'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f532a61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1093727</th>\n",
       "      <td>1393061275620000681</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000681</td>\n",
       "      <td>1393061275</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.583435,41.158665],[-8.582958,41.158899],[...</td>\n",
       "      <td>58200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "1093727  1393061275620000681         C          NaN           NaN  20000681   \n",
       "\n",
       "          TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "1093727  1393061275        A         False   \n",
       "\n",
       "                                                  POLYLINE  TRAVEL_TIME  \n",
       "1093727  [[-8.583435,41.158665],[-8.582958,41.158899],[...        58200  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.TRAVEL_TIME == df.TRAVEL_TIME.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bfb1bfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRIP_ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001502</td>\n",
       "      <td>0.869592</td>\n",
       "      <td>-0.509085</td>\n",
       "      <td>-0.499938</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>-0.019728</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>-0.023349</td>\n",
       "      <td>0.023528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.008460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAXI_ID</th>\n",
       "      <td>-0.001502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>-0.003322</td>\n",
       "      <td>-0.003081</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.012360</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.021025</td>\n",
       "      <td>-0.039728</td>\n",
       "      <td>-0.013108</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.014255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <td>0.869592</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.865639</td>\n",
       "      <td>-0.843203</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>-0.019655</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>-0.022901</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>0.003655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <td>-0.509085</td>\n",
       "      <td>-0.003322</td>\n",
       "      <td>-0.865639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965413</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>-0.006156</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>-0.011345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEK</th>\n",
       "      <td>-0.499938</td>\n",
       "      <td>-0.003081</td>\n",
       "      <td>-0.843203</td>\n",
       "      <td>0.965413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069588</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>-0.001152</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.006286</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>-0.013465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.002470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY</th>\n",
       "      <td>0.067491</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.069588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.014688</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>0.003913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUR</th>\n",
       "      <td>-0.019728</td>\n",
       "      <td>-0.012360</td>\n",
       "      <td>-0.019655</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>-0.137938</td>\n",
       "      <td>0.040660</td>\n",
       "      <td>0.108566</td>\n",
       "      <td>-0.154914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.031993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN</th>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>-0.001152</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>-0.012956</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>-0.016434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKDAY</th>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.021025</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.014688</td>\n",
       "      <td>-0.137938</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048157</td>\n",
       "      <td>-0.060164</td>\n",
       "      <td>0.108881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-0.049312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <td>0.002146</td>\n",
       "      <td>-0.039728</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>-0.006156</td>\n",
       "      <td>-0.006286</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.040660</td>\n",
       "      <td>-0.012956</td>\n",
       "      <td>-0.048157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.508486</td>\n",
       "      <td>-0.344436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>0.017330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <td>-0.023349</td>\n",
       "      <td>-0.013108</td>\n",
       "      <td>-0.022901</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.108566</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>-0.060164</td>\n",
       "      <td>-0.508486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.633241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>-0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <td>0.023528</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>-0.011345</td>\n",
       "      <td>-0.013465</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>-0.154914</td>\n",
       "      <td>-0.016434</td>\n",
       "      <td>0.108881</td>\n",
       "      <td>-0.344436</td>\n",
       "      <td>-0.633241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.076117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>-0.049312</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>-0.084100</td>\n",
       "      <td>0.076117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID   TAXI_ID      YEAR     MONTH      WEEK       DAY  \\\n",
       "TRIP_ID       1.000000 -0.001502  0.869592 -0.509085 -0.499938  0.067491   \n",
       "TAXI_ID      -0.001502  1.000000  0.001145 -0.003322 -0.003081 -0.002344   \n",
       "YEAR          0.869592  0.001145  1.000000 -0.865639 -0.843203 -0.018801   \n",
       "MONTH        -0.509085 -0.003322 -0.865639  1.000000  0.965413  0.017073   \n",
       "WEEK         -0.499938 -0.003081 -0.843203  0.965413  1.000000  0.069588   \n",
       "DAY           0.067491 -0.002344 -0.018801  0.017073  0.069588  1.000000   \n",
       "HOUR         -0.019728 -0.012360 -0.019655  0.010190  0.008136  0.018916   \n",
       "MIN           0.001571  0.002757  0.001590 -0.001379 -0.001152  0.000750   \n",
       "WEEKDAY       0.018385  0.021025  0.010306  0.002304  0.007167 -0.014688   \n",
       "CALL_TYPE_A   0.002146 -0.039728  0.004415 -0.006156 -0.006286  0.004625   \n",
       "CALL_TYPE_B  -0.023349 -0.013108 -0.022901  0.015480  0.017532  0.007632   \n",
       "CALL_TYPE_C   0.023528  0.050000  0.021000 -0.011345 -0.013465 -0.012478   \n",
       "ORIGIN_CALL        NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "ORIGIN_STAND       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "MISSING_DATA -0.000690  0.002130 -0.001079  0.001224  0.001215 -0.000395   \n",
       "TRAVEL_TIME   0.008460  0.014255  0.003655  0.001772  0.002470  0.003913   \n",
       "\n",
       "                  HOUR       MIN   WEEKDAY  CALL_TYPE_A  CALL_TYPE_B  \\\n",
       "TRIP_ID      -0.019728  0.001571  0.018385     0.002146    -0.023349   \n",
       "TAXI_ID      -0.012360  0.002757  0.021025    -0.039728    -0.013108   \n",
       "YEAR         -0.019655  0.001590  0.010306     0.004415    -0.022901   \n",
       "MONTH         0.010190 -0.001379  0.002304    -0.006156     0.015480   \n",
       "WEEK          0.008136 -0.001152  0.007167    -0.006286     0.017532   \n",
       "DAY           0.018916  0.000750 -0.014688     0.004625     0.007632   \n",
       "HOUR          1.000000 -0.002944 -0.137938     0.040660     0.108566   \n",
       "MIN          -0.002944  1.000000 -0.007654    -0.012956     0.025754   \n",
       "WEEKDAY      -0.137938 -0.007654  1.000000    -0.048157    -0.060164   \n",
       "CALL_TYPE_A   0.040660 -0.012956 -0.048157     1.000000    -0.508486   \n",
       "CALL_TYPE_B   0.108566  0.025754 -0.060164    -0.508486     1.000000   \n",
       "CALL_TYPE_C  -0.154914 -0.016434  0.108881    -0.344436    -0.633241   \n",
       "ORIGIN_CALL        NaN       NaN       NaN          NaN          NaN   \n",
       "ORIGIN_STAND       NaN       NaN       NaN          NaN          NaN   \n",
       "MISSING_DATA  0.000206 -0.000361  0.000630    -0.000486    -0.001020   \n",
       "TRAVEL_TIME   0.031993  0.000811 -0.049312     0.017330    -0.084100   \n",
       "\n",
       "              CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  MISSING_DATA  \\\n",
       "TRIP_ID          0.023528          NaN           NaN     -0.000690   \n",
       "TAXI_ID          0.050000          NaN           NaN      0.002130   \n",
       "YEAR             0.021000          NaN           NaN     -0.001079   \n",
       "MONTH           -0.011345          NaN           NaN      0.001224   \n",
       "WEEK            -0.013465          NaN           NaN      0.001215   \n",
       "DAY             -0.012478          NaN           NaN     -0.000395   \n",
       "HOUR            -0.154914          NaN           NaN      0.000206   \n",
       "MIN             -0.016434          NaN           NaN     -0.000361   \n",
       "WEEKDAY          0.108881          NaN           NaN      0.000630   \n",
       "CALL_TYPE_A     -0.344436          NaN           NaN     -0.000486   \n",
       "CALL_TYPE_B     -0.633241          NaN           NaN     -0.001020   \n",
       "CALL_TYPE_C      1.000000          NaN           NaN      0.001549   \n",
       "ORIGIN_CALL           NaN          NaN           NaN           NaN   \n",
       "ORIGIN_STAND          NaN          NaN           NaN           NaN   \n",
       "MISSING_DATA     0.001549          NaN           NaN      1.000000   \n",
       "TRAVEL_TIME      0.076117          NaN           NaN      0.003408   \n",
       "\n",
       "              TRAVEL_TIME  \n",
       "TRIP_ID          0.008460  \n",
       "TAXI_ID          0.014255  \n",
       "YEAR             0.003655  \n",
       "MONTH            0.001772  \n",
       "WEEK             0.002470  \n",
       "DAY              0.003913  \n",
       "HOUR             0.031993  \n",
       "MIN              0.000811  \n",
       "WEEKDAY         -0.049312  \n",
       "CALL_TYPE_A      0.017330  \n",
       "CALL_TYPE_B     -0.084100  \n",
       "CALL_TYPE_C      0.076117  \n",
       "ORIGIN_CALL           NaN  \n",
       "ORIGIN_STAND          NaN  \n",
       "MISSING_DATA     0.003408  \n",
       "TRAVEL_TIME      1.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b93c03b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 16:36:02.257748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 16:36:02.259349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 16:36:02.261688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 16:36:02.698189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 16:36:02.700162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 16:36:02.701558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-29 16:36:03.330037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 16:36:03.335056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 16:36:03.338711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 3s 7ms/step - loss: 404.3230 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 332.6851 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 332.1812 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 331.8935 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 331.6771 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 331.6803 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.6538 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 331.2074 - accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.5596 - accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.0239 - accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.0006 - accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.8781 - accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.2421 - accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.4576 - accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.4275 - accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.0818 - accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.6585 - accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.9906 - accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.8736 - accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2775 - accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2658 - accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.5426 - accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.8490 - accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.0105 - accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9283 - accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0345 - accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2974 - accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1937 - accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.6706 - accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2241 - accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.5062 - accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1617 - accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 328.9828 - accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2150 - accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.4633 - accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0511 - accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.6281 - accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0173 - accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 329.1272 - accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5296 - accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2781 - accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0349 - accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2506 - accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8656 - accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.4852 - accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9834 - accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9721 - accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1293 - accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1277 - accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7937 - accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8790 - accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1353 - accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8787 - accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8363 - accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.3648 - accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9095 - accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1364 - accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.6352 - accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0670 - accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8020 - accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5817 - accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7771 - accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0793 - accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9827 - accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6035 - accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7769 - accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5066 - accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4810 - accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6850 - accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8993 - accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.0801 - accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4034 - accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5782 - accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7132 - accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8043 - accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4298 - accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.2313 - accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4296 - accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4589 - accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4097 - accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.2566 - accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 327.9745 - accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5084 - accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.9979 - accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.9516 - accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 330.0071 - accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.4629 - accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4208 - accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0285 - accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4056 - accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4188 - accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.1418 - accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1454 - accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7784 - accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8111 - accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7152 - accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1678 - accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.6541 - accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.7520 - accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.5246 - accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.4956 - accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.5169 - accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.7513 - accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.8581 - accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.8779 - accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.6701 - accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.5798 - accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9464 - accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7696 - accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0645 - accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.7727 - accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.3635 - accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.3795 - accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.5359 - accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2544 - accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2473 - accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9716 - accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.7543 - accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.3088 - accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2169 - accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4703 - accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6118 - accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1942 - accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.0840 - accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9795 - accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7220 - accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6122 - accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.3779 - accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.9557 - accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1848 - accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7448 - accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6425 - accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.3610 - accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5923 - accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8616 - accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2811 - accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6938 - accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1744 - accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1143 - accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.2497 - accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1256 - accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.6889 - accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.8394 - accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 329.1446 - accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.1464 - accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.4513 - accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.5702 - accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.7663 - accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.1802 - accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 328.2660 - accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4a2c545c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 384ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 16:39:16.745989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-29 16:39:16.747511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-29 16:39:16.749052: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 621.2972\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "T308 620.2324\n"
     ]
    }
   ],
   "source": [
    "trips_id = []\n",
    "travel_preds = []\n",
    "\n",
    "for taxi_id in taxi_ids[0:1]:\n",
    "    new_train=dftrain[dftrain['TAXI_ID'] == taxi_id]\n",
    "    train_corr=new_train[['TRAVEL_TIME', 'YEAR', 'MONTH', 'WEEK', 'DAY', 'HOUR', 'MIN', 'WEEKDAY']].corr()\n",
    "    positive_corr_list=list(train_corr[train_corr > 0]['TRAVEL_TIME'].dropna().keys())\n",
    "    positive_corr_list.remove('TRAVEL_TIME')\n",
    "\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for row in new_train.iterrows():\n",
    "    lst = []\n",
    "    for elem in positive_corr_list:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    Xtrain.append(np.array(lst))\n",
    "    value = row[1]['TRAVEL_TIME'] #/ 15 + 1\n",
    "    ytrain.append(np.array([value]))\n",
    "    \n",
    "    X_train = np.array(Xtrain)\n",
    "    y_train = np.array(ytrain)\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    y_train = np.reshape(y_train, (-1,1))\n",
    "\n",
    "    timesteps = X_train.shape[1]\n",
    "    features = X_train.shape[2]\n",
    "    num_classes = 1\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, features)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mae', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=150,verbose=True)#, validation_data=(X_val, y_val))\n",
    "\n",
    "tmp_test=dftest[dftest['TAXI_ID'] == taxi_id]  \n",
    "for row in tmp_test.iterrows():\n",
    "    trip_id = row[1]['TRIP_ID']\n",
    "\n",
    "    lst = []\n",
    "    for elem in positive_corr_list:\n",
    "        lst.append(row[1][elem])\n",
    "\n",
    "    #Reshape your data either using array.reshape(-1, 1) if your data has a single feature \n",
    "    #or array.reshape(1, -1) if it contains a single sample.\n",
    "    pred = model.predict(np.array(lst).reshape(1,-1))[0][0]\n",
    "    print(trip_id,pred)\n",
    "#         preds.append(pred)\n",
    "        \n",
    "#         travel_preds.append(pred)\n",
    "#         trips_id.append(trip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4138cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='LEN'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df_cleaned[df_cleaned.TAXI_ID == taxi_ids[0]].LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc4f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df_cleaned[df_cleaned.TAXI_ID == taxi_ids[0]].LEN\n",
    "\n",
    "Q1 = np.percentile(tmp,25)\n",
    "Q3 = np.percentile(tmp,75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the DataFrame to remove outliers\n",
    "tmp = tmp[(tmp >= lower_bound) & (tmp <= upper_bound)]\n",
    "# if len(df_filtered) > 0:\n",
    "#     print(st.mode(df_filtered['TRAVEL_TIME']))\n",
    "# else:\n",
    "#     print('skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251dbb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='LEN'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c507f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(tmp,25)\n",
    "Q3 = np.percentile(tmp,75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the DataFrame to remove outliers\n",
    "tmp = tmp[(tmp >= lower_bound) & (tmp <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c6d196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='LEN'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d858a406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "274bed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "936588b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 285  375  810  510  735  600  720  900 1080  450 1635  405  705  795\n",
      " 1440  690 1035 2685 1200  180  330  270  585  675  540  225  465  495\n",
      "  825 1770  555  750  120 1005  300  390  480 1230 1260  945  345  780\n",
      "  435 4845 2400  615  885 1125  660 1965 2460  990  360  525  420  210\n",
      "  315 2295  630 1170 3840 1935  855 5550 1245  840 1185  870 1680 2385\n",
      " 1020 1050 1995  915 1425  765  570  645  960 2970 1980 3435 1155  255\n",
      " 1380 1740 1095 1500  165  240 3600  135 1485 2085 6945 1395 1365  105\n",
      " 1410 2895 2340  975 1110 1710 1455 1065  930 1140] 6945 108\n"
     ]
    }
   ],
   "source": [
    "tmp=df_cleaned[(df_cleaned.TAXI_ID == taxi_ids[0]) & (df_cleaned.MON == 8)].LEN\n",
    "print(tmp.unique(), tmp.max(), len(tmp.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27d416a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>20000542</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>20000108</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>20000370</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>20000492</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>20000621</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T323</td>\n",
       "      <td>20000430</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>T324</td>\n",
       "      <td>20000020</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>T325</td>\n",
       "      <td>20000207</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>T326</td>\n",
       "      <td>20000667</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>T327</td>\n",
       "      <td>20000255</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "0        T1  20000542  2014      8    33   14    17   57        3   \n",
       "1        T2  20000108  2014      8    33   14    17   50        3   \n",
       "2        T3  20000370  2014      8    33   14    17   49        3   \n",
       "3        T4  20000492  2014      8    33   14    17   58        3   \n",
       "4        T5  20000621  2014      8    33   14    17   59        3   \n",
       "..      ...       ...   ...    ...   ...  ...   ...  ...      ...   \n",
       "315    T323  20000430  2014     12    51   21    14   18        6   \n",
       "316    T324  20000020  2014     12    51   21    14    6        6   \n",
       "317    T325  20000207  2014     12    51   21    14   28        6   \n",
       "318    T326  20000667  2014     12    51   21    14   26        6   \n",
       "319    T327  20000255  2014     12    51   21    14   17        6   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0              0            1            0            1             1   \n",
       "1              0            1            0            1             1   \n",
       "2              0            1            0            1             1   \n",
       "3              0            1            0            1             1   \n",
       "4              0            1            0            1             1   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "315            1            0            0            1             1   \n",
       "316            0            1            0            1             1   \n",
       "317            0            0            1            1             1   \n",
       "318            1            0            0            1             1   \n",
       "319            1            0            0            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "315             0  \n",
       "316             0  \n",
       "317             0  \n",
       "318             0  \n",
       "319             0  \n",
       "\n",
       "[320 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18293d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>T74</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>T253</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  \\\n",
       "73      T74  20000256  2014      8    33   14    17   40        3   \n",
       "245    T253  20000256  2014     11    44    1     3   38        5   \n",
       "\n",
       "     CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "73             0            0            1            1             1   \n",
       "245            0            0            1            1             1   \n",
       "\n",
       "     MISSING_DATA  \n",
       "73              0  \n",
       "245             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest.TAXI_ID == taxi_ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T253 -- time = 1260\n",
    "# T74 -- time = 1155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f253542",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_labels = len(tmp.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9a88eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_labels = list(range(uniq_labels))\n",
    "dicts = dict(zip(tmp.unique(), encoding_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fcfbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy training data\n",
    "X_train = np.random.random((1000, 10))\n",
    "y_train = np.random.randint(0, 3, (1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94eb722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24713907",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = df.POLYLINE.apply(lambda x: max((x.count('[')-1-1)*15, 0)) # if (x.count('[')-1-1)*15 > 0 else np.nan)\n",
    "df = df.assign(TRAVEL_TIME = times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "69581b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = dftrain.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "429f64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = dftrain[dftrain.MISSING_DATA != True]\n",
    "tmpdf = df_filtered[df_filtered.TAXI_ID == taxi_ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f9ac847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = tmpdf[tmpdf.TRAVEL_TIME <= 1515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2aba421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for row in tmpdf.iterrows():\n",
    "    #print(row[1])\n",
    "    lst = [row[1]['MONTH'], row[1]['WEEK'], row[1]['MIN']]\n",
    "    X_train.append(lst)\n",
    "    y_train.append(row[1]['TRAVEL_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1264948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "861afa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    y_train[i] = dicts[y_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5bb7e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:05:34.412962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10379 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:3e:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_148/3175137562.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0996debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on new data\n",
    "X_test = np.array([X_train[10], X_train[12]])\n",
    "y_pred = model.predict(X_test)\n",
    "np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "46dc91fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>T73</td>\n",
       "      <td>20000334</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  WEEKDAY  CALL_TYPE_A  \\\n",
       "72     T73  20000334  2014      8    33   14    17   57        3            0   \n",
       "\n",
       "    CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  ORIGIN_STAND  MISSING_DATA  \n",
       "72            1            0            1             1             0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest[dftest.TRIP_ID == 'T73']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dcb4b2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MIN</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1372638021620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1372660598620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1372664539620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>1372667190620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1372668303620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671680</th>\n",
       "      <td>1404135567620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672228</th>\n",
       "      <td>1404137654620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672492</th>\n",
       "      <td>1404144140620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673195</th>\n",
       "      <td>1404158391620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673812</th>\n",
       "      <td>1404159875620000256</td>\n",
       "      <td>20000256</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4300 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID   TAXI_ID  YEAR  MONTH  WEEK  DAY  HOUR  MIN  \\\n",
       "346      1372638021620000256  20000256  2013      7    27    1     0   20   \n",
       "487      1372660598620000256  20000256  2013      7    27    1     6   36   \n",
       "682      1372664539620000256  20000256  2013      7    27    1     7   42   \n",
       "772      1372667190620000256  20000256  2013      7    27    1     8   26   \n",
       "986      1372668303620000256  20000256  2013      7    27    1     8   45   \n",
       "...                      ...       ...   ...    ...   ...  ...   ...  ...   \n",
       "1671680  1404135567620000256  20000256  2014      6    27   30    13   39   \n",
       "1672228  1404137654620000256  20000256  2014      6    27   30    14   14   \n",
       "1672492  1404144140620000256  20000256  2014      6    27   30    16    2   \n",
       "1673195  1404158391620000256  20000256  2014      6    27   30    19   59   \n",
       "1673812  1404159875620000256  20000256  2014      6    27   30    20   24   \n",
       "\n",
       "         WEEKDAY  CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  ORIGIN_CALL  \\\n",
       "346            0            0            0            1            1   \n",
       "487            0            0            0            1            1   \n",
       "682            0            0            1            0            1   \n",
       "772            0            1            0            0            1   \n",
       "986            0            0            0            1            1   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1671680        0            1            0            0            1   \n",
       "1672228        0            1            0            0            1   \n",
       "1672492        0            0            1            0            1   \n",
       "1673195        0            0            1            0            1   \n",
       "1673812        0            0            1            0            1   \n",
       "\n",
       "         ORIGIN_STAND  MISSING_DATA  TRAVEL_TIME  \n",
       "346                 1             0        750.0  \n",
       "487                 1             0        795.0  \n",
       "682                 1             0        900.0  \n",
       "772                 1             0        585.0  \n",
       "986                 1             0        900.0  \n",
       "...               ...           ...          ...  \n",
       "1671680             1             0        795.0  \n",
       "1672228             1             0       1155.0  \n",
       "1672492             1             0        825.0  \n",
       "1673195             1             0        300.0  \n",
       "1673812             1             0        285.0  \n",
       "\n",
       "[4300 rows x 16 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce7b9fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408038045"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data.TAXI_ID == taxi_ids[0]].TIMESTAMP[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "538d929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., 27.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1b923711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7., 27., 20.],\n",
       "       [ 7., 27., 36.],\n",
       "       [ 7., 27., 42.],\n",
       "       ...,\n",
       "       [ 6., 27.,  2.],\n",
       "       [ 6., 27., 59.],\n",
       "       [ 6., 27., 24.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3a226836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2., ..., 67., 60., 44.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
